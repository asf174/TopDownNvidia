							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Prieto (UC) <pablo.prieto@unican.es>, Pablo Abad (UC) <pablo.abad@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         Open Source                                                                        ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16037== NVPROF is profiling process 16037, command: ../../../../CUDA/bin/add_two_matrix
==16037== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16037== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16037== Profiling result:
==16037== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144517421   144517421   144517421   144517421

==16037== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.38%      27.38%      27.38%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.52%       2.52%       2.52%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.37%      51.37%      51.37%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.32%      18.32%      18.32%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196224    0.196224    0.196224
          1                               inst_issued                          Instructions Issued    28332470    28332470    28332470
          1                                       ipc                                 Executed IPC    0.196021    0.196021    0.196021

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║                                                    ║
			║ IPC OBTAINED: 0.196021 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3060.9% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.26% ║
			║                                           ║
			║ IPC DEGRADATION (%):               29.27% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.73% ║
			║                                           ║
			║ IPC DEGRADATION (%):               67.45% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.003% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16355== NVPROF is profiling process 16355, command: ../../../../CUDA/bin/add_two_matrix
==16355== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16355== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16355== Profiling result:
==16355== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144600830   144600830   144600830   144600830

==16355== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.32%       0.32%       0.32%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      31.44%      31.44%      31.44%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.75%       1.75%       1.75%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      54.60%      54.60%      54.60%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.69%      11.69%      11.69%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.195682    0.195682    0.195682
          1                               inst_issued                          Instructions Issued    28332396    28332396    28332396
          1                                       ipc                                 Executed IPC    0.195907    0.195907    0.195907

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║                                                    ║
			║ IPC OBTAINED: 0.195907 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3062.68% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          33.65%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               32.551% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          66.34%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               64.174% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16672== NVPROF is profiling process 16672, command: ../../../../CUDA/bin/add_two_matrix
==16672== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16672== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16672== Profiling result:
==16672== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113174085   113174085   113174085   113174085

==16672== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.19%      26.19%      26.19%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.69%       1.69%       1.69%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      60.36%      60.36%      60.36%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.26%      11.26%      11.26%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.226832    0.226832    0.226832
          1                               inst_issued                          Instructions Issued    28331989    28331989    28331989
          1                                       ipc                                 Executed IPC    0.250308    0.250308    0.250308

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.250308 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2397.05% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          28.31%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               27.129% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          71.67% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16990== NVPROF is profiling process 16990, command: ../../../../CUDA/bin/add_two_matrix
==16990== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16990== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16990== Profiling result:
==16990== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144340559   144340559   144340559   144340559

==16990== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      30.14%      30.14%      30.14%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.63%       1.63%       1.63%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      56.59%      56.59%      56.59%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.15%      11.15%      11.15%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196249    0.196249    0.196249
          1                               inst_issued                          Instructions Issued    28332603    28332603    28332603
          1                                       ipc                                 Executed IPC    0.196261    0.196261    0.196261

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196261 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3057.15% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          32.2%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               31.147% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          67.79%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               65.573% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17328== NVPROF is profiling process 17328, command: ../../../../CUDA/bin/add_two_matrix
==17328== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17328== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17328== Profiling result:
==17328== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144594172   144594172   144594172   144594172

==17328== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.28%       0.28%       0.28%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      25.93%      25.93%      25.93%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.98%      51.98%      51.98%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      19.05%      19.05%      19.05%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.208637    0.208637    0.208637
          1                               inst_issued                          Instructions Issued    28332187    28332187    28332187
          1                                       ipc                                 Executed IPC    0.195916    0.195916    0.195916

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.195916 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3062.54% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          28.92%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               27.914% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          71.07%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               68.599% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.212% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17641== NVPROF is profiling process 17641, command: ../../../../CUDA/bin/add_two_matrix
==17641== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17641== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17641== Profiling result:
==17641== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   124383930   124383930   124383930   124383930

==17641== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.34%       0.34%       0.34%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      33.24%      33.24%      33.24%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.84%       1.84%       1.84%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.00%      52.00%      52.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      12.37%      12.37%      12.37%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197196    0.197196    0.197196
          1                               inst_issued                          Instructions Issued    28332267    28332267    28332267
          1                                       ipc                                 Executed IPC    0.227750    0.227750    0.227750

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.22775 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2634.47% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          35.57% ║
			║                                           ║
			║ IPC DEGRADATION (%):               34.22% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          64.42%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               61.975% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17954== NVPROF is profiling process 17954, command: ../../../../CUDA/bin/add_two_matrix
==17954== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17954== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17954== Profiling result:
==17954== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144329109   144329109   144329109   144329109

==17954== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.30%      26.30%      26.30%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.48%       2.48%       2.48%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.84%      52.84%      52.84%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      17.98%      17.98%      17.98%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197261    0.197261    0.197261
          1                               inst_issued                          Instructions Issued    28332385    28332385    28332385
          1                                       ipc                                 Executed IPC    0.196276    0.196276    0.196276

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196276 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3056.92% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          29.14%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               28.182% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          70.86% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.53% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.016% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.27%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        26.30% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.48%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                52.84% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             17.98% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.197261 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.196276 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332385 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               144329109 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18273== NVPROF is profiling process 18273, command: ../../../../CUDA/bin/add_two_matrix
==18273== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18273== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18273== Profiling result:
==18273== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113042117   113042117   113042117   113042117

==18273== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.36%       0.36%       0.36%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      35.29%      35.29%      35.29%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.95%       1.95%       1.95%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      49.21%      49.21%      49.21%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      12.98%      12.98%      12.98%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196515    0.196515    0.196515
          1                               inst_issued                          Instructions Issued    28332272    28332272    28332272
          1                                       ipc                                 Executed IPC    0.250600    0.250600    0.250600

The results have been obtained correctly. General results of IPC are the following:

			╔══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.2506 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2394.25% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          37.75%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               36.173% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          62.25% ║
			║                                           ║
			║ IPC DEGRADATION (%):               59.65% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.36%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        35.29% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.95%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.15%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                49.21% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             12.98% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196515 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.250600 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332272 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               113042117 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18600== NVPROF is profiling process 18600, command: ../../../../CUDA/bin/add_two_matrix
==18600== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18600== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18600== Profiling result:
==18600== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   112597227   112597227   112597227   112597227

==18600== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.29%      28.29%      28.29%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.65%       1.65%       1.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.66%      58.66%      58.66%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.92%      10.92%      10.92%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.206927    0.206927    0.206927
          1                               inst_issued                          Instructions Issued    28332167    28332167    28332167
          1                                       ipc                                 Executed IPC    0.251590    0.251590    0.251590

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.25159 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2384.83% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.37% ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.0%   ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.63% ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.0%   ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        28.29% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.65%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.66% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             10.92% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.206927 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.251590 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332167 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               112597227 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18828== NVPROF is profiling process 18828, command: ../../../../CUDA/bin/add_two_matrix
==18828== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18828== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18828== Profiling result:
==18828== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144046329   144046329   144046329   144046329

==18828== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.92%      29.92%      29.92%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.65%       1.65%       1.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      56.77%      56.77%      56.77%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.18%      11.18%      11.18%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196879    0.196879    0.196879
          1                               inst_issued                          Instructions Issued    28332325    28332325    28332325
          1                                       ipc                                 Executed IPC    0.196662    0.196662    0.196662

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196662 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3050.92% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          32.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               31.999% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          68.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               67.997% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.004% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        29.92% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.65%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                56.77% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.18% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196879 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.196662 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332325 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               144046329 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19143== NVPROF is profiling process 19143, command: ../../../../CUDA/bin/add_two_matrix
==19143== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19143== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19143== Profiling result:
==19143== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   143210090   143210090   143210090   143210090

==19143== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.35%      26.35%      26.35%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.51%       2.51%       2.51%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.57%      52.57%      52.57%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.17%      18.17%      18.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196907    0.196907    0.196907
          1                               inst_issued                          Instructions Issued    28332468    28332468    28332468
          1                                       ipc                                 Executed IPC    0.197810    0.197810    0.197810

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.19781 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3033.21% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          29.22% ║
			║                                           ║
			║ IPC DEGRADATION (%):               29.22% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          70.78% ║
			║                                           ║
			║ IPC DEGRADATION (%):               70.78% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.27%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        26.35% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.51%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                52.57% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             18.17% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196907 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.197810 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332468 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               143210090 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19456== NVPROF is profiling process 19456, command: ../../../../CUDA/bin/add_two_matrix
==19456== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19456== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19456== Profiling result:
==19456== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   112630399   112630399   112630399   112630399

==19456== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.05%      29.05%      29.05%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.61%       1.61%       1.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.10%      58.10%      58.10%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.77%      10.77%      10.77%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197742    0.197742    0.197742
          1                               inst_issued                          Instructions Issued    28332398    28332398    28332398
          1                                       ipc                                 Executed IPC    0.251516    0.251516    0.251516

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.251516 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2385.53% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          31.09% ║
			║                                           ║
			║ IPC DEGRADATION (%):               31.09% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          68.92% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.92% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        29.05% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.61%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.10% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             10.77% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.197742 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.251516 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332398 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               112630399 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19768== NVPROF is profiling process 19768, command: ../../../../CUDA/bin/add_two_matrix
==19768== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19768== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19768== Profiling result:
==19768== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   111577968   111577968   111577968   111577968

==19768== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.27%      28.27%      28.27%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.64%       1.64%       1.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.61%      58.61%      58.61%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.00%      11.00%      11.00%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.209046    0.209046    0.209046
          1                               inst_issued                          Instructions Issued    28332275    28332275    28332275
          1                                       ipc                                 Executed IPC    0.253889    0.253889    0.253889

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.253889 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2363.24% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.34% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.34% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.66% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.66% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        28.27% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.64%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.61% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.00% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.209046 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253889 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332275 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               111577968 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20079== NVPROF is profiling process 20079, command: ../../../../CUDA/bin/add_two_matrix
==20079== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==20079== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20079== Profiling result:
==20079== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   143354493   143354493   143354493   143354493

==20079== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.28%       0.28%       0.28%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.10%      27.10%      27.10%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.53%       2.53%       2.53%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.20%      51.20%      51.20%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.75%      18.75%      18.75%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.198023    0.198023    0.198023
          1                               inst_issued                          Instructions Issued    28332617    28332617    28332617
          1                                       ipc                                 Executed IPC    0.197611    0.197611    0.197611

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.197611 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3036.27% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          30.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               29.998% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          69.99%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               69.985% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.007% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.28%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        27.10% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.53%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                51.20% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             18.75% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.198023 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.197611 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332617 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               143354493 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21000== NVPROF is profiling process 21000, command: ../../../../CUDA/bin/add_two_matrix
==21000== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21000== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21000== Profiling result:
==21000== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   168328766   168328766   168328766   168328766

==21000== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.09%      29.09%      29.09%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.31%       1.31%       1.31%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.18%      58.18%      58.18%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.04%      11.04%      11.04%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.160541    0.160541    0.160541
          1                               inst_issued                          Instructions Issued    28333221    28333221    28333221
          1                                       ipc                                 Executed IPC    0.168292    0.168292    0.168292

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.168292 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3565.23% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.74% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.74% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.26% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.26% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21322== NVPROF is profiling process 21322, command: ../../../../CUDA/bin/add_two_matrix
==21322== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21322== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21322== Profiling result:
==21322== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   176607376   176607376   176607376   176607376

==21322== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.90%      28.90%      28.90%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.28%       1.28%       1.28%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.45%      58.45%      58.45%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.99%      10.99%      10.99%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.159628    0.159628    0.159628
          1                               inst_issued                          Instructions Issued    28333113    28333113    28333113
          1                                       ipc                                 Executed IPC    0.160403    0.160403    0.160403

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.160403 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3740.58% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.52% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.52% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.48% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.48% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: Divergece analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21635== NVPROF is profiling process 21635, command: ../../../../CUDA/bin/add_two_matrix
==21635== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21635== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21635== NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
Profiling result:
==21635== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   174890188   174890188   174890188   174890188

==21635== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.03%      29.03%      29.03%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.31%       1.31%       1.31%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.38%      58.38%      58.38%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.90%      10.90%      10.90%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.161852    0.161852    0.161852
          1                               inst_issued                          Instructions Issued    28332980    28332980    28332980
          1                                       ipc                                 Executed IPC    0.161978    0.161978    0.161978

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.161978 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3704.21% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.32% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.32% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21956== NVPROF is profiling process 21956, command: ../../../../CUDA/bin/add_two_matrix
==21956== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21956== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21956== Profiling result:
==21956== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   174527602   174527602   174527602   174527602

==21956== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.96%      27.96%      27.96%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.34%       1.34%       1.34%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.11%       0.11%       0.11%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      59.14%      59.14%      59.14%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.170768    0.170768    0.170768
          1                               inst_issued                          Instructions Issued    28332946    28332946    28332946
          1                                       ipc                                 Executed IPC    0.162315    0.162315    0.162315

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.162315 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3696.52% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          29.65%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               29.607% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          70.35%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               70.248% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.145% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22522== NVPROF is profiling process 22522, command: ../../../../CUDA/bin/add_two_matrix
==22522== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==22522== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22522== Profiling result:
==22522== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   139712275   139712275   139712275   139712275

==22522== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.91%      28.91%      28.91%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.32%       1.32%       1.32%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.33%      58.33%      58.33%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.06%      11.06%      11.06%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.161019    0.161019    0.161019
          1                               inst_issued                          Instructions Issued    28332945    28332945    28332945
          1                                       ipc                                 Executed IPC    0.202762    0.202762    0.202762

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.202762 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2959.13% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.57% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.57% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.43% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.43% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23079== NVPROF is profiling process 23079, command: ../../../../CUDA/bin/add_two_matrix
==23079== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==23079== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23079== Profiling result:
==23079== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==23079== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      10.91%      10.91%      10.91%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      23.99%      23.99%      23.99%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      14.29%      14.29%      14.29%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      50.29%      50.29%      50.29%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.51%       0.51%       0.51%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.211454    0.211454    0.211454
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          49.19%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               48.899% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          50.8%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               50.499% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.592% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
<<<<<<< HEAD
==2674== NVPROF is profiling process 2674, command: ../../../../CUDA/bin/add_two_matrix
==2674== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2674== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==2674== Profiling result:
==2674== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==2674== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051118    0.051118    0.051118
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==15856== NVPROF is profiling process 15856, command: ../../../../CUDA/bin/add_two_matrix
==15856== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==15856== Profiling application: ../../../../CUDA/bin/add_two_matrix
==15856== Profiling result:
==15856== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105842847   105842847   105842847   105842847

==15856== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.40%      12.40%      12.40%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.33%      73.33%      73.33%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.13%      11.13%      11.13%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252376    0.252376    0.252376
          1                               inst_issued                          Instructions Issued    26802972    26802972    26802972
          1                                       ipc                                 Executed IPC    0.253178    0.253178    0.253178
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==15898== NVPROF is profiling process 15898, command: ../../../../CUDA/bin/add_two_matrix
==15898== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==15898== Profiling application: ../../../../CUDA/bin/add_two_matrix
==15898== Profiling result:
==15898== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116231983   116231983   116231983   116231983

==15898== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.93%      11.93%      11.93%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.59%       2.59%       2.59%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.91%      73.91%      73.91%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.07%      11.07%      11.07%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.230605    0.230605    0.230605
          1                               inst_issued                          Instructions Issued    26803639    26803639    26803639
          1                                       ipc                                 Executed IPC    0.229243    0.229243    0.229243

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.229243 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2617.31% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.82%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.817% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          85.05% ║
			║                                           ║
			║ IPC DEGRADATION (%):               85.03% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.024% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17106== NVPROF is profiling process 17106, command: ../../../../CUDA/bin/add_two_matrix
==17106== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17106== Profiling application: ../../../../CUDA/bin/add_two_matrix
==17106== Profiling result:
==17106== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105890251   105890251   105890251   105890251

==17106== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.05%      12.05%      12.05%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.53%      73.53%      73.53%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.28%      11.28%      11.28%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253122    0.253122    0.253122
          1                               inst_issued                          Instructions Issued    26803191    26803191    26803191
          1                                       ipc                                 Executed IPC    0.252412    0.252412    0.252412

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.252412 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2377.07% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          15.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.998% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          84.88% ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.87% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.012% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17934== NVPROF is profiling process 17934, command: ../../../../CUDA/bin/add_two_matrix
==17934== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17934== Profiling application: ../../../../CUDA/bin/add_two_matrix
==17934== Profiling result:
==17934== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   124071692   124071692   124071692   124071692

==17934== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.16%       0.16%       0.16%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.84%      11.84%      11.84%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.60%       2.60%       2.60%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.12%       0.12%       0.12%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.96%      73.96%      73.96%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.12%      11.12%      11.12%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.216915    0.216915    0.216915
          1                               inst_issued                          Instructions Issued    26805308    26805308    26805308
          1                                       ipc                                 Executed IPC    0.215981    0.215981    0.215981

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.215981 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2778.02% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.72%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.718% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          85.14%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               85.126% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.016% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18299== NVPROF is profiling process 18299, command: ../../../../CUDA/bin/add_two_matrix
==18299== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18299== Profiling application: ../../../../CUDA/bin/add_two_matrix
==18299== Profiling result:
==18299== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106236146   106236146   106236146   106236146

==18299== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.18%      12.18%      12.18%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.65%       2.65%       2.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.36%      73.36%      73.36%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.27%      11.27%      11.27%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252273    0.252273    0.252273
          1                               inst_issued                          Instructions Issued    26804185    26804185    26804185
          1                                       ipc                                 Executed IPC    0.252241    0.252241    0.252241

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.252241 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2378.68% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          15.16% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.16% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔══════════════════════════════════════════╗
			║ BACK-END RESULTS                         ║
			║ ----------------                         ║
			║                                          ║
			║ STALLS, on the total (%):          84.7% ║
			║                                          ║
			║ IPC DEGRADATION (%):               84.7% ║
			║                                          ║
			╚══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.001% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20304== NVPROF is profiling process 20304, command: ../../../../CUDA/bin/add_two_matrix
==20304== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20304== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20304== Profiling result:
==20304== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106129987   106129987   106129987   106129987

==20304== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.17%      12.17%      12.17%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.60%       2.60%       2.60%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.31%      73.31%      73.31%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.39%      11.39%      11.39%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252961    0.252961    0.252961
          1                               inst_issued                          Instructions Issued    26803240    26803240    26803240
          1                                       ipc                                 Executed IPC    0.252493    0.252493    0.252493
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20326== NVPROF is profiling process 20326, command: ../../../../CUDA/bin/add_two_matrix
==20326== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20326== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20326== Profiling result:
==20326== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106119736   106119736   106119736   106119736

==20326== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.39%      12.39%      12.39%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.68%       2.68%       2.68%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.09%      73.09%      73.09%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.31%      11.31%      11.31%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.251792    0.251792    0.251792
          1                               inst_issued                          Instructions Issued    26804802    26804802    26804802
          1                                       ipc                                 Executed IPC    0.252518    0.252518    0.252518
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20442== NVPROF is profiling process 20442, command: ../../../../CUDA/bin/add_two_matrix
==20442== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20442== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20442== Profiling result:
==20442== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   123449126   123449126   123449126   123449126

==20442== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.16%       0.16%       0.16%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.02%      12.02%      12.02%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.52%       2.52%       2.52%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.12%       0.12%       0.12%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.83%      73.83%      73.83%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.16%      11.16%      11.16%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.217124    0.217124    0.217124
          1                               inst_issued                          Instructions Issued    26803748    26803748    26803748
          1                                       ipc                                 Executed IPC    0.216018    0.216018    0.216018
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20482== NVPROF is profiling process 20482, command: ../../../../CUDA/bin/add_two_matrix
==20482== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20482== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20482== Profiling result:
==20482== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   123410503   123410503   123410503   123410503

==20482== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.16%       0.16%       0.16%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.93%      11.93%      11.93%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.53%       2.53%       2.53%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.12%       0.12%       0.12%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.89%      73.89%      73.89%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.19%      11.19%      11.19%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.217067    0.217067    0.217067
          1                               inst_issued                          Instructions Issued    26804535    26804535    26804535
          1                                       ipc                                 Executed IPC    0.217138    0.217138    0.217138
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20546== NVPROF is profiling process 20546, command: ../../../../CUDA/bin/add_two_matrix
==20546== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20546== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20546== Profiling result:
==20546== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106411986   106411986   106411986   106411986

==20546== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.44%      12.44%      12.44%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.64%       2.64%       2.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.15%      73.15%      73.15%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.24%      11.24%      11.24%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.251880    0.251880    0.251880
          1                               inst_issued                          Instructions Issued    26803926    26803926    26803926
          1                                       ipc                                 Executed IPC    0.251824    0.251824    0.251824
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20647== NVPROF is profiling process 20647, command: ../../../../CUDA/bin/add_two_matrix
==20647== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20647== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20647== Profiling result:
==20647== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   118865639   118865639   118865639   118865639

==20647== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.88%      11.88%      11.88%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.49%       2.49%       2.49%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.99%      73.99%      73.99%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.14%      11.14%      11.14%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.225502    0.225502    0.225502
          1                               inst_issued                          Instructions Issued    26804420    26804420    26804420
          1                                       ipc                                 Executed IPC    0.225995    0.225995    0.225995
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20689== NVPROF is profiling process 20689, command: ../../../../CUDA/bin/add_two_matrix
==20689== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20689== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20689== Profiling result:
==20689== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   118603851   118603851   118603851   118603851

==20689== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.10%      12.10%      12.10%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.58%       2.58%       2.58%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.63%      73.63%      73.63%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.21%      11.21%      11.21%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.225194    0.225194    0.225194
          1                               inst_issued                          Instructions Issued    26803468    26803468    26803468
          1                                       ipc                                 Executed IPC    0.225938    0.225938    0.225938
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20744== NVPROF is profiling process 20744, command: ../../../../CUDA/bin/add_two_matrix
==20744== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20744== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20744== Profiling result:
==20744== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   119404766   119404766   119404766   119404766

==20744== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.22%      12.22%      12.22%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.58%       2.58%       2.58%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.70%      73.70%      73.70%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.01%      11.01%      11.01%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.224476    0.224476    0.224476
          1                               inst_issued                          Instructions Issued    26803508    26803508    26803508
          1                                       ipc                                 Executed IPC    0.225900    0.225900    0.225900
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20783== NVPROF is profiling process 20783, command: ../../../../CUDA/bin/add_two_matrix
==20783== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20783== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20783== Profiling result:
==20783== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   117042345   117042345   117042345   117042345

==20783== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.13%      12.13%      12.13%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.52%       2.52%       2.52%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.66%      73.66%      73.66%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.19%      11.19%      11.19%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229010    0.229010    0.229010
          1                               inst_issued                          Instructions Issued    26803920    26803920    26803920
          1                                       ipc                                 Executed IPC    0.229100    0.229100    0.229100
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20827== NVPROF is profiling process 20827, command: ../../../../CUDA/bin/add_two_matrix
==20827== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20827== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20827== Profiling result:
==20827== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116542658   116542658   116542658   116542658

==20827== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.91%      11.91%      11.91%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.56%       2.56%       2.56%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.82%      73.82%      73.82%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.22%      11.22%      11.22%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229994    0.229994    0.229994
          1                               inst_issued                          Instructions Issued    26804086    26804086    26804086
          1                                       ipc                                 Executed IPC    0.229091    0.229091    0.229091
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20866== NVPROF is profiling process 20866, command: ../../../../CUDA/bin/add_two_matrix
==20866== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20866== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20866== Profiling result:
==20866== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116466995   116466995   116466995   116466995

==20866== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.15%      12.15%      12.15%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.65%       2.65%       2.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      74.54%      74.54%      74.54%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.17%      10.17%      10.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.230145    0.230145    0.230145
          1                               inst_issued                          Instructions Issued    26804260    26804260    26804260
          1                                       ipc                                 Executed IPC    0.254822    0.254822    0.254822
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20904== NVPROF is profiling process 20904, command: ../../../../CUDA/bin/add_two_matrix
==20904== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20904== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20904== Profiling result:
==20904== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106048625   106048625   106048625   106048625

==20904== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.27%      12.27%      12.27%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.32%      73.32%      73.32%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.21%      11.21%      11.21%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252742    0.252742    0.252742
          1                               inst_issued                          Instructions Issued    26802932    26802932    26802932
          1                                       ipc                                 Executed IPC    0.253316    0.253316    0.253316
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20931== NVPROF is profiling process 20931, command: ../../../../CUDA/bin/add_two_matrix
==20931== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20931== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20931== Profiling result:
==20931== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   109076142   109076142   109076142   109076142

==20931== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.24%      12.24%      12.24%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.74%       2.74%       2.74%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.25%      73.25%      73.25%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.25%      11.25%      11.25%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.245738    0.245738    0.245738
          1                               inst_issued                          Instructions Issued    26804129    26804129    26804129
          1                                       ipc                                 Executed IPC    0.246918    0.246918    0.246918
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20965== NVPROF is profiling process 20965, command: ../../../../CUDA/bin/add_two_matrix
==20965== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20965== Profiling application: ../../../../CUDA/bin/add_two_matrix
==20965== Profiling result:
==20965== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   122163202   122163202   122163202   122163202

==20965== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.16%       0.16%       0.16%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.90%      11.90%      11.90%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.57%       2.57%       2.57%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.12%       0.12%       0.12%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      74.07%      74.07%      74.07%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.98%      10.98%      10.98%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.219408    0.219408    0.219408
          1                               inst_issued                          Instructions Issued    26803589    26803589    26803589
          1                                       ipc                                 Executed IPC    0.219425    0.219425    0.219425
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21057== NVPROF is profiling process 21057, command: ../../../../CUDA/bin/add_two_matrix
==21057== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21057== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21057== Profiling result:
==21057== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106024542   106024542   106024542   106024542

==21057== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.19%      12.19%      12.19%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.64%       2.64%       2.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.36%      73.36%      73.36%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.27%      11.27%      11.27%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252804    0.252804    0.252804
          1                               inst_issued                          Instructions Issued    26803404    26803404    26803404
          1                                       ipc                                 Executed IPC    0.252400    0.252400    0.252400
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21105== NVPROF is profiling process 21105, command: ../../../../CUDA/bin/add_two_matrix
==21105== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21105== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21105== Profiling result:
==21105== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106188253   106188253   106188253   106188253

==21105== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.30%      12.30%      12.30%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.72%       2.72%       2.72%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.21%      73.21%      73.21%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.22%      11.22%      11.22%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252411    0.252411    0.252411
          1                               inst_issued                          Instructions Issued    26803092    26803092    26803092
          1                                       ipc                                 Executed IPC    0.253016    0.253016    0.253016
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21164== NVPROF is profiling process 21164, command: ../../../../CUDA/bin/add_two_matrix
==21164== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21164== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21164== Profiling result:
==21164== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   111373273   111373273   111373273   111373273

==21164== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.11%      12.11%      12.11%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.54%      73.54%      73.54%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.23%      11.23%      11.23%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.241315    0.241315    0.241315
          1                               inst_issued                          Instructions Issued    26803164    26803164    26803164
          1                                       ipc                                 Executed IPC    0.240606    0.240606    0.240606
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21210== NVPROF is profiling process 21210, command: ../../../../CUDA/bin/add_two_matrix
==21210== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21210== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21210== Profiling result:
==21210== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   110972828   110972828   110972828   110972828

==21210== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.23%      12.23%      12.23%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.42%      73.42%      73.42%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.23%      11.23%      11.23%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.241533    0.241533    0.241533
          1                               inst_issued                          Instructions Issued    26803606    26803606    26803606
          1                                       ipc                                 Executed IPC    0.241348    0.241348    0.241348
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22064== NVPROF is profiling process 22064, command: ../../../../CUDA/bin/add_two_matrix
==22064== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22064== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22064== Profiling result:
==22064== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   121702561   121702561   121702561   121702561

==22064== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.16%       0.16%       0.16%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.81%      11.81%      11.81%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.55%       2.55%       2.55%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      74.03%      74.03%      74.03%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.13%      11.13%      11.13%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.222081    0.222081    0.222081
          1                               inst_issued                          Instructions Issued    26803351    26803351    26803351
          1                                       ipc                                 Executed IPC    0.220185    0.220185    0.220185
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22120== NVPROF is profiling process 22120, command: ../../../../CUDA/bin/add_two_matrix
==22120== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22120== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22120== Profiling result:
==22120== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   135626695   135626695   135626695   135626695

==22120== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      13.14%      13.14%      13.14%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.55%       2.55%       2.55%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.12%       0.12%       0.12%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      72.91%      72.91%      72.91%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.92%      10.92%      10.92%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197635    0.197635    0.197635
          1                               inst_issued                          Instructions Issued    26804592    26804592    26804592
          1                                       ipc                                 Executed IPC    0.221514    0.221514    0.221514
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22159== NVPROF is profiling process 22159, command: ../../../../CUDA/bin/add_two_matrix
==22159== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22159== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22159== Profiling result:
==22159== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   133761717   133761717   133761717   133761717

==22159== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.15%       0.15%       0.15%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.64%      11.64%      11.64%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.58%       2.58%       2.58%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.11%       0.11%       0.11%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      74.20%      74.20%      74.20%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.13%      11.13%      11.13%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.200387    0.200387    0.200387
          1                               inst_issued                          Instructions Issued    26804058    26804058    26804058
          1                                       ipc                                 Executed IPC    0.200218    0.200218    0.200218
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22283== NVPROF is profiling process 22283, command: ../../../../CUDA/bin/add_two_matrix
==22283== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22283== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22283== Profiling result:
==22283== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105815543   105815543   105815543   105815543

==22283== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.21%      12.21%      12.21%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.58%       2.58%       2.58%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.32%      73.32%      73.32%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.36%      11.36%      11.36%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.251734    0.251734    0.251734
          1                               inst_issued                          Instructions Issued    26804172    26804172    26804172
          1                                       ipc                                 Executed IPC    0.253244    0.253244    0.253244
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22326== NVPROF is profiling process 22326, command: ../../../../CUDA/bin/add_two_matrix
==22326== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22326== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22326== Profiling result:
==22326== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   108985141   108985141   108985141   108985141

==22326== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.10%      12.10%      12.10%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.58%       2.58%       2.58%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.56%      73.56%      73.56%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.23%      11.23%      11.23%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.246682    0.246682    0.246682
          1                               inst_issued                          Instructions Issued    26803299    26803299    26803299
          1                                       ipc                                 Executed IPC    0.245879    0.245879    0.245879
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22454== NVPROF is profiling process 22454, command: ../../../../CUDA/bin/add_two_matrix
==22454== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22454== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22454== Profiling result:
==22454== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106223145   106223145   106223145   106223145

==22454== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.25%      12.25%      12.25%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.60%       2.60%       2.60%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.40%      73.40%      73.40%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.21%      11.21%      11.21%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252328    0.252328    0.252328
          1                               inst_issued                          Instructions Issued    26803072    26803072    26803072
          1                                       ipc                                 Executed IPC    0.252071    0.252071    0.252071
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22530== NVPROF is profiling process 22530, command: ../../../../CUDA/bin/add_two_matrix
==22530== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22530== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22530== Profiling result:
==22530== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   114542233   114542233   114542233   114542233

==22530== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.94%      11.94%      11.94%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.77%      73.77%      73.77%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.234411    0.234411    0.234411
          1                               inst_issued                          Instructions Issued    26803746    26803746    26803746
          1                                       ipc                                 Executed IPC    0.233950    0.233950    0.233950
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22579== NVPROF is profiling process 22579, command: ../../../../CUDA/bin/add_two_matrix
==22579== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22579== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22579== Profiling result:
==22579== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113932997   113932997   113932997   113932997

==22579== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.16%      12.16%      12.16%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.57%       2.57%       2.57%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.60%      73.60%      73.60%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.15%      11.15%      11.15%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.234945    0.234945    0.234945
          1                               inst_issued                          Instructions Issued    26803287    26803287    26803287
          1                                       ipc                                 Executed IPC    0.235201    0.235201    0.235201
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22643== NVPROF is profiling process 22643, command: ../../../../CUDA/bin/add_two_matrix
==22643== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22643== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22643== Profiling result:
==22643== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106198115   106198115   106198115   106198115

==22643== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.26%      12.26%      12.26%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.68%       2.68%       2.68%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.22%      73.22%      73.22%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.30%      11.30%      11.30%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252389    0.252389    0.252389
          1                               inst_issued                          Instructions Issued    26803282    26803282    26803282
          1                                       ipc                                 Executed IPC    0.252504    0.252504    0.252504
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22703== NVPROF is profiling process 22703, command: ../../../../CUDA/bin/add_two_matrix
==22703== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22703== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22703== Profiling result:
==22703== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116799485   116799485   116799485   116799485

==22703== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.98%      11.98%      11.98%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.75%      73.75%      73.75%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.15%      11.15%      11.15%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229482    0.229482    0.229482
          1                               inst_issued                          Instructions Issued    26803360    26803360    26803360
          1                                       ipc                                 Executed IPC    0.229780    0.229780    0.229780

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.17%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        11.98% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.62%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.75% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.15% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.229482 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.229780 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803360 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               116799485 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22799== NVPROF is profiling process 22799, command: ../../../../CUDA/bin/add_two_matrix
==22799== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22799== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22799== Profiling result:
==22799== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106261318   106261318   106261318   106261318

==22799== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.33%      12.33%      12.33%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.57%       2.57%       2.57%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.30%      73.30%      73.30%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.27%      11.27%      11.27%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252238    0.252238    0.252238
          1                               inst_issued                          Instructions Issued    26803141    26803141    26803141
          1                                       ipc                                 Executed IPC    0.252601    0.252601    0.252601
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22996== NVPROF is profiling process 22996, command: ../../../../CUDA/bin/add_two_matrix
==22996== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22996== Profiling application: ../../../../CUDA/bin/add_two_matrix
==22996== Profiling result:
==22996== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106076595   106076595   106076595   106076595

==22996== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.30%      12.30%      12.30%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.71%       2.71%       2.71%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.35%      73.35%      73.35%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.11%      11.11%      11.11%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.251856    0.251856    0.251856
          1                               inst_issued                          Instructions Issued    26804531    26804531    26804531
          1                                       ipc                                 Executed IPC    0.252620    0.252620    0.252620

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.30% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.71%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.35% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.11% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   106076595 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                106076595 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          106076595 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             106076595 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.251856 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.252620 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26804531 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               106076595 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23020== NVPROF is profiling process 23020, command: ../../../../CUDA/bin/add_two_matrix
==23020== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23020== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23020== Profiling result:
==23020== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   110334674   110334674   110334674   110334674

==23020== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.92%      11.92%      11.92%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.47%      73.47%      73.47%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.44%      11.44%      11.44%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.242925    0.242925    0.242925
          1                               inst_issued                          Instructions Issued    26803000    26803000    26803000
          1                                       ipc                                 Executed IPC    0.240878    0.240878    0.240878

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        11.92% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.66%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.47% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.44% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   110334674 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                110334674 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          110334674 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             110334674 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.242925 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.240878 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803000 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               110334674 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23118== NVPROF is profiling process 23118, command: ../../../../CUDA/bin/add_two_matrix
==23118== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23118== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23118== Profiling result:
==23118== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105512984   105512984   105512984   105512984

==23118== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.26%      12.26%      12.26%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.64%       2.64%       2.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.30%      73.30%      73.30%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.27%      11.27%      11.27%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252048    0.252048    0.252048
          1                               inst_issued                          Instructions Issued    26803161    26803161    26803161
          1                                       ipc                                 Executed IPC    0.253970    0.253970    0.253970

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.26% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.64%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.30% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.27% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   105512984 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                105512984 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          105512984 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             105512984 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.252048 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253970 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803161 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               105512984 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23294== NVPROF is profiling process 23294, command: ../../../../CUDA/bin/add_two_matrix
==23294== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23294== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23294== Profiling result:
==23294== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106361517   106361517   106361517   106361517

==23294== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.03%      12.03%      12.03%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.73%      73.73%      73.73%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.08%      11.08%      11.08%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253936    0.253936    0.253936
          1                               inst_issued                          Instructions Issued    26802953    26802953    26802953
          1                                       ipc                                 Executed IPC    0.251944    0.251944    0.251944

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.03% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.62%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.15%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.73% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.08% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   106361517 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                106361517 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          106361517 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             106361517 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.253936 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.251944 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26802953 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               106361517 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23342== NVPROF is profiling process 23342, command: ../../../../CUDA/bin/add_two_matrix
==23342== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23342== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23342== Profiling result:
==23342== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113879378   113879378   113879378   113879378

==23342== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.95%      11.95%      11.95%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.65%       2.65%       2.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.68%      73.68%      73.68%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.22%      11.22%      11.22%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.235368    0.235368    0.235368
          1                               inst_issued                          Instructions Issued    26803613    26803613    26803613
          1                                       ipc                                 Executed IPC    0.234787    0.234787    0.234787

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.17%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        11.95% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.65%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.68% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.22% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   113879378 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                113879378 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          113879378 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             113879378 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.235368 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.234787 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803613 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               113879378 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23384== NVPROF is profiling process 23384, command: ../../../../CUDA/bin/add_two_matrix
==23384== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23384== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23384== Profiling result:
==23384== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105692340   105692340   105692340   105692340

==23384== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.14%      12.14%      12.14%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.35%      73.35%      73.35%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.37%      11.37%      11.37%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253598    0.253598    0.253598
          1                               inst_issued                          Instructions Issued    26803334    26803334    26803334
          1                                       ipc                                 Executed IPC    0.253981    0.253981    0.253981

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.14% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.61%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.35% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.37% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   105692340 
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                105692340 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          105692340 
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             105692340 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.253598 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253981 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803334 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               105692340 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23436== NVPROF is profiling process 23436, command: ../../../../CUDA/bin/add_two_matrix
==23436== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23436== Profiling application: ../../../../CUDA/bin/add_two_matrix
==23436== Profiling result:
==23436== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   109063882   109063882   109063882   109063882

==23436== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.35%      12.35%      12.35%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.70%       2.70%       2.70%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.12%      73.12%      73.12%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.31%      11.31%      11.31%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.245393    0.245393    0.245393
          1                               inst_issued                          Instructions Issued    26803138    26803138    26803138
          1                                       ipc                                 Executed IPC    0.245701    0.245701    0.245701

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.35% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.70%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.12% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.31% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.12% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.31% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.245393 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.245701 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803138 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               109063882 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==6311== NVPROF is profiling process 6311, command: ../../../../CUDA/bin/add_two_matrix
==6311== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==6311== Profiling application: ../../../../CUDA/bin/add_two_matrix
==6311== Profiling result:
==6311== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106309656   106309656   106309656   106309656

==6311== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.41%      12.41%      12.41%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.55%       2.55%       2.55%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.33%      73.33%      73.33%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252139    0.252139    0.252139
          1                               inst_issued                          Instructions Issued    26804772    26804772    26804772
          1                                       ipc                                 Executed IPC    0.252093    0.252093    0.252093

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.41% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.55%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.15%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.33% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.17% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.33% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.17% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.252139 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.252093 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26804772 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               106309656 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==6436== NVPROF is profiling process 6436, command: ../../../../CUDA/bin/add_two_matrix
==6436== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==6436== Profiling application: ../../../../CUDA/bin/add_two_matrix
==6436== Profiling result:
==6436== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105881515   105881515   105881515   105881515

==6436== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.21%      12.21%      12.21%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.64%       2.64%       2.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.35%      73.35%      73.35%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.26%      11.26%      11.26%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253159    0.253159    0.253159
          1                               inst_issued                          Instructions Issued    26804817    26804817    26804817
          1                                       ipc                                 Executed IPC    0.252316    0.252316    0.252316

List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.21% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.64%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.35% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.26% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.35% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.26% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.253159 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.252316 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26804817 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               105881515 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==7668== NVPROF is profiling process 7668, command: ../../../../CUDA/bin/add_two_matrix
==7668== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==7668== Profiling application: ../../../../CUDA/bin/add_two_matrix
==7668== Profiling result:
==7668== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106338372   106338372   106338372   106338372

==7668== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.28%      12.28%      12.28%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.23%      73.23%      73.23%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.31%      11.31%      11.31%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252061    0.252061    0.252061
          1                               inst_issued                          Instructions Issued    26803719    26803719    26803719
          1                                       ipc                                 Executed IPC    0.252762    0.252762    0.252762
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==7700== NVPROF is profiling process 7700, command: ../../../../CUDA/bin/add_two_matrix
==7700== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==7700== Profiling application: ../../../../CUDA/bin/add_two_matrix
==7700== Profiling result:
==7700== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   114449632   114449632   114449632   114449632

==7700== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.11%      12.11%      12.11%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.52%      73.52%      73.52%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.25%      11.25%      11.25%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.234202    0.234202    0.234202
          1                               inst_issued                          Instructions Issued    26804365    26804365    26804365
          1                                       ipc                                 Executed IPC    0.234415    0.234415    0.234415

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.234415 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2559.56% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          15.02% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.02% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          84.84% ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.84% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.17%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.11% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.61%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.52% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.25% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.52% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.25% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.234202 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.234415 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26804365 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               114449632 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==8014== NVPROF is profiling process 8014, command: ../../../../CUDA/bin/add_two_matrix
==8014== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==8014== Profiling application: ../../../../CUDA/bin/add_two_matrix
==8014== Profiling result:
==8014== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   114141355   114141355   114141355   114141355

==8014== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.03%      12.03%      12.03%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.59%       2.59%       2.59%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.67%      73.67%      73.67%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.20%      11.20%      11.20%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.235196    0.235196    0.235196
          1                               inst_issued                          Instructions Issued    26803939    26803939    26803939
          1                                       ipc                                 Executed IPC    0.234771    0.234771    0.234771

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.234771 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2555.68% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.93%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.929% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.94%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.934% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.007% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.03% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.59%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.67% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.20% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.67% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.20% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.235196 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.234771 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803939 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               114141355 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==8353== NVPROF is profiling process 8353, command: ../../../../CUDA/bin/add_two_matrix
==8353== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==8353== Profiling application: ../../../../CUDA/bin/add_two_matrix
==8353== Profiling result:
==8353== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105782030   105782030   105782030   105782030

==8353== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.33%      12.33%      12.33%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.68%       2.68%       2.68%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.23%      73.23%      73.23%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.22%      11.22%      11.22%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253215    0.253215    0.253215
          1                               inst_issued                          Instructions Issued    26803631    26803631    26803631
          1                                       ipc                                 Executed IPC    0.253324    0.253324    0.253324

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.253324 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2368.51% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          15.34% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.34% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          84.52% ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.52% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.33% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.68%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.23% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.22% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.23% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.22% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.253215 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253324 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803631 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               105782030 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==8666== NVPROF is profiling process 8666, command: ../../../../CUDA/bin/add_two_matrix
==8666== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==8666== Profiling application: ../../../../CUDA/bin/add_two_matrix
==8666== Profiling result:
==8666== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105953305   105953305   105953305   105953305

==8666== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.29%      12.29%      12.29%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.26%      73.26%      73.26%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.28%      11.28%      11.28%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252979    0.252979    0.252979
          1                               inst_issued                          Instructions Issued    26804000    26804000    26804000
          1                                       ipc                                 Executed IPC    0.253488    0.253488    0.253488
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==8711== NVPROF is profiling process 8711, command: ../../../../CUDA/bin/add_two_matrix
==8711== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==8711== Profiling application: ../../../../CUDA/bin/add_two_matrix
==8711== Profiling result:
==8711== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116788797   116788797   116788797   116788797

==8711== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.07%      12.07%      12.07%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.70%      73.70%      73.70%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.12%      11.12%      11.12%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229861    0.229861    0.229861
          1                               inst_issued                          Instructions Issued    26804214    26804214    26804214
          1                                       ipc                                 Executed IPC    0.229449    0.229449    0.229449
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==8766== NVPROF is profiling process 8766, command: ../../../../CUDA/bin/add_two_matrix
==8766== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==8766== Profiling application: ../../../../CUDA/bin/add_two_matrix
==8766== Profiling result:
==8766== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116266362   116266362   116266362   116266362

==8766== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.89%      11.89%      11.89%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.93%      73.93%      73.93%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.08%      11.08%      11.08%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.230535    0.230535    0.230535
          1                               inst_issued                          Instructions Issued    26803436    26803436    26803436
          1                                       ipc                                 Executed IPC    0.229425    0.229425    0.229425

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.229425 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2615.23% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.8%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.797% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          85.08%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               85.064% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.019% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.17%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        11.89% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.61%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.93% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.08% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.230535 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.229425 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803436 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               116266362 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==9124== NVPROF is profiling process 9124, command: ../../../../CUDA/bin/add_two_matrix
==9124== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==9124== Profiling application: ../../../../CUDA/bin/add_two_matrix
==9124== Profiling result:
==9124== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116129975   116129975   116129975   116129975

==9124== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      11.99%      11.99%      11.99%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.53%       2.53%       2.53%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      74.06%      74.06%      74.06%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.92%      10.92%      10.92%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.230806    0.230806    0.230806
          1                               inst_issued                          Instructions Issued    26803550    26803550    26803550
          1                                       ipc                                 Executed IPC    0.229251    0.229251    0.229251
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==10184== NVPROF is profiling process 10184, command: ../../../../CUDA/bin/add_two_matrix
==10184== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==10184== Profiling application: ../../../../CUDA/bin/add_two_matrix
==10184== Profiling result:
==10184== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105713088   105713088   105713088   105713088

==10184== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.11%      12.11%      12.11%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.54%       2.54%       2.54%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.60%      73.60%      73.60%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.21%      11.21%      11.21%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.253553    0.253553    0.253553
          1                               inst_issued                          Instructions Issued    26803165    26803165    26803165
          1                                       ipc                                 Executed IPC    0.253489    0.253489    0.253489

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.253489 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2366.97% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          14.98% ║
			║                                           ║
			║ IPC DEGRADATION (%):               14.98% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.88%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.879% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.001% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.11% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.54%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.60% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.21% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.253553 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253489 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803165 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               105713088 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==10487== NVPROF is profiling process 10487, command: ../../../../CUDA/bin/add_two_matrix
==10487== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==10487== Profiling application: ../../../../CUDA/bin/add_two_matrix
==10487== Profiling result:
==10487== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106323512   106323512   106323512   106323512

==10487== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.28%      12.28%      12.28%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.71%       2.71%       2.71%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.31%      73.31%      73.31%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252108    0.252108    0.252108
          1                               inst_issued                          Instructions Issued    26805029    26805029    26805029
          1                                       ipc                                 Executed IPC    0.251498    0.251498    0.251498

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.251498 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2385.7% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          15.32%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               15.318% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.55%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.541% ║
			║                                            ║
			╚════════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==10765== NVPROF is profiling process 10765, command: ../../../../CUDA/bin/add_two_matrix
==10765== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==10765== Profiling application: ../../../../CUDA/bin/add_two_matrix
==10765== Profiling result:
==10765== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116427999   116427999   116427999   116427999

==10765== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.03%      12.03%      12.03%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.72%      73.72%      73.72%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.09%      11.09%      11.09%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.230227    0.230227    0.230227
          1                               inst_issued                          Instructions Issued    26804834    26804834    26804834
          1                                       ipc                                 Executed IPC    0.229347    0.229347    0.229347

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.229347 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2616.12% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.99%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.988% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.88%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.867% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==11808== NVPROF is profiling process 11808, command: ../../../../CUDA/bin/add_two_matrix
==11808== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==11808== Profiling application: ../../../../CUDA/bin/add_two_matrix
==11808== Profiling result:
==11808== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   105974845   105974845   105974845   105974845

==11808== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.25%      12.25%      12.25%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.69%       2.69%       2.69%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.31%      73.31%      73.31%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.20%      11.20%      11.20%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252796    0.252796    0.252796
          1                               inst_issued                          Instructions Issued    26803194    26803194    26803194
          1                                       ipc                                 Executed IPC    0.252863    0.252863    0.252863
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.252863 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2372.83% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==2994== NVPROF is profiling process 2994, command: ../../../../CUDA/bin/add_two_matrix
==2994== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2994== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==2994== Profiling result:
==2994== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==2994== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052459    0.052459    0.052459
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==11945== NVPROF is profiling process 11945, command: ../../../../CUDA/bin/add_two_matrix
==11945== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==11945== Profiling application: ../../../../CUDA/bin/add_two_matrix
==11945== Profiling result:
==11945== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   117259022   117259022   117259022   117259022

==11945== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.09%      12.09%      12.09%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.57%       2.57%       2.57%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.71%      73.71%      73.71%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.14%      11.14%      11.14%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.228583    0.228583    0.228583
          1                               inst_issued                          Instructions Issued    26803389    26803389    26803389
          1                                       ipc                                 Executed IPC    0.229669    0.229669    0.229669
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.229669 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2612.46% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==12100== NVPROF is profiling process 12100, command: ../../../../CUDA/bin/add_two_matrix
==12100== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==12100== Profiling application: ../../../../CUDA/bin/add_two_matrix
==12100== Profiling result:
==12100== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116828355   116828355   116828355   116828355

==12100== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.09%      12.09%      12.09%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.52%       2.52%       2.52%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.66%      73.66%      73.66%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.23%      11.23%      11.23%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229432    0.229432    0.229432
          1                               inst_issued                          Instructions Issued    26804157    26804157    26804157
          1                                       ipc                                 Executed IPC    0.229979    0.229979    0.229979

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.229979 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2608.93% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3307== NVPROF is profiling process 3307, command: ../../../../CUDA/bin/add_two_matrix
==3307== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3307== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3307== Profiling result:
==3307== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3307== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.050740    0.050740    0.050740
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.							╔═══════════════════════════════════════╗
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==12249== NVPROF is profiling process 12249, command: ../../../../CUDA/bin/add_two_matrix
==12249== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==12249== Profiling application: ../../../../CUDA/bin/add_two_matrix
==12249== Profiling result:
==12249== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116936335   116936335   116936335   116936335

==12249== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.04%      12.04%      12.04%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.71%      73.71%      73.71%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.12%      11.12%      11.12%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229504    0.229504    0.229504
          1                               inst_issued                          Instructions Issued    26803862    26803862    26803862
          1                                       ipc                                 Executed IPC    0.229160    0.229160    0.229160

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.22916 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2618.26% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3372== NVPROF is profiling process 3372, command: ../../../../CUDA/bin/add_two_matrix
==3372== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3372== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3372== Profiling result:
==3372== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3372== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051502    0.051502    0.051502
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==12563== NVPROF is profiling process 12563, command: ../../../../CUDA/bin/add_two_matrix
==12563== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==12563== Profiling application: ../../../../CUDA/bin/add_two_matrix
==12563== Profiling result:
==12563== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   114342164   114342164   114342164   114342164

==12563== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.06%      12.06%      12.06%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.56%       2.56%       2.56%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.71%      73.71%      73.71%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.16%      11.16%      11.16%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.234449    0.234449    0.234449
          1                               inst_issued                          Instructions Issued    26804266    26804266    26804266
          1                                       ipc                                 Executed IPC    0.234359    0.234359    0.234359
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.234359 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2560.17% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
=======
			║ STALLS, on the total (%):          14.92% ║
			║                                           ║
			║ IPC DEGRADATION (%):               14.92% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3690== NVPROF is profiling process 3690, command: ../../../../CUDA/bin/add_two_matrix
==3690== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3690== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3690== Profiling result:
==3690== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3690== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052747    0.052747    0.052747
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==12787== NVPROF is profiling process 12787, command: ../../../../CUDA/bin/add_two_matrix
==12787== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==12787== Profiling application: ../../../../CUDA/bin/add_two_matrix
==12787== Profiling result:
==12787== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   114326996   114326996   114326996   114326996

==12787== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.04%      12.04%      12.04%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.59%       2.59%       2.59%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.70%      73.70%      73.70%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.16%      11.16%      11.16%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.234633    0.234633    0.234633
          1                               inst_issued                          Instructions Issued    26804264    26804264    26804264
          1                                       ipc                                 Executed IPC    0.234390    0.234390    0.234390

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.23439 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2559.84% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝
=======
			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          14.93%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               14.929% ║
			║                                            ║
			╚════════════════════════════════════════════╝
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
<<<<<<< HEAD
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
=======
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==13001== NVPROF is profiling process 13001, command: ../../../../CUDA/bin/add_two_matrix
==13001== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==13001== Profiling application: ../../../../CUDA/bin/add_two_matrix
==13001== Profiling result:
==13001== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116599262   116599262   116599262   116599262

==13001== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.11%      12.11%      12.11%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.61%       2.61%       2.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.67%      73.67%      73.67%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.11%      11.11%      11.11%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229815    0.229815    0.229815
          1                               inst_issued                          Instructions Issued    26804493    26804493    26804493
          1                                       ipc                                 Executed IPC    0.229822    0.229822    0.229822

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.229822 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2610.72% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          15.02% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.02% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4014== NVPROF is profiling process 4014, command: ../../../../CUDA/bin/add_two_matrix
==4014== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4014== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4014== Profiling result:
==4014== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4014== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.028674    0.028674    0.028674
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==13194== NVPROF is profiling process 13194, command: ../../../../CUDA/bin/add_two_matrix
==13194== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==13194== Profiling application: ../../../../CUDA/bin/add_two_matrix
==13194== Profiling result:
==13194== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   116558271   116558271   116558271   116558271

==13194== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.17%       0.17%       0.17%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.15%      12.15%      12.15%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.54%       2.54%       2.54%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.64%      73.64%      73.64%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.18%      11.18%      11.18%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.229964    0.229964    0.229964
          1                               inst_issued                          Instructions Issued    26804161    26804161    26804161
          1                                       ipc                                 Executed IPC    0.230191    0.230191    0.230191
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.230191 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2606.53% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
=======
			║ STALLS, on the total (%):          14.99% ║
			║                                           ║
			║ IPC DEGRADATION (%):               14.99% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
			║ STALLS, on the total (%):          84.89% ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.89% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4327== NVPROF is profiling process 4327, command: ../../../../CUDA/bin/add_two_matrix
==4327== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4327== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4327== Profiling result:
==4327== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4327== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052747    0.052747    0.052747
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==13484== NVPROF is profiling process 13484, command: ../../../../CUDA/bin/add_two_matrix
==13484== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==13484== Profiling application: ../../../../CUDA/bin/add_two_matrix
==13484== Profiling result:
==13484== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106001224   106001224   106001224   106001224

==13484== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.17%      12.17%      12.17%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.32%      73.32%      73.32%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.31%      11.31%      11.31%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252867    0.252867    0.252867
          1                               inst_issued                          Instructions Issued    26804161    26804161    26804161
          1                                       ipc                                 Executed IPC    0.252167    0.252167    0.252167
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.252167 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2379.38% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝
=======
			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          15.16%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               15.158% ║
			║                                            ║
			╚════════════════════════════════════════════╝
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
=======
			║ STALLS, on the total (%):          84.7%  ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.69% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4644== NVPROF is profiling process 4644, command: ../../../../CUDA/bin/add_two_matrix
==4644== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4644== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4644== Profiling result:
==4644== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4644== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.32%      11.32%      11.32%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.88%      24.88%      24.88%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.12%      11.12%      11.12%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051337    0.051337    0.051337
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==13761== NVPROF is profiling process 13761, command: ../../../../CUDA/bin/add_two_matrix
==13761== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==13761== Profiling application: ../../../../CUDA/bin/add_two_matrix
==13761== Profiling result:
==13761== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106281832   106281832   106281832   106281832

==13761== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.33%      12.33%      12.33%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.70%       2.70%       2.70%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.26%      73.26%      73.26%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252204    0.252204    0.252204
          1                               inst_issued                          Instructions Issued    26804693    26804693    26804693
          1                                       ipc                                 Executed IPC    0.252078    0.252078    0.252078
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.252078 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2380.22% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          47.32% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.32% ║
=======
			║ STALLS, on the total (%):          15.36% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.36% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


<<<<<<< HEAD
							╔═══════════════════════════════════════╗
=======
			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.5%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.498% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

			╔═══════════════════════════════════════════╗
			║ BACK_END.MEMORY_BOUND RESULTS             ║
			║ -----------------------------             ║
			║                                           ║
			║ STALLS, on the total (%):          84.44% ║
			║                                           ║
			║ IPC DEGRADATION (%):               71.35% ║
			║                                           ║
			╚═══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4912== NVPROF is profiling process 4912, command: ../../../../CUDA/bin/add_two_matrix
==4912== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4912== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4912== Profiling result:
==4912== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4912== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051613    0.051613    0.051613
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==14109== NVPROF is profiling process 14109, command: ../../../../CUDA/bin/add_two_matrix
==14109== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==14109== Profiling application: ../../../../CUDA/bin/add_two_matrix
==14109== Profiling result:
==14109== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   108414534   108414534   108414534   108414534

==14109== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.18%       0.18%       0.18%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.09%      12.09%      12.09%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.30%      73.30%      73.30%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.43%      11.43%      11.43%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.247233    0.247233    0.247233
          1                               inst_issued                          Instructions Issued    26803614    26803614    26803614
          1                                       ipc                                 Executed IPC    0.246161    0.246161    0.246161
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.246161 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2437.43% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝
=======
			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          15.07%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               15.067% ║
			║                                            ║
			╚════════════════════════════════════════════╝
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


<<<<<<< HEAD
			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
=======
			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          84.8%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               84.784% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

			╔════════════════════════════════════════════╗
			║ BACK_END.MEMORY_BOUND RESULTS              ║
			║ -----------------------------              ║
			║                                            ║
			║ STALLS, on the total (%):          84.74%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               71.846% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK_END.CORE_BOUND: C_B Description

			╔═══════════════════════════════════════════╗
			║ BACK_END.CORE_BOUND RESULTS               ║
			║ ---------------------------               ║
			║                                           ║
			║ STALLS, on the total (%):          0.06%  ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.051% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

<<<<<<< HEAD
			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
=======
			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.019% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.18%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.09% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.66%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.30% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.43% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.30% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.43% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.247233 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.246161 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803614 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               108414534 
			-------------------------------------------------------------------------------------------------------

>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
<<<<<<< HEAD
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==5282== NVPROF is profiling process 5282, command: ../../../../CUDA/bin/add_two_matrix
==5282== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==5282== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==5282== Profiling result:
==5282== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==5282== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052574    0.052574    0.052574
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991
=======
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==14742== NVPROF is profiling process 14742, command: ../../../../CUDA/bin/add_two_matrix
==14742== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==14742== Profiling application: ../../../../CUDA/bin/add_two_matrix
==14742== Profiling result:
==14742== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch      382816      382816      382816      382816
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   106020186   106020186   106020186   106020186

==14742== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "GeForce GTX 1070 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.19%       0.19%       0.19%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      12.30%      12.30%      12.30%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.66%       2.66%       2.66%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      73.17%      73.17%      73.17%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.01%       0.01%       0.01%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.34%      11.34%      11.34%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.252162    0.252162    0.252162
          1                               inst_issued                          Instructions Issued    26803657    26803657    26803657
          1                                       ipc                                 Executed IPC    0.252755    0.252755    0.252755
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
<<<<<<< HEAD
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
=======
			║ IPC OBTAINED: 0.252755 | MAXIMUM POSSIBLE IPC: 6.0 ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

<<<<<<< HEAD
As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
=======
As you can see, the IPC obtanied it is 2373.84% smaller than you could get. This lower IPC is due to STALLS in the different 
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
=======
			║ STALLS, on the total (%):          15.29% ║
			║                                           ║
			║ IPC DEGRADATION (%):               15.29% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
<<<<<<< HEAD
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
=======
			║ STALLS, on the total (%):          84.58% ║
			║                                           ║
			║ IPC DEGRADATION (%):               84.58% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK_END.MEMORY_BOUND: M_B Description

			╔════════════════════════════════════════════╗
			║ BACK_END.MEMORY_BOUND RESULTS              ║
			║ -----------------------------              ║
			║                                            ║
			║ STALLS, on the total (%):          84.52%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               71.487% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK_END.CORE_BOUND: C_B Description

			╔═══════════════════════════════════════════╗
			║ BACK_END.CORE_BOUND RESULTS               ║
			║ ---------------------------               ║
			║                                           ║
			║ STALLS, on the total (%):          0.06%  ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.051% ║
>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
<<<<<<< HEAD
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
=======
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.19%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        12.30% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.66%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.14%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.17% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.34% 
			-------------------------------------------------------------------------------------------------------

- BACK_END.CORE_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			-------------------------------------------------------------------------------------------------------

- BACK_END.MEMORY_BOUND RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                73.17% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.01%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.34% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.252162 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               382816 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.252755 
			-------------------------------------------------------------------------------------------------------

- EXTRA_MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               26803657 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               106020186 
			-------------------------------------------------------------------------------------------------------

>>>>>>> e6c4273bdfa2f5e7a61463c6237948da7a962a74
