							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Prieto (UC) <pablo.prieto@unican.es>, Pablo Abad (UC) <pablo.abad@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         Open Source                                                                        ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16037== NVPROF is profiling process 16037, command: ../../../../CUDA/bin/add_two_matrix
==16037== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16037== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16037== Profiling result:
==16037== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144517421   144517421   144517421   144517421

==16037== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.38%      27.38%      27.38%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.52%       2.52%       2.52%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.37%      51.37%      51.37%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.32%      18.32%      18.32%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196224    0.196224    0.196224
          1                               inst_issued                          Instructions Issued    28332470    28332470    28332470
          1                                       ipc                                 Executed IPC    0.196021    0.196021    0.196021

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║                                                    ║
			║ IPC OBTAINED: 0.196021 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3060.9% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.26% ║
			║                                           ║
			║ IPC DEGRADATION (%):               29.27% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.73% ║
			║                                           ║
			║ IPC DEGRADATION (%):               67.45% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.003% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16355== NVPROF is profiling process 16355, command: ../../../../CUDA/bin/add_two_matrix
==16355== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16355== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16355== Profiling result:
==16355== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144600830   144600830   144600830   144600830

==16355== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.32%       0.32%       0.32%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      31.44%      31.44%      31.44%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.75%       1.75%       1.75%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.14%       0.14%       0.14%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      54.60%      54.60%      54.60%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.69%      11.69%      11.69%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.195682    0.195682    0.195682
          1                               inst_issued                          Instructions Issued    28332396    28332396    28332396
          1                                       ipc                                 Executed IPC    0.195907    0.195907    0.195907

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║                                                    ║
			║ IPC OBTAINED: 0.195907 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3062.68% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          33.65%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               32.551% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          66.34%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               64.174% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16672== NVPROF is profiling process 16672, command: ../../../../CUDA/bin/add_two_matrix
==16672== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16672== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16672== Profiling result:
==16672== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113174085   113174085   113174085   113174085

==16672== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.19%      26.19%      26.19%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.69%       1.69%       1.69%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      60.36%      60.36%      60.36%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.26%      11.26%      11.26%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.226832    0.226832    0.226832
          1                               inst_issued                          Instructions Issued    28331989    28331989    28331989
          1                                       ipc                                 Executed IPC    0.250308    0.250308    0.250308

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.250308 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2397.05% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          28.31%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               27.129% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          71.67% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==16990== NVPROF is profiling process 16990, command: ../../../../CUDA/bin/add_two_matrix
==16990== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==16990== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==16990== Profiling result:
==16990== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144340559   144340559   144340559   144340559

==16990== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      30.14%      30.14%      30.14%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.63%       1.63%       1.63%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      56.59%      56.59%      56.59%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.15%      11.15%      11.15%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196249    0.196249    0.196249
          1                               inst_issued                          Instructions Issued    28332603    28332603    28332603
          1                                       ipc                                 Executed IPC    0.196261    0.196261    0.196261

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196261 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3057.15% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          32.2%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               31.147% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          67.79%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               65.573% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17328== NVPROF is profiling process 17328, command: ../../../../CUDA/bin/add_two_matrix
==17328== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17328== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17328== Profiling result:
==17328== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144594172   144594172   144594172   144594172

==17328== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.28%       0.28%       0.28%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      25.93%      25.93%      25.93%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.62%       2.62%       2.62%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.98%      51.98%      51.98%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      19.05%      19.05%      19.05%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.208637    0.208637    0.208637
          1                               inst_issued                          Instructions Issued    28332187    28332187    28332187
          1                                       ipc                                 Executed IPC    0.195916    0.195916    0.195916

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.195916 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3062.54% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          28.92%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               27.914% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          71.07%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               68.599% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.212% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17641== NVPROF is profiling process 17641, command: ../../../../CUDA/bin/add_two_matrix
==17641== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17641== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17641== Profiling result:
==17641== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   124383930   124383930   124383930   124383930

==17641== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.34%       0.34%       0.34%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      33.24%      33.24%      33.24%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.84%       1.84%       1.84%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.00%      52.00%      52.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      12.37%      12.37%      12.37%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197196    0.197196    0.197196
          1                               inst_issued                          Instructions Issued    28332267    28332267    28332267
          1                                       ipc                                 Executed IPC    0.227750    0.227750    0.227750

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.22775 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2634.47% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          35.57% ║
			║                                           ║
			║ IPC DEGRADATION (%):               34.22% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          64.42%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               61.975% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==17954== NVPROF is profiling process 17954, command: ../../../../CUDA/bin/add_two_matrix
==17954== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==17954== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==17954== Profiling result:
==17954== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144329109   144329109   144329109   144329109

==17954== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.30%      26.30%      26.30%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.48%       2.48%       2.48%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.84%      52.84%      52.84%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      17.98%      17.98%      17.98%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197261    0.197261    0.197261
          1                               inst_issued                          Instructions Issued    28332385    28332385    28332385
          1                                       ipc                                 Executed IPC    0.196276    0.196276    0.196276

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196276 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3056.92% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          29.14%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               28.182% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          70.86% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.53% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.016% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.27%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        26.30% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.48%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                52.84% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             17.98% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.197261 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.196276 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332385 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               144329109 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18273== NVPROF is profiling process 18273, command: ../../../../CUDA/bin/add_two_matrix
==18273== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18273== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18273== Profiling result:
==18273== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   113042117   113042117   113042117   113042117

==18273== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.36%       0.36%       0.36%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      35.29%      35.29%      35.29%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.95%       1.95%       1.95%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.15%       0.15%       0.15%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      49.21%      49.21%      49.21%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.06%       0.06%       0.06%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      12.98%      12.98%      12.98%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196515    0.196515    0.196515
          1                               inst_issued                          Instructions Issued    28332272    28332272    28332272
          1                                       ipc                                 Executed IPC    0.250600    0.250600    0.250600

The results have been obtained correctly. General results of IPC are the following:

			╔══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.2506 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2394.25% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          37.75%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               36.173% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          62.25% ║
			║                                           ║
			║ IPC DEGRADATION (%):               59.65% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.36%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        35.29% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.95%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.15%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                49.21% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.06%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             12.98% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196515 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.250600 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332272 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               113042117 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18600== NVPROF is profiling process 18600, command: ../../../../CUDA/bin/add_two_matrix
==18600== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18600== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18600== Profiling result:
==18600== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   112597227   112597227   112597227   112597227

==18600== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.29%      28.29%      28.29%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.65%       1.65%       1.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.66%      58.66%      58.66%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.92%      10.92%      10.92%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.206927    0.206927    0.206927
          1                               inst_issued                          Instructions Issued    28332167    28332167    28332167
          1                                       ipc                                 Executed IPC    0.251590    0.251590    0.251590

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.25159 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2384.83% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.37% ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.0%   ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.63% ║
			║                                           ║
			║ IPC DEGRADATION (%):               0.0%   ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        28.29% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.65%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.66% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             10.92% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.206927 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.251590 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332167 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               112597227 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==18828== NVPROF is profiling process 18828, command: ../../../../CUDA/bin/add_two_matrix
==18828== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==18828== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==18828== Profiling result:
==18828== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   144046329   144046329   144046329   144046329

==18828== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.92%      29.92%      29.92%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.65%       1.65%       1.65%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      56.77%      56.77%      56.77%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.18%      11.18%      11.18%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196879    0.196879    0.196879
          1                               inst_issued                          Instructions Issued    28332325    28332325    28332325
          1                                       ipc                                 Executed IPC    0.196662    0.196662    0.196662

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.196662 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3050.92% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          32.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               31.999% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          68.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               67.997% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.004% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        29.92% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.65%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                56.77% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.18% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196879 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.196662 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332325 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               144046329 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19143== NVPROF is profiling process 19143, command: ../../../../CUDA/bin/add_two_matrix
==19143== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19143== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19143== Profiling result:
==19143== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   143210090   143210090   143210090   143210090

==19143== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.27%       0.27%       0.27%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      26.35%      26.35%      26.35%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.51%       2.51%       2.51%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      52.57%      52.57%      52.57%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.17%      18.17%      18.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.196907    0.196907    0.196907
          1                               inst_issued                          Instructions Issued    28332468    28332468    28332468
          1                                       ipc                                 Executed IPC    0.197810    0.197810    0.197810

The results have been obtained correctly. General results of IPC are the following:

			╔═══════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.19781 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚═══════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC' 
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3033.21% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          29.22% ║
			║                                           ║
			║ IPC DEGRADATION (%):               29.22% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          70.78% ║
			║                                           ║
			║ IPC DEGRADATION (%):               70.78% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.27%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        26.35% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.51%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                52.57% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             18.17% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.196907 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.197810 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332468 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               143210090 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19456== NVPROF is profiling process 19456, command: ../../../../CUDA/bin/add_two_matrix
==19456== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19456== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19456== Profiling result:
==19456== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   112630399   112630399   112630399   112630399

==19456== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.05%      29.05%      29.05%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.61%       1.61%       1.61%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.10%      58.10%      58.10%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.77%      10.77%      10.77%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.197742    0.197742    0.197742
          1                               inst_issued                          Instructions Issued    28332398    28332398    28332398
          1                                       ipc                                 Executed IPC    0.251516    0.251516    0.251516

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.251516 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2385.53% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          31.09% ║
			║                                           ║
			║ IPC DEGRADATION (%):               31.09% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          68.92% ║
			║                                           ║
			║ IPC DEGRADATION (%):               68.92% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        29.05% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.61%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.10% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             10.77% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.197742 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.251516 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332398 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               112630399 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==19768== NVPROF is profiling process 19768, command: ../../../../CUDA/bin/add_two_matrix
==19768== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==19768== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==19768== Profiling result:
==19768== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   111577968   111577968   111577968   111577968

==19768== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.30%       0.30%       0.30%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.27%      28.27%      28.27%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.64%       1.64%       1.64%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.13%       0.13%       0.13%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.61%      58.61%      58.61%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.05%       0.05%       0.05%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.00%      11.00%      11.00%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.209046    0.209046    0.209046
          1                               inst_issued                          Instructions Issued    28332275    28332275    28332275
          1                                       ipc                                 Executed IPC    0.253889    0.253889    0.253889

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.253889 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2363.24% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.34% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.34% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.66% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.66% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.30%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        28.27% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       1.64%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.13%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                58.61% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.05%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             11.00% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.209046 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.253889 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332275 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               111577968 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    True                                ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==20079== NVPROF is profiling process 20079, command: ../../../../CUDA/bin/add_two_matrix
==20079== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==20079== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==20079== Profiling result:
==20079== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   143354493   143354493   143354493   143354493

==20079== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.28%       0.28%       0.28%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.10%      27.10%      27.10%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       2.53%       2.53%       2.53%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.09%       0.09%       0.09%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      51.20%      51.20%      51.20%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      18.75%      18.75%      18.75%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.198023    0.198023    0.198023
          1                               inst_issued                          Instructions Issued    28332617    28332617    28332617
          1                                       ipc                                 Executed IPC    0.197611    0.197611    0.197611

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.197611 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3036.27% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          30.0%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               29.998% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          69.99%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               69.985% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: D Description

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.007% ║
			║                                          ║
			╚══════════════════════════════════════════╝
List of counters/metrics measured according to the part.

- FRONT-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)          0.28%  
			stall_exec_dependency                         Issue Stall Reasons (Execution Dependency)        27.10% 
			stall_sync                                    Issue Stall Reasons (Synchronization)             0.00%  
			stall_other                                   Issue Stall Reasons (Other)                       2.53%  
			stall_not_selected                            Issue Stall Reasons (Not Selected)                0.09%  
			-------------------------------------------------------------------------------------------------------

- BACK-END RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			stall_memory_dependency                       Issue Stall Reasons (Data Request)                51.20% 
			stall_constant_memory_dependency              Issue Stall Reasons (Immediate constant)          0.00%  
			stall_pipe_busy                               Issue Stall Reasons (Pipe Busy)                   0.04%  
			stall_memory_throttle                         Issue Stall Reasons (Memory Throttle)             18.75% 
			-------------------------------------------------------------------------------------------------------

- DIVERGENCE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			branch_efficiency                             Branch Efficiency                                 100.00% 
			warp_execution_efficiency                     Warp Execution Efficiency                         100.00% 
			issued_ipc                                    Issued IPC                                        0.198023 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			branch                                        -                                               1531264 
			divergent_branch                              -                                               0      
			-------------------------------------------------------------------------------------------------------

- RETIRE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			ipc                                           Executed IPC                                      0.197611 
			-------------------------------------------------------------------------------------------------------

- EXTRA-MEASURE RESULTS:
			-------------------------------------------------------------------------------------------------------
			Metric Name                                   Metric Description                                Value 
			-------------------------------------------------------------------------------------------------------
			inst_issued                                   Instructions Issued                               28332617 
			-------------------------------------------------------------------------------------------------------

			-------------------------------------------------------------------------------------------------------
			Event Name                                    Event Description                               Value 
			-------------------------------------------------------------------------------------------------------
			active_cycles                                 -                                               143354493 
			-------------------------------------------------------------------------------------------------------

							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21000== NVPROF is profiling process 21000, command: ../../../../CUDA/bin/add_two_matrix
==21000== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21000== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21000== Profiling result:
==21000== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   168328766   168328766   168328766   168328766

==21000== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.09%      29.09%      29.09%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.31%       1.31%       1.31%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.18%      58.18%      58.18%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.04%      11.04%      11.04%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.160541    0.160541    0.160541
          1                               inst_issued                          Instructions Issued    28333221    28333221    28333221
          1                                       ipc                                 Executed IPC    0.168292    0.168292    0.168292

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.168292 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3565.23% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.74% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.74% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.26% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.26% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: D Description

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21322== NVPROF is profiling process 21322, command: ../../../../CUDA/bin/add_two_matrix
==21322== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21322== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21322== Profiling result:
==21322== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   176607376   176607376   176607376   176607376

==21322== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.90%      28.90%      28.90%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.28%       1.28%       1.28%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.45%      58.45%      58.45%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.99%      10.99%      10.99%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.159628    0.159628    0.159628
          1                               inst_issued                          Instructions Issued    28333113    28333113    28333113
          1                                       ipc                                 Executed IPC    0.160403    0.160403    0.160403

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.160403 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3740.58% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: FrontEnd bound analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.52% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.52% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: BackEnd bound analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.48% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.48% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: Divergece analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Helpers:         Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21635== NVPROF is profiling process 21635, command: ../../../../CUDA/bin/add_two_matrix
==21635== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21635== Profiling application: ../../../../CUDA/bin/add_two_matrix
==21635== NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
Profiling result:
==21635== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   174890188   174890188   174890188   174890188

==21635== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      29.03%      29.03%      29.03%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.31%       1.31%       1.31%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.38%      58.38%      58.38%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      10.90%      10.90%      10.90%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.161852    0.161852    0.161852
          1                               inst_issued                          Instructions Issued    28332980    28332980    28332980
          1                                       ipc                                 Executed IPC    0.161978    0.161978    0.161978

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.161978 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3704.21% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.32% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.32% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==21956== NVPROF is profiling process 21956, command: ../../../../CUDA/bin/add_two_matrix
==21956== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==21956== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==21956== Profiling result:
==21956== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   174527602   174527602   174527602   174527602

==21956== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      27.96%      27.96%      27.96%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.34%       1.34%       1.34%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.11%       0.11%       0.11%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      59.14%      59.14%      59.14%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.17%      11.17%      11.17%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.170768    0.170768    0.170768
          1                               inst_issued                          Instructions Issued    28332946    28332946    28332946
          1                                       ipc                                 Executed IPC    0.162315    0.162315    0.162315

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.162315 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3696.52% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          29.65%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               29.607% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          70.35%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               70.248% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.145% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==22522== NVPROF is profiling process 22522, command: ../../../../CUDA/bin/add_two_matrix
==22522== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==22522== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==22522== Profiling result:
==22522== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch     1531264     1531264     1531264     1531264
          1                          divergent_branch           0           0           0           0
          1                             active_cycles   139712275   139712275   139712275   139712275

==22522== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)       0.24%       0.24%       0.24%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      28.91%      28.91%      28.91%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)       1.32%       1.32%       1.32%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.10%       0.10%       0.10%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)      58.33%      58.33%      58.33%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)       0.00%       0.00%       0.00%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.04%       0.04%       0.04%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)      11.06%      11.06%      11.06%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.161019    0.161019    0.161019
          1                               inst_issued                          Instructions Issued    28332945    28332945    28332945
          1                                       ipc                                 Executed IPC    0.202762    0.202762    0.202762

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.202762 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 2959.13% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          30.57% ║
			║                                           ║
			║ IPC DEGRADATION (%):               30.57% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          69.43% ║
			║                                           ║
			║ IPC DEGRADATION (%):               69.43% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==23079== NVPROF is profiling process 23079, command: ../../../../CUDA/bin/add_two_matrix
==23079== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==23079== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==23079== Profiling result:
==23079== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==23079== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      10.91%      10.91%      10.91%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      23.99%      23.99%      23.99%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      14.29%      14.29%      14.29%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      50.29%      50.29%      50.29%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.51%       0.51%       0.51%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.211454    0.211454    0.211454
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔════════════════════════════════════════════╗
			║ FRONT-END RESULTS                          ║
			║ -----------------                          ║
			║                                            ║
			║ STALLS, on the total (%):          49.19%  ║
			║                                            ║
			║ IPC DEGRADATION (%):               48.899% ║
			║                                            ║
			╚════════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔════════════════════════════════════════════╗
			║ BACK-END RESULTS                           ║
			║ ----------------                           ║
			║                                            ║
			║ STALLS, on the total (%):          50.8%   ║
			║                                            ║
			║ IPC DEGRADATION (%):               50.499% ║
			║                                            ║
			╚════════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔══════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                       ║
			║ ------------------                       ║
			║                                          ║
			║ IPC DEGRADATION (%):              0.592% ║
			║                                          ║
			╚══════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==2674== NVPROF is profiling process 2674, command: ../../../../CUDA/bin/add_two_matrix
==2674== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2674== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==2674== Profiling result:
==2674== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==2674== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051118    0.051118    0.051118
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==2994== NVPROF is profiling process 2994, command: ../../../../CUDA/bin/add_two_matrix
==2994== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2994== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==2994== Profiling result:
==2994== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==2994== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052459    0.052459    0.052459
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3307== NVPROF is profiling process 3307, command: ../../../../CUDA/bin/add_two_matrix
==3307== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3307== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3307== Profiling result:
==3307== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3307== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.050740    0.050740    0.050740
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3372== NVPROF is profiling process 3372, command: ../../../../CUDA/bin/add_two_matrix
==3372== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3372== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3372== Profiling result:
==3372== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3372== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051502    0.051502    0.051502
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==3690== NVPROF is profiling process 3690, command: ../../../../CUDA/bin/add_two_matrix
==3690== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==3690== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==3690== Profiling result:
==3690== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==3690== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052747    0.052747    0.052747
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4014== NVPROF is profiling process 4014, command: ../../../../CUDA/bin/add_two_matrix
==4014== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4014== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4014== Profiling result:
==4014== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4014== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.028674    0.028674    0.028674
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4327== NVPROF is profiling process 4327, command: ../../../../CUDA/bin/add_two_matrix
==4327== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4327== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4327== Profiling result:
==4327== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4327== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052747    0.052747    0.052747
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4644== NVPROF is profiling process 4644, command: ../../../../CUDA/bin/add_two_matrix
==4644== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4644== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4644== Profiling result:
==4644== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4644== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.32%      11.32%      11.32%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.88%      24.88%      24.88%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.12%      11.12%      11.12%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051337    0.051337    0.051337
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.32% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.32% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==4912== NVPROF is profiling process 4912, command: ../../../../CUDA/bin/add_two_matrix
==4912== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4912== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==4912== Profiling result:
==4912== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==4912== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.051613    0.051613    0.051613
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     1                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
==5282== NVPROF is profiling process 5282, command: ../../../../CUDA/bin/add_two_matrix
==5282== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==5282== Profiling application: ../../../../CUDA/bin/add_two_matrix
NUMBLOCKS: 47852 THREADS_PER_BLOCK: 256
==5282== Profiling result:
==5282== Event result:
Invocations                                Event Name         Min         Max         Avg       Total
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                                    branch           8           8           8           8
          1                          divergent_branch           0           0           0           0
          1                             active_cycles         226         226         226         226

==5282== Metric result:
Invocations                               Metric Name                           Metric Description         Min         Max         Avg
Device "NVIDIA Tegra X2 (0)"
    Kernel: addMatrix(int*, int*, int*, int)
          1                          stall_inst_fetch     Issue Stall Reasons (Instructions Fetch)      11.42%      11.42%      11.42%
          1                     stall_exec_dependency   Issue Stall Reasons (Execution Dependency)      24.82%      24.82%      24.82%
          1                                stall_sync        Issue Stall Reasons (Synchronization)       0.00%       0.00%       0.00%
          1                               stall_other                  Issue Stall Reasons (Other)      11.09%      11.09%      11.09%
          1                        stall_not_selected           Issue Stall Reasons (Not Selected)       0.00%       0.00%       0.00%
          1                   stall_memory_dependency           Issue Stall Reasons (Data Request)       0.00%       0.00%       0.00%
          1          stall_constant_memory_dependency     Issue Stall Reasons (Immediate constant)      52.15%      52.15%      52.15%
          1                           stall_pipe_busy              Issue Stall Reasons (Pipe Busy)       0.00%       0.00%       0.00%
          1                     stall_memory_throttle        Issue Stall Reasons (Memory Throttle)       0.53%       0.53%       0.53%
          1                         branch_efficiency                            Branch Efficiency     100.00%     100.00%     100.00%
          1                 warp_execution_efficiency                    Warp Execution Efficiency     100.00%     100.00%     100.00%
          1                                issued_ipc                                   Issued IPC    0.052574    0.052574    0.052574
          1                               inst_issued                          Instructions Issued          48          48          48
          1                                       ipc                                 Executed IPC    0.176991    0.176991    0.176991

The results have been obtained correctly. General results of IPC are the following:

			╔════════════════════════════════════════════════════╗
			║ IPC OBTAINED: 0.176991 | MAXIMUM POSSIBLE IPC: 6.0 ║
			╚════════════════════════════════════════════════════╝

'IPC OBTAINED' is the IPC of the analyzed program (computed by scan tool) and 'MAXIMUM POSSIBLE IPC'
is the the maximum IPC your GPU can achieve. This is computed taking into account architectural concepts, such as the 
number of warp planners per SM, as well as the number of Dispatch units of each SM.    

As you can see, the IPC obtanied it is 3390.0% smaller than you could get. This lower IPC is due to STALLS in the different 
parts of the architecture and DIVERGENCE problems. We analyze them based on the level of the TopDown:


FRONT-END: It analyzes the parts of the GPU architecture where the FrontEnd produces bottlenecks, 
which leads to IPC losses. In this part, aspects related to the fetch of instructions
are analyzed, such as errors in the instruction cache or IPC losses due to thread synchronization.


			╔═══════════════════════════════════════════╗
			║ FRONT-END RESULTS                         ║
			║ -----------------                         ║
			║                                           ║
			║ STALLS, on the total (%):          47.33% ║
			║                                           ║
			║ IPC DEGRADATION (%):               47.33% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

BACK-END: It analyzes the parts of the GPU architecture where the BackEnd produces bottleneck, 
which leads to IPC losses. In this part, We analyze aspects related to the 'execution' part of 
the instructions, in which aspects such as limitations by functional units, memory limits, etc. 


			╔═══════════════════════════════════════════╗
			║ BACK-END RESULTS                          ║
			║ ----------------                          ║
			║                                           ║
			║ STALLS, on the total (%):          52.68% ║
			║                                           ║
			║ IPC DEGRADATION (%):               52.68% ║
			║                                           ║
			╚═══════════════════════════════════════════╝

DIVERGENCE: It analyzes the parts of the GPU architecture where the where divergence causes a loss of performance. 
This problem is caused when warps are not used correctly. This is caused for example when, for example, there are 
threads (of the same warp) that have to execute an instruction and others do not. In this case there are GPU cores 
that are not being used. Another worst case occurs when some threads of a warp have to execute one instruction and 
others another (if-else). In this case, twice as many cycles are necessary to execute, and in all cases part of the 
cores will not be used.

			╔════════════════════════════════════════╗
			║ DIVERGENCE RESULTS                     ║
			║ ------------------                     ║
			║                                        ║
			║ IPC DEGRADATION (%):              0.0% ║
			║                                        ║
			╚════════════════════════════════════════╝							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
							╔═══════════════════════════════════════╗
							║ TopDown Metholodgy over NVIDIA's GPUs ║
							╚═══════════════════════════════════════╝


Welcome to the ../src/topdown.py program where you can check the bottlenecks of your 
CUDA program running on NVIDIA GPUs. This analysis is carried out considering the architectural 
aspects of your GPU, in its different parts. The objective is to detect the bottlenecks in your 
program, which cause the IPC (Instructions per Cycle) to be drastically reduced.

Next, you can see general information about the program
╔═══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║ GENERAL INFORMATION                                                                                   ║
║ -------------------                                                                                   ║
║                                                                                                       ║
║ - Program Name:    topdown.py                                                                         ║
║ - Author:          Alvaro Saiz (UC)                                                                   ║
║ - Contact info:    asf174@alumnos.unican.es                                                           ║
║ - Company:         University Of Cantabria                                                            ║
║ - Place:           Santander, Cantabria, Kingdom of Spain                                             ║
║ - Teachers:        Pablo Abad (UC) <pablo.abad@unican.es>, Pablo Prieto (UC) <pablo.prieto@unican.es> ║
║ - Bugs Report:     asf174@alumnos.unican.es                                                           ║
║                                                                                                       ║
║ - Licence:         GNU GPL                                                                            ║
╚═══════════════════════════════════════════════════════════════════════════════════════════════════════╝

In accordance with what has been entered, the execution will be carried out following the following terms:
╔════════════════════════════════════════════════════════════╗
║ PROGRAM FEATURES                                           ║
║ ----------------                                           ║
║                                                            ║
║ - Execution Level:     2                                   ║
║ - Analyzed program:    ../../../../CUDA/bin/add_two_matrix ║
║ - Output File:         ../results/output.log               ║
║ - Long-Description:    False                               ║
╚════════════════════════════════════════════════════════════╝

Said that, according to the level entered by you, WE START THE ANALYSIS.
