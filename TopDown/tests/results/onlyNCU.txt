==PROF== Connected to process 45361 (/usr/bin/python3.6)
==PROF== Profiling "FillPhiloxRandomKernelLaunch" - 1: 0%
==WARNING== Backing up device memory in system memory. Kernel replay might be slow. Consider using application replay to avoid memory save-and-restore.
....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 2: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 3: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 4: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 5: 0%....50%....100% - 8 passes
==PROF== Profiling "FillPhiloxRandomKernelLaunch" - 6: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 7: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 8: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 9: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 10: 0%....50%....100% - 8 passes
==PROF== Profiling "FillPhiloxRandomKernelLaunch" - 11: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 12: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 13: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 14: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 15: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 16: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 17: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 18: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 19: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 20: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 21: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 22: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 23: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_128x32_nn" - 24: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 25: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 26: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 27: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 28: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 29: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 30: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 31: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 32: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 33: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 34: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 35: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 36: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 37: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 38: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 39: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 40: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 41: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 42: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 43: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 44: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 45: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 46: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 47: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 48: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 49: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 50: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 51: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 52: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 53: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 54: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 55: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 56: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 57: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 58: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 59: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceMax16ColumnsKernel" - 60: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 61: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 62: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 63: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 64: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 65: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 66: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 67: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 68: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 69: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 70: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 71: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 72: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 73: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 74: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 75: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 76: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 77: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 78: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 79: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 80: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 81: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 82: 0%....50%....100% - 8 passes
   1/1874 [..............................] - ETA: 235:05:53 - loss: 2.2809 - accuracy: 0.0938==PROF== Profiling "volta_sgemm_128x32_nn" - 83: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 84: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 85: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 86: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 87: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 88: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 89: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 90: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 91: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 92: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 93: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 94: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 95: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 96: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 97: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 98: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 99: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 100: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 101: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 102: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 103: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 104: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 105: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 106: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 107: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 108: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 109: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 110: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 111: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 112: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 113: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 114: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 115: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 116: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 117: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 118: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 119: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 120: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 121: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 122: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 123: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 124: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 125: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 126: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 127: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 128: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 129: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 130: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 131: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 132: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 133: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 134: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 135: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 136: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 137: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 138: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 139: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 140: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 141: 0%....50%....100% - 8 passes
   2/1874 [..............................] - ETA: 213:54:14 - loss: 2.2707 - accuracy: 0.1094==PROF== Profiling "volta_sgemm_128x32_nn" - 142: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 143: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 144: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 145: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 146: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 147: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 148: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 149: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 150: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 151: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 152: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 153: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 154: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 155: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 156: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 157: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 158: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 159: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 160: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 161: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 162: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 163: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 164: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 165: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 166: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 167: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 168: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 169: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 170: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 171: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 172: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 173: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 174: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 175: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 176: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 177: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 178: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 179: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 180: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 181: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 182: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 183: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 184: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 185: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 186: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 187: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 188: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 189: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 190: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 191: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 192: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 193: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 194: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 195: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 196: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 197: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 198: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 199: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 200: 0%....50%....100% - 8 passes
   3/1874 [..............................] - ETA: 212:19:03 - loss: 2.2728 - accuracy: 0.1076==PROF== Profiling "volta_sgemm_128x32_nn" - 201: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 202: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 203: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 204: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 205: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 206: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 207: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 208: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 209: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 210: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 211: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 212: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 213: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 214: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 215: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 216: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 217: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 218: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 219: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 220: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 221: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 222: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 223: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 224: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 225: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 226: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 227: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 228: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 229: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 230: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 231: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 232: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 233: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 234: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 235: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 236: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 237: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 238: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 239: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 240: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 241: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 242: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 243: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 244: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 245: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 246: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 247: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 248: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 249: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 250: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 251: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 252: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 253: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 254: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 255: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 256: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 257: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 258: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 259: 0%....50%....100% - 8 passes
   4/1874 [..............................] - ETA: 210:22:30 - loss: 2.2723 - accuracy: 0.1061==PROF== Profiling "volta_sgemm_128x32_nn" - 260: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 261: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 262: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 263: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 264: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 265: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 266: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 267: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 268: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 269: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 270: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 271: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 272: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 273: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 274: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 275: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 276: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 277: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 278: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 279: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 280: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 281: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 282: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 283: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 284: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 285: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 286: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 287: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 288: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 289: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 290: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 291: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 292: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 293: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 294: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 295: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 296: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 297: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 298: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 299: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 300: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 301: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 302: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 303: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 304: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 305: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 306: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 307: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 308: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 309: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 310: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 311: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 312: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 313: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 314: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 315: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 316: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 317: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 318: 0%....50%....100% - 8 passes
   5/1874 [..............................] - ETA: 210:38:58 - loss: 2.2703 - accuracy: 0.1061==PROF== Profiling "volta_sgemm_128x32_nn" - 319: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 320: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 321: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 322: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 323: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 324: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 325: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 326: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 327: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 328: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 329: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 330: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 331: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 332: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 333: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 334: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 335: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 336: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 337: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 338: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 339: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 340: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 341: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 342: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 343: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 344: 0%....50%....100% - 8 passes
==PROF== Profiling "BlockReduceKernel" - 345: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 346: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 347: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 348: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 349: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 350: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 351: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 352: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 353: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 354: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 355: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 356: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 357: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 358: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_tn" - 359: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 360: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 361: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 362: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_tn" - 363: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nt" - 364: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasGradNHWC_SharedAtomics" - 365: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 366: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 367: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 368: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x128_nt" - 369: 0%....50%....100% - 8 passes
==PROF== Profiling "ColumnReduceKernel" - 370: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 371: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 372: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 373: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 374: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 375: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 376: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 377: 0%....50%....100% - 8 passes
   6/1874 [..............................] - ETA: 210:18:17 - loss: 2.2638 - accuracy: 0.1136==PROF== Profiling "volta_sgemm_128x32_nn" - 378: 0%....50%....100% - 8 passes
==PROF== Profiling "splitKreduce_kernel" - 379: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 380: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 381: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 382: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 383: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 384: 0%....50%....100% - 8 passes
==PROF== Profiling "volta_sgemm_32x32_sliced1x4_nn" - 385: 0%....50%....100% - 8 passes
==PROF== Profiling "BiasNHWCKernel" - 386: 0%....50%....100% - 8 passes
==PROF== Profiling "RowReduceKernel" - 387: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow7functor15RowR..." - 388: 0%....50%....100% - 8 passes
==PROF== Profiling "_ZN10tensorflow88_GLOBAL__N__..." - 389: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 390: 0%....50%....100% - 8 passes
==PROF== Profiling "EigenMetaKernel" - 391: 0%....50%....==PROF== Received signal
==PROF== Trying to shutdown target application
 - 8 passes
==ERROR== Failed to profile kernel "EigenMetaKernel" in process 45361
==ERROR== An error occurred while trying to profile.
[45361] python3.6@127.0.0.1
  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(unsigned long long const*, unsigned long long const*, tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>), 2021-May-03 20:58:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,84
    SM Frequency                                                             cycle/usecond                         892,55
    Elapsed Cycles                                                                   cycle                          6.832
    Memory [%]                                                                           %                          23,33
    SOL DRAM                                                                             %                           0,74
    Duration                                                                       usecond                           7,65
    SOL L1/TEX Cache                                                                     %                          39,05
    SOL L2 Cache                                                                         %                          23,33
    SM Active Cycles                                                                 cycle                       4.636,56
    SM [%]                                                                               %                          36,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          92,55
    Achieved Active Warps Per SM                                                      warp                          29,61
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 20:58:22, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,27
    SM Frequency                                                             cycle/usecond                         811,18
    Elapsed Cycles                                                                   cycle                          2.700
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,33
    SOL L1/TEX Cache                                                                     %                          11,73
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,81
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,84
    Achieved Active Warps Per SM                                                      warp                          21,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:58:29, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,66
    SM Frequency                                                             cycle/usecond                         873,62
    Elapsed Cycles                                                                   cycle                          5.317
    Memory [%]                                                                           %                          42,85
    SOL DRAM                                                                             %                          42,85
    Duration                                                                       usecond                           6,08
    SOL L1/TEX Cache                                                                     %                          34,86
    SOL L2 Cache                                                                         %                          36,72
    SM Active Cycles                                                                 cycle                       3.300,78
    SM [%]                                                                               %                           7,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,62
    Achieved Active Warps Per SM                                                      warp                          27,72
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:58:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,84
    SM Frequency                                                             cycle/usecond                         888,99
    Elapsed Cycles                                                                   cycle                          5.384
    Memory [%]                                                                           %                          41,74
    SOL DRAM                                                                             %                          41,74
    Duration                                                                       usecond                           6,05
    SOL L1/TEX Cache                                                                     %                          34,44
    SOL L2 Cache                                                                         %                          36,28
    SM Active Cycles                                                                 cycle                       3.372,17
    SM [%]                                                                               %                           7,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,66
    Achieved Active Warps Per SM                                                      warp                          27,41
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:58:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,18
    SM Frequency                                                             cycle/usecond                         810,65
    Elapsed Cycles                                                                   cycle                          2.725
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          14,59
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          35,03
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          62,55
    Achieved Active Warps Per SM                                                      warp                          20,02
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(unsigned long long const*, unsigned long long const*, tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>), 2021-May-03 20:58:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,71
    SM Frequency                                                             cycle/usecond                         873,48
    Elapsed Cycles                                                                   cycle                          5.289
    Memory [%]                                                                           %                          12,41
    SOL DRAM                                                                             %                           0,35
    Duration                                                                       usecond                           6,05
    SOL L1/TEX Cache                                                                     %                          22,63
    SOL L2 Cache                                                                         %                          12,41
    SM Active Cycles                                                                 cycle                       2.362,86
    SM [%]                                                                               %                          21,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,41
    Achieved Active Warps Per SM                                                      warp                          28,29
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 20:58:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,18
    SM Frequency                                                             cycle/usecond                         807,02
    Elapsed Cycles                                                                   cycle                          2.712
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          11,18
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          36,53
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,55
    Achieved Active Warps Per SM                                                      warp                          21,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,50
    SM Frequency                                                             cycle/usecond                         851,79
    Elapsed Cycles                                                                   cycle                          3.632
    Memory [%]                                                                           %                           8,26
    SOL DRAM                                                                             %                           8,26
    Duration                                                                       usecond                           4,26
    SOL L1/TEX Cache                                                                     %                          13,63
    SOL L2 Cache                                                                         %                           7,34
    SM Active Cycles                                                                 cycle                         891,08
    SM [%]                                                                               %                           5,38
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,47
    Achieved Active Warps Per SM                                                      warp                          28,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:11, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,19
    SM Frequency                                                             cycle/usecond                         807,37
    Elapsed Cycles                                                                   cycle                          3.467
    Memory [%]                                                                           %                           8,45
    SOL DRAM                                                                             %                           8,45
    Duration                                                                       usecond                           4,29
    SOL L1/TEX Cache                                                                     %                          13,47
    SOL L2 Cache                                                                         %                           7,68
    SM Active Cycles                                                                 cycle                         901,61
    SM [%]                                                                               %                           5,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,06
    Achieved Active Warps Per SM                                                      warp                          28,18
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:18, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         808,10
    Elapsed Cycles                                                                   cycle                          2.716
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          12,60
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          35,06
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,12
    Achieved Active Warps Per SM                                                      warp                          19,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(unsigned long long const*, unsigned long long const*, tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>), 2021-May-03 20:59:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,87
    SM Frequency                                                             cycle/usecond                         761,70
    Elapsed Cycles                                                                   cycle                          4.169
    Memory [%]                                                                           %                           0,94
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           5,47
    SOL L1/TEX Cache                                                                     %                          29,20
    SOL L2 Cache                                                                         %                           0,94
    SM Active Cycles                                                                 cycle                          74,31
    SM [%]                                                                               %                           0,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,73
    Achieved Active Warps Per SM                                                      warp                          26,79
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 20:59:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,13
    SM Frequency                                                             cycle/usecond                         798,00
    Elapsed Cycles                                                                   cycle                          2.708
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          14,49
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          35,08
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,26
    Achieved Active Warps Per SM                                                      warp                          21,20
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,33
    SM Frequency                                                             cycle/usecond                         825,68
    Elapsed Cycles                                                                   cycle                          2.934
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,34
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          19,94
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          39,83
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          62,61
    Achieved Active Warps Per SM                                                      warp                          20,04
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,19
    SM Frequency                                                             cycle/usecond                         814,30
    Elapsed Cycles                                                                   cycle                          2.894
    Memory [%]                                                                           %                           0,83
    SOL DRAM                                                                             %                           0,35
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          19,66
    SOL L2 Cache                                                                         %                           0,83
    SM Active Cycles                                                                 cycle                          40,42
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,96
    Achieved Active Warps Per SM                                                      warp                          19,83
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,31
    SM Frequency                                                             cycle/usecond                         815,13
    Elapsed Cycles                                                                   cycle                          2.793
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          11,17
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          36,81
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,47
    Achieved Active Warps Per SM                                                      warp                          18,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 20:59:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,18
    SM Frequency                                                             cycle/usecond                         805,00
    Elapsed Cycles                                                                   cycle                          2.707
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          11,61
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          35,17
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,13
    Achieved Active Warps Per SM                                                      warp                          19,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:00:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         809,29
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          11,65
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          35,06
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,16
    Achieved Active Warps Per SM                                                      warp                          19,25
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<long long>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<long long>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:00:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,23
    SM Frequency                                                             cycle/usecond                         804,27
    Elapsed Cycles                                                                   cycle                          2.605
    Memory [%]                                                                           %                           0,65
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,23
    SOL L1/TEX Cache                                                                     %                          12,74
    SOL L2 Cache                                                                         %                           0,65
    SM Active Cycles                                                                 cycle                          32,06
    SM [%]                                                                               %                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,36
    Achieved Active Warps Per SM                                                      warp                          18,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:00:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,33
    SM Frequency                                                             cycle/usecond                         825,54
    Elapsed Cycles                                                                   cycle                          2.776
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          11,68
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          34,97
    SM [%]                                                                               %                           0,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,22
    Achieved Active Warps Per SM                                                      warp                          19,27
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_const_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:00:26, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,38
    SM Frequency                                                             cycle/usecond                         829,87
    Elapsed Cycles                                                                   cycle                          2.763
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,33
    SOL L1/TEX Cache                                                                     %                          11,64
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          35,08
    SM [%]                                                                               %                           0,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,27
    Achieved Active Warps Per SM                                                      warp                          19,29
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:00:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         760,94
    Elapsed Cycles                                                                   cycle                          2.632
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,69
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,61
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,92
    Achieved Active Warps Per SM                                                      warp                          18,22
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:00:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         760,53
    Elapsed Cycles                                                                   cycle                          2.629
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,70
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,88
    Achieved Active Warps Per SM                                                      warp                          18,20
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:00:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,83
    SM Frequency                                                             cycle/usecond                         756,08
    Elapsed Cycles                                                                   cycle                          2.686
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          12,55
    SOL L2 Cache                                                                         %                           0,63
    SM Active Cycles                                                                 cycle                          33,86
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,70
    Achieved Active Warps Per SM                                                      warp                          17,50
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:00:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         923,24
    Elapsed Cycles                                                                   cycle                         14.510
    Memory [%]                                                                           %                          30,88
    SOL DRAM                                                                             %                          17,90
    Duration                                                                       usecond                          15,71
    SOL L1/TEX Cache                                                                     %                          52,60
    SOL L2 Cache                                                                         %                          12,39
    SM Active Cycles                                                                 cycle                      10.293,19
    SM [%]                                                                               %                          30,88
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,93
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:01:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,35
    SM Frequency                                                             cycle/usecond                         826,85
    Elapsed Cycles                                                                   cycle                          5.005
    Memory [%]                                                                           %                          19,80
    SOL DRAM                                                                             %                          19,80
    Duration                                                                       usecond                           6,05
    SOL L1/TEX Cache                                                                     %                          10,96
    SOL L2 Cache                                                                         %                           9,24
    SM Active Cycles                                                                 cycle                       3.040,47
    SM [%]                                                                               %                           6,62
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          25,03
    Achieved Active Warps Per SM                                                      warp                           8,01
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:01:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,52
    SM Frequency                                                             cycle/usecond                         857,60
    Elapsed Cycles                                                                   cycle                          3.186
    Memory [%]                                                                           %                           3,35
    SOL DRAM                                                                             %                           3,29
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          14,50
    SOL L2 Cache                                                                         %                           3,35
    SM Active Cycles                                                                 cycle                         467,56
    SM [%]                                                                               %                           3,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,59
    Achieved Active Warps Per SM                                                      warp                          29,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:01:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,18
    SM Frequency                                                             cycle/usecond                         804,00
    Elapsed Cycles                                                                   cycle                          3.501
    Memory [%]                                                                           %                           2,81
    SOL DRAM                                                                             %                           2,81
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                          12,96
    SOL L2 Cache                                                                         %                           2,66
    SM Active Cycles                                                                 cycle                         320,19
    SM [%]                                                                               %                           2,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,75
    Achieved Active Warps Per SM                                                      warp                          28,08
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:01:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,05
    SM Frequency                                                             cycle/usecond                         937,38
    Elapsed Cycles                                                                   cycle                         15.601
    Memory [%]                                                                           %                           3,74
    SOL DRAM                                                                             %                           2,49
    Duration                                                                       usecond                          16,64
    SOL L1/TEX Cache                                                                     %                          37,26
    SOL L2 Cache                                                                         %                           2,58
    SM Active Cycles                                                                 cycle                       1.567,36
    SM [%]                                                                               %                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:01:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,72
    SM Frequency                                                             cycle/usecond                         879,22
    Elapsed Cycles                                                                   cycle                          3.210
    Memory [%]                                                                           %                           1,29
    SOL DRAM                                                                             %                           1,11
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          13,24
    SOL L2 Cache                                                                         %                           1,29
    SM Active Cycles                                                                 cycle                         179,64
    SM [%]                                                                               %                           1,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,50
    Achieved Active Warps Per SM                                                      warp                          27,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:01:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         773,55
    Elapsed Cycles                                                                   cycle                          3.194
    Memory [%]                                                                           %                           1,22
    SOL DRAM                                                                             %                           1,06
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                          13,78
    SOL L2 Cache                                                                         %                           1,22
    SM Active Cycles                                                                 cycle                         119,78
    SM [%]                                                                               %                           0,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,48
    Achieved Active Warps Per SM                                                      warp                          28,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:01:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         925,21
    Elapsed Cycles                                                                   cycle                          9.715
    Memory [%]                                                                           %                           1,13
    SOL DRAM                                                                             %                           0,49
    Duration                                                                       usecond                          10,50
    SOL L1/TEX Cache                                                                     %                          31,67
    SOL L2 Cache                                                                         %                           1,13
    SM Active Cycles                                                                 cycle                         225,25
    SM [%]                                                                               %                           0,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:01:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         814,47
    Elapsed Cycles                                                                   cycle                          2.818
    Memory [%]                                                                           %                           0,74
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          13,82
    SOL L2 Cache                                                                         %                           0,74
    SM Active Cycles                                                                 cycle                          38,19
    SM [%]                                                                               %                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          62,30
    Achieved Active Warps Per SM                                                      warp                          19,93
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:01:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         924,93
    Elapsed Cycles                                                                   cycle                          2.843
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                           5,51
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         290,64
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:02:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,92
    SM Frequency                                                             cycle/usecond                         914,68
    Elapsed Cycles                                                                   cycle                          3.103
    Memory [%]                                                                           %                           1,65
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                           4,54
    SOL L2 Cache                                                                         %                           1,65
    SM Active Cycles                                                                 cycle                         352,64
    SM [%]                                                                               %                           0,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:02:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         926,39
    Elapsed Cycles                                                                   cycle                          4.270
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,09
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                           7,06
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          75,89
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,68
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:02:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,06
    SM Frequency                                                             cycle/usecond                         932,51
    Elapsed Cycles                                                                   cycle                          4.000
    Memory [%]                                                                           %                           1,24
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,29
    SOL L1/TEX Cache                                                                     %                           6,29
    SOL L2 Cache                                                                         %                           1,24
    SM Active Cycles                                                                 cycle                          71,08
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,88
    Achieved Active Warps Per SM                                                      warp                           8,92
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:02:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         765,57
    Elapsed Cycles                                                                   cycle                          2.647
    Memory [%]                                                                           %                           0,65
    SOL DRAM                                                                             %                           0,06
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,29
    SOL L2 Cache                                                                         %                           0,65
    SM Active Cycles                                                                 cycle                          33,67
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,16
    Achieved Active Warps Per SM                                                      warp                          17,65
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:02:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,87
    SM Frequency                                                             cycle/usecond                         914,03
    Elapsed Cycles                                                                   cycle                          2.633
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           2,88
    SOL L1/TEX Cache                                                                     %                          12,87
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          31,72
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,60
    Achieved Active Warps Per SM                                                      warp                          18,75
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:02:39, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         913,85
    Elapsed Cycles                                                                   cycle                          2.838
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                           5,50
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         290,72
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:02:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,19
    SM Frequency                                                             cycle/usecond                         804,53
    Elapsed Cycles                                                                   cycle                          3.554
    Memory [%]                                                                           %                           1,40
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,42
    SOL L1/TEX Cache                                                                     %                           9,25
    SOL L2 Cache                                                                         %                           1,40
    SM Active Cycles                                                                 cycle                          57,33
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          41,75
    Achieved Active Warps Per SM                                                      warp                          13,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:02:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,19
    SM Frequency                                                             cycle/usecond                         799,55
    Elapsed Cycles                                                                   cycle                          8.266
    Memory [%]                                                                           %                           2,06
    SOL DRAM                                                                             %                           0,49
    Duration                                                                       usecond                          10,34
    SOL L1/TEX Cache                                                                     %                          65,61
    SOL L2 Cache                                                                         %                           2,06
    SM Active Cycles                                                                 cycle                         195,06
    SM [%]                                                                               %                           0,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,35
    Achieved Active Warps Per SM                                                      warp                          21,23
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:03:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,74
    SM Frequency                                                             cycle/usecond                         887,79
    Elapsed Cycles                                                                   cycle                         16.878
    Memory [%]                                                                           %                           1,51
    SOL DRAM                                                                             %                           0,29
    Duration                                                                       usecond                          19,01
    SOL L1/TEX Cache                                                                     %                          44,90
    SOL L2 Cache                                                                         %                           1,51
    SM Active Cycles                                                                 cycle                         414,72
    SM [%]                                                                               %                           0,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,29
    Achieved Active Warps Per SM                                                      warp                          14,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:03:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         781,91
    Elapsed Cycles                                                                   cycle                          2.858
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          13,61
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          38,58
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,83
    Achieved Active Warps Per SM                                                      warp                          18,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:03:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,25
    SM Frequency                                                             cycle/usecond                         809,91
    Elapsed Cycles                                                                   cycle                          3.321
    Memory [%]                                                                           %                           0,92
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          10,33
    SOL L2 Cache                                                                         %                           0,92
    SM Active Cycles                                                                 cycle                          52,72
    SM [%]                                                                               %                           0,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,46
    Achieved Active Warps Per SM                                                      warp                          17,11
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:03:21, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         762,21
    Elapsed Cycles                                                                   cycle                          2.635
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,70
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,89
    Achieved Active Warps Per SM                                                      warp                          18,20
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:03:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         779,66
    Elapsed Cycles                                                                   cycle                          2.946
    Memory [%]                                                                           %                           0,89
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,78
    SOL L1/TEX Cache                                                                     %                          10,22
    SOL L2 Cache                                                                         %                           0,89
    SM Active Cycles                                                                 cycle                          39,94
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,12
    Achieved Active Warps Per SM                                                      warp                           7,40
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:03:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,10
    SM Frequency                                                             cycle/usecond                         782,54
    Elapsed Cycles                                                                   cycle                          2.906
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,01
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          40,81
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,16
    Achieved Active Warps Per SM                                                      warp                           7,41
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:03:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         771,04
    Elapsed Cycles                                                                   cycle                          2.691
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          11,68
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,97
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,89
    Achieved Active Warps Per SM                                                      warp                          21,40
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:03:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         764,93
    Elapsed Cycles                                                                   cycle                          2.644
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,38
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,97
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,02
    Achieved Active Warps Per SM                                                      warp                          17,93
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:03:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         767,99
    Elapsed Cycles                                                                   cycle                          2.631
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          11,69
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          34,94
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,81
    Achieved Active Warps Per SM                                                      warp                          18,82
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         799,24
    Elapsed Cycles                                                                   cycle                          3.352
    Memory [%]                                                                           %                           0,97
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           8,01
    SOL L2 Cache                                                                         %                           0,97
    SM Active Cycles                                                                 cycle                          51,31
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,53
    Achieved Active Warps Per SM                                                      warp                          14,57
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,12
    SM Frequency                                                             cycle/usecond                         798,26
    Elapsed Cycles                                                                   cycle                          3.301
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                           7,90
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          52,03
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          46,18
    Achieved Active Warps Per SM                                                      warp                          14,78
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         771,08
    Elapsed Cycles                                                                   cycle                          2.716
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,71
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          35,11
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,06
    Achieved Active Warps Per SM                                                      warp                          21,14
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         767,33
    Elapsed Cycles                                                                   cycle                          2.705
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,29
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          36,42
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,20
    Achieved Active Warps Per SM                                                      warp                          21,82
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:04:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,94
    SM Frequency                                                             cycle/usecond                         767,28
    Elapsed Cycles                                                                   cycle                          3.022
    Memory [%]                                                                           %                           1,68
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,94
    SOL L1/TEX Cache                                                                     %                           9,59
    SOL L2 Cache                                                                         %                           1,68
    SM Active Cycles                                                                 cycle                          43,17
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,67
    Achieved Active Warps Per SM                                                      warp                          17,17
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         777,64
    Elapsed Cycles                                                                   cycle                          2.714
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          11,75
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                             35
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,68
    Achieved Active Warps Per SM                                                      warp                          21,34
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:04:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         763,02
    Elapsed Cycles                                                                   cycle                          3.523
    Memory [%]                                                                           %                           1,90
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                           8,87
    SOL L2 Cache                                                                         %                           1,90
    SM Active Cycles                                                                 cycle                          59,47
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,45
    Achieved Active Warps Per SM                                                      warp                          14,54
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:04:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         792,44
    Elapsed Cycles                                                                   cycle                          3.276
    Memory [%]                                                                           %                           1,00
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                           7,61
    SOL L2 Cache                                                                         %                           1,00
    SM Active Cycles                                                                 cycle                          54,06
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          43,22
    Achieved Active Warps Per SM                                                      warp                          13,83
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:04:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,02
    SM Frequency                                                             cycle/usecond                         932,64
    Elapsed Cycles                                                                   cycle                          4.836
    Memory [%]                                                                           %                           0,45
    SOL DRAM                                                                             %                           0,11
    Duration                                                                       usecond                           5,18
    SOL L1/TEX Cache                                                                     %                          21,93
    SOL L2 Cache                                                                         %                           0,45
    SM Active Cycles                                                                 cycle                          90,44
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,73
    Achieved Active Warps Per SM                                                      warp                          30,95
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:05:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         918,75
    Elapsed Cycles                                                                   cycle                          3.412
    Memory [%]                                                                           %                           1,33
    SOL DRAM                                                                             %                           0,11
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                           7,95
    SOL L2 Cache                                                                         %                           1,33
    SM Active Cycles                                                                 cycle                          54,53
    SM [%]                                                                               %                           0,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        352
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                            352
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              2
    Theoretical Active Warps per SM                                                   warp                             22
    Theoretical Occupancy                                                                %                          68,75
    Achieved Occupancy                                                                   %                          28,20
    Achieved Active Warps Per SM                                                      warp                           9,02
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:05:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,71
    SM Frequency                                                             cycle/usecond                         882,51
    Elapsed Cycles                                                                   cycle                          6.724
    Memory [%]                                                                           %                           2,01
    SOL DRAM                                                                             %                           0,60
    Duration                                                                       usecond                           7,62
    SOL L1/TEX Cache                                                                     %                          23,43
    SOL L2 Cache                                                                         %                           1,74
    SM Active Cycles                                                                 cycle                         576,58
    SM [%]                                                                               %                           2,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:05:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,73
    SM Frequency                                                             cycle/usecond                         890,82
    Elapsed Cycles                                                                   cycle                          6.446
    Memory [%]                                                                           %                           3,53
    SOL DRAM                                                                             %                           0,29
    Duration                                                                       usecond                           7,23
    SOL L1/TEX Cache                                                                     %                          42,50
    SOL L2 Cache                                                                         %                           1,28
    SM Active Cycles                                                                 cycle                         535,39
    SM [%]                                                                               %                           3,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:05:26, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,24
    SM Frequency                                                             cycle/usecond                         815,82
    Elapsed Cycles                                                                   cycle                          3.293
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,03
    SOL L1/TEX Cache                                                                     %                           8,07
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          52,31
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          47,60
    Achieved Active Warps Per SM                                                      warp                          15,23
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:05:33, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         801,53
    Elapsed Cycles                                                                   cycle                          3.258
    Memory [%]                                                                           %                           0,91
    SOL DRAM                                                                             %                           0,66
    Duration                                                                       usecond                           4,06
    SOL L1/TEX Cache                                                                     %                          16,68
    SOL L2 Cache                                                                         %                           0,91
    SM Active Cycles                                                                 cycle                          50,31
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,97
    Achieved Active Warps Per SM                                                      warp                          18,55
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:05:39, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,15
    SM Frequency                                                             cycle/usecond                         794,78
    Elapsed Cycles                                                                   cycle                          2.928
    Memory [%]                                                                           %                           2,18
    SOL DRAM                                                                             %                           2,18
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          15,81
    SOL L2 Cache                                                                         %                           1,79
    SM Active Cycles                                                                 cycle                         150,39
    SM [%]                                                                               %                           0,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,54
    Achieved Active Warps Per SM                                                      warp                          27,37
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:05:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,97
    SM Frequency                                                             cycle/usecond                         921,57
    Elapsed Cycles                                                                   cycle                         10.002
    Memory [%]                                                                           %                           8,35
    SOL DRAM                                                                             %                           3,23
    Duration                                                                       usecond                          10,85
    SOL L1/TEX Cache                                                                     %                          36,17
    SOL L2 Cache                                                                         %                           3,55
    SM Active Cycles                                                                 cycle                       2.308,25
    SM [%]                                                                               %                           7,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:05:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,89
    SM Frequency                                                             cycle/usecond                         903,76
    Elapsed Cycles                                                                   cycle                          7.786
    Memory [%]                                                                           %                          17,37
    SOL DRAM                                                                             %                           2,07
    Duration                                                                       usecond                           8,61
    SOL L1/TEX Cache                                                                     %                          29,73
    SOL L2 Cache                                                                         %                           6,27
    SM Active Cycles                                                                 cycle                       5.564,25
    SM [%]                                                                               %                          17,37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,96
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:06:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,32
    SM Frequency                                                             cycle/usecond                         967,60
    Elapsed Cycles                                                                   cycle                          4.059
    Memory [%]                                                                           %                           1,77
    SOL DRAM                                                                             %                           0,84
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                          27,86
    SOL L2 Cache                                                                         %                           0,89
    SM Active Cycles                                                                 cycle                         258,42
    SM [%]                                                                               %                           1,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          95,91
    Achieved Active Warps Per SM                                                      warp                          30,69
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:06:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,04
    SM Frequency                                                             cycle/usecond                         927,69
    Elapsed Cycles                                                                   cycle                          3.386
    Memory [%]                                                                           %                           1,43
    SOL DRAM                                                                             %                           1,00
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          17,61
    SOL L2 Cache                                                                         %                           1,43
    SM Active Cycles                                                                 cycle                         203,22
    SM [%]                                                                               %                           1,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,92
    Achieved Active Warps Per SM                                                      warp                          22,38
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:06:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,23
    SM Frequency                                                             cycle/usecond                         816,56
    Elapsed Cycles                                                                   cycle                          3.061
    Memory [%]                                                                           %                           6,32
    SOL DRAM                                                                             %                           6,32
    Duration                                                                       usecond                           3,74
    SOL L1/TEX Cache                                                                     %                          16,07
    SOL L2 Cache                                                                         %                           4,43
    SM Active Cycles                                                                 cycle                         421,83
    SM [%]                                                                               %                           2,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          92,31
    Achieved Active Warps Per SM                                                      warp                          29,54
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:06:21, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,53
    SM Frequency                                                             cycle/usecond                         860,95
    Elapsed Cycles                                                                   cycle                          4.550
    Memory [%]                                                                           %                          13,70
    SOL DRAM                                                                             %                          13,70
    Duration                                                                       usecond                           5,28
    SOL L1/TEX Cache                                                                     %                          18,16
    SOL L2 Cache                                                                         %                           8,58
    SM Active Cycles                                                                 cycle                       1.148,14
    SM [%]                                                                               %                           5,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,01
    Achieved Active Warps Per SM                                                      warp                          28,80
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:06:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,11
    SM Frequency                                                             cycle/usecond                         796,69
    Elapsed Cycles                                                                   cycle                          3.037
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          10,23
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          44,25
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,06
    Achieved Active Warps Per SM                                                      warp                          16,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:06:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         927,16
    Elapsed Cycles                                                                   cycle                         12.348
    Memory [%]                                                                           %                          42,09
    SOL DRAM                                                                             %                           3,47
    Duration                                                                       usecond                          13,31
    SOL L1/TEX Cache                                                                     %                          68,86
    SOL L2 Cache                                                                         %                          19,93
    SM Active Cycles                                                                 cycle                      10.328,61
    SM [%]                                                                               %                          42,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,63
    Achieved Active Warps Per SM                                                      warp                          14,60
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:06:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,34
    SM Frequency                                                             cycle/usecond                         970,39
    Elapsed Cycles                                                                   cycle                          3.669
    Memory [%]                                                                           %                           3,49
    SOL DRAM                                                                             %                           2,67
    Duration                                                                       usecond                           3,78
    SOL L1/TEX Cache                                                                     %                          21,36
    SOL L2 Cache                                                                         %                           1,84
    SM Active Cycles                                                                 cycle                         598,61
    SM [%]                                                                               %                           4,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                            Kbyte/block                           1,20
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             51
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          95,56
    Achieved Active Warps Per SM                                                      warp                          30,58
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:06:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         931,69
    Elapsed Cycles                                                                   cycle                          3.401
    Memory [%]                                                                           %                           2,80
    SOL DRAM                                                                             %                           2,80
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          17,33
    SOL L2 Cache                                                                         %                           2,46
    SM Active Cycles                                                                 cycle                         516,03
    SM [%]                                                                               %                           2,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,57
    Achieved Active Warps Per SM                                                      warp                          22,58
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:06:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,68
    SM Frequency                                                             cycle/usecond                         876,96
    Elapsed Cycles                                                                   cycle                          8.310
    Memory [%]                                                                           %                          55,54
    SOL DRAM                                                                             %                          55,54
    Duration                                                                       usecond                           9,47
    SOL L1/TEX Cache                                                                     %                          28,60
    SOL L2 Cache                                                                         %                          35,09
    SM Active Cycles                                                                 cycle                       5.714,64
    SM [%]                                                                               %                           6,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,04
    Achieved Active Warps Per SM                                                      warp                          27,53
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,29
    SM Frequency                                                             cycle/usecond                         812,82
    Elapsed Cycles                                                                   cycle                          3.071
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,26
    Duration                                                                       usecond                           3,78
    SOL L1/TEX Cache                                                                     %                          12,00
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          44,89
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,13
    Achieved Active Warps Per SM                                                      warp                          17,64
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,83
    SM Frequency                                                             cycle/usecond                         762,44
    Elapsed Cycles                                                                   cycle                          2.587
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          12,94
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,56
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,39
    Achieved Active Warps Per SM                                                      warp                          18,69
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         773,01
    Elapsed Cycles                                                                   cycle                          2.648
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          11,27
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          36,22
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,11
    Achieved Active Warps Per SM                                                      warp                          19,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,06
    SM Frequency                                                             cycle/usecond                         775,40
    Elapsed Cycles                                                                   cycle                          2.706
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          14,50
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          35,06
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,66
    Achieved Active Warps Per SM                                                      warp                          21,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,13
    SM Frequency                                                             cycle/usecond                         790,31
    Elapsed Cycles                                                                   cycle                          3.320
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           7,98
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          51,53
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,35
    Achieved Active Warps Per SM                                                      warp                          14,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:07:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         766,86
    Elapsed Cycles                                                                   cycle                          2.603
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          12,97
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,47
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,77
    Achieved Active Warps Per SM                                                      warp                          18,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:07:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,98
    SM Frequency                                                             cycle/usecond                         922,85
    Elapsed Cycles                                                                   cycle                         14.534
    Memory [%]                                                                           %                          30,83
    SOL DRAM                                                                             %                          17,86
    Duration                                                                       usecond                          15,74
    SOL L1/TEX Cache                                                                     %                          52,51
    SOL L2 Cache                                                                         %                          12,37
    SM Active Cycles                                                                 cycle                      10.367,83
    SM [%]                                                                               %                          30,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,94
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:07:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         799,34
    Elapsed Cycles                                                                   cycle                          4.863
    Memory [%]                                                                           %                          20,47
    SOL DRAM                                                                             %                          20,47
    Duration                                                                       usecond                           6,08
    SOL L1/TEX Cache                                                                     %                          10,79
    SOL L2 Cache                                                                         %                           9,51
    SM Active Cycles                                                                 cycle                       3.089,08
    SM [%]                                                                               %                           6,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,84
    Achieved Active Warps Per SM                                                      warp                           7,95
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:07:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,07
    SM Frequency                                                             cycle/usecond                         946,01
    Elapsed Cycles                                                                   cycle                          3.271
    Memory [%]                                                                           %                           3,27
    SOL DRAM                                                                             %                           3,16
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          14,18
    SOL L2 Cache                                                                         %                           3,27
    SM Active Cycles                                                                 cycle                         477,86
    SM [%]                                                                               %                           2,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,01
    Achieved Active Warps Per SM                                                      warp                          29,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:08:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,23
    SM Frequency                                                             cycle/usecond                         801,46
    Elapsed Cycles                                                                   cycle                          3.516
    Memory [%]                                                                           %                           2,74
    SOL DRAM                                                                             %                           2,74
    Duration                                                                       usecond                           4,38
    SOL L1/TEX Cache                                                                     %                          11,98
    SOL L2 Cache                                                                         %                           2,65
    SM Active Cycles                                                                 cycle                         346,53
    SM [%]                                                                               %                           2,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,65
    Achieved Active Warps Per SM                                                      warp                          28,37
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:08:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,13
    SM Frequency                                                             cycle/usecond                         948,57
    Elapsed Cycles                                                                   cycle                         15.818
    Memory [%]                                                                           %                           3,69
    SOL DRAM                                                                             %                           2,47
    Duration                                                                       usecond                          16,67
    SOL L1/TEX Cache                                                                     %                          36,78
    SOL L2 Cache                                                                         %                           2,55
    SM Active Cycles                                                                 cycle                       1.587,86
    SM [%]                                                                               %                           3,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:08:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         943,05
    Elapsed Cycles                                                                   cycle                          3.230
    Memory [%]                                                                           %                           1,27
    SOL DRAM                                                                             %                           1,09
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,26
    SOL L2 Cache                                                                         %                           1,27
    SM Active Cycles                                                                 cycle                         193,97
    SM [%]                                                                               %                           1,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,82
    Achieved Active Warps Per SM                                                      warp                          27,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:08:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         786,25
    Elapsed Cycles                                                                   cycle                          3.273
    Memory [%]                                                                           %                           1,19
    SOL DRAM                                                                             %                           0,98
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                          13,76
    SOL L2 Cache                                                                         %                           1,19
    SM Active Cycles                                                                 cycle                         119,94
    SM [%]                                                                               %                           0,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,20
    Achieved Active Warps Per SM                                                      warp                          28,23
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:08:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,95
    SM Frequency                                                             cycle/usecond                         922,07
    Elapsed Cycles                                                                   cycle                          9.710
    Memory [%]                                                                           %                           1,13
    SOL DRAM                                                                             %                           0,48
    Duration                                                                       usecond                          10,53
    SOL L1/TEX Cache                                                                     %                          31,33
    SOL L2 Cache                                                                         %                           1,13
    SM Active Cycles                                                                 cycle                         227,69
    SM [%]                                                                               %                           0,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:08:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         915,40
    Elapsed Cycles                                                                   cycle                          2.844
    Memory [%]                                                                           %                           0,73
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                          13,91
    SOL L2 Cache                                                                         %                           0,73
    SM Active Cycles                                                                 cycle                          37,94
    SM [%]                                                                               %                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,82
    Achieved Active Warps Per SM                                                      warp                          19,78
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:08:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,76
    SM Frequency                                                             cycle/usecond                         885,56
    Elapsed Cycles                                                                   cycle                          2.835
    Memory [%]                                                                           %                           1,33
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,20
    SOL L1/TEX Cache                                                                     %                           5,54
    SOL L2 Cache                                                                         %                           1,33
    SM Active Cycles                                                                 cycle                            289
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:08:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         913,90
    Elapsed Cycles                                                                   cycle                          3.131
    Memory [%]                                                                           %                           1,63
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                           4,57
    SOL L2 Cache                                                                         %                           1,63
    SM Active Cycles                                                                 cycle                            350
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:09:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,85
    SM Frequency                                                             cycle/usecond                         908,97
    Elapsed Cycles                                                                   cycle                          4.221
    Memory [%]                                                                           %                           1,27
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                           7,07
    SOL L2 Cache                                                                         %                           1,27
    SM Active Cycles                                                                 cycle                          75,83
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,67
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         924,49
    Elapsed Cycles                                                                   cycle                          4.026
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                           6,34
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          70,58
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,22
    Achieved Active Warps Per SM                                                      warp                           8,71
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,03
    SM Frequency                                                             cycle/usecond                         776,03
    Elapsed Cycles                                                                   cycle                          2.712
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,06
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,41
    SOL L2 Cache                                                                         %                           0,63
    SM Active Cycles                                                                 cycle                          33,36
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,83
    Achieved Active Warps Per SM                                                      warp                          17,54
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         763,77
    Elapsed Cycles                                                                   cycle                          2.640
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,82
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,48
    Achieved Active Warps Per SM                                                      warp                          18,07
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         763,03
    Elapsed Cycles                                                                   cycle                          2.615
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,84
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,22
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,65
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,88
    SM Frequency                                                             cycle/usecond                         767,72
    Elapsed Cycles                                                                   cycle                          2.683
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,06
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,68
    SOL L2 Cache                                                                         %                           0,63
    SM Active Cycles                                                                 cycle                          33,53
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,57
    Achieved Active Warps Per SM                                                      warp                          17,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:09:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,68
    SM Frequency                                                             cycle/usecond                         871,44
    Elapsed Cycles                                                                   cycle                          2.595
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           2,98
    SOL L1/TEX Cache                                                                     %                          12,97
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,01
    Achieved Active Warps Per SM                                                      warp                          18,56
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:09:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,82
    SM Frequency                                                             cycle/usecond                         899,31
    Elapsed Cycles                                                                   cycle                          2.851
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,17
    SOL L1/TEX Cache                                                                     %                           5,53
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         289,14
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:09:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,13
    SM Frequency                                                             cycle/usecond                         799,14
    Elapsed Cycles                                                                   cycle                          3.530
    Memory [%]                                                                           %                           1,41
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,42
    SOL L1/TEX Cache                                                                     %                          11,05
    SOL L2 Cache                                                                         %                           1,41
    SM Active Cycles                                                                 cycle                          57,06
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          41,29
    Achieved Active Warps Per SM                                                      warp                          13,21
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:10:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,40
    SM Frequency                                                             cycle/usecond                         836,85
    Elapsed Cycles                                                                   cycle                          8.544
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,28
    Duration                                                                       usecond                          10,21
    SOL L1/TEX Cache                                                                     %                          68,02
    SOL L2 Cache                                                                         %                           2,00
    SM Active Cycles                                                                 cycle                         188,17
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,00
    Achieved Active Warps Per SM                                                      warp                          22,08
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:10:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,75
    SM Frequency                                                             cycle/usecond                         890,61
    Elapsed Cycles                                                                   cycle                         16.596
    Memory [%]                                                                           %                           1,53
    SOL DRAM                                                                             %                           0,27
    Duration                                                                       usecond                          18,62
    SOL L1/TEX Cache                                                                     %                          43,76
    SOL L2 Cache                                                                         %                           1,53
    SM Active Cycles                                                                 cycle                         425,39
    SM [%]                                                                               %                           0,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          44,07
    Achieved Active Warps Per SM                                                      warp                          14,10
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:10:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         771,55
    Elapsed Cycles                                                                   cycle                          2.865
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          13,66
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          38,44
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,41
    Achieved Active Warps Per SM                                                      warp                          18,37
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:10:26, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,33
    SM Frequency                                                             cycle/usecond                         820,16
    Elapsed Cycles                                                                   cycle                          3.387
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,15
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                          10,22
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          53,28
    SM [%]                                                                               %                           0,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          52,99
    Achieved Active Warps Per SM                                                      warp                          16,96
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:10:33, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         764,06
    Elapsed Cycles                                                                   cycle                          2.642
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,75
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,47
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,66
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:10:40, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,15
    SM Frequency                                                             cycle/usecond                         802,07
    Elapsed Cycles                                                                   cycle                          2.953
    Memory [%]                                                                           %                           0,88
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          10,31
    SOL L2 Cache                                                                         %                           0,88
    SM Active Cycles                                                                 cycle                          39,61
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:10:47, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         798,65
    Elapsed Cycles                                                                   cycle                          2.967
    Memory [%]                                                                           %                           0,88
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,29
    SOL L2 Cache                                                                         %                           0,88
    SM Active Cycles                                                                 cycle                          39,67
    SM [%]                                                                               %                           0,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:10:54, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         769,38
    Elapsed Cycles                                                                   cycle                          2.710
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,82
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,78
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,32
    Achieved Active Warps Per SM                                                      warp                          21,22
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:01, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         769,27
    Elapsed Cycles                                                                   cycle                          2.661
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,48
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,72
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,85
    Achieved Active Warps Per SM                                                      warp                          17,87
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:08, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,07
    SM Frequency                                                             cycle/usecond                         782,47
    Elapsed Cycles                                                                   cycle                          2.708
    Memory [%]                                                                           %                           0,67
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,47
    SOL L2 Cache                                                                         %                           0,67
    SM Active Cycles                                                                 cycle                          32,75
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,64
    Achieved Active Warps Per SM                                                      warp                          17,80
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:15, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         777,95
    Elapsed Cycles                                                                   cycle                          2.740
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,83
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,75
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,29
    Achieved Active Warps Per SM                                                      warp                          21,21
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:22, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         794,23
    Elapsed Cycles                                                                   cycle                          3.306
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,03
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          51,19
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,05
    Achieved Active Warps Per SM                                                      warp                          14,41
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:29, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         767,98
    Elapsed Cycles                                                                   cycle                          2.608
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,00
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,69
    Achieved Active Warps Per SM                                                      warp                          18,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         760,59
    Elapsed Cycles                                                                   cycle                          2.630
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,49
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,69
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,89
    Achieved Active Warps Per SM                                                      warp                          17,88
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,14
    SM Frequency                                                             cycle/usecond                         797,40
    Elapsed Cycles                                                                   cycle                          3.319
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           7,97
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,61
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          44,76
    Achieved Active Warps Per SM                                                      warp                          14,32
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         779,02
    Elapsed Cycles                                                                   cycle                          3.292
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                           8,06
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                             51
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,21
    Achieved Active Warps Per SM                                                      warp                          14,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:11:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,90
    SM Frequency                                                             cycle/usecond                         768,86
    Elapsed Cycles                                                                   cycle                          2.732
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,71
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,86
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          65,97
    Achieved Active Warps Per SM                                                      warp                          21,11
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:12:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,02
    SM Frequency                                                             cycle/usecond                         772,56
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,73
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          35,06
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          65,97
    Achieved Active Warps Per SM                                                      warp                          21,11
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:12:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,90
    SM Frequency                                                             cycle/usecond                         758,77
    Elapsed Cycles                                                                   cycle                          3.016
    Memory [%]                                                                           %                           1,69
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,97
    SOL L1/TEX Cache                                                                     %                           9,68
    SOL L2 Cache                                                                         %                           1,69
    SM Active Cycles                                                                 cycle                          42,75
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,53
    Achieved Active Warps Per SM                                                      warp                          17,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:12:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         770,80
    Elapsed Cycles                                                                   cycle                          2.715
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,24
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          36,58
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,27
    Achieved Active Warps Per SM                                                      warp                          21,85
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:12:25, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         801,25
    Elapsed Cycles                                                                   cycle                          3.595
    Memory [%]                                                                           %                           1,86
    SOL DRAM                                                                             %                           0,15
    Duration                                                                       usecond                           4,48
    SOL L1/TEX Cache                                                                     %                           9,33
    SOL L2 Cache                                                                         %                           1,86
    SM Active Cycles                                                                 cycle                          56,58
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,66
    Achieved Active Warps Per SM                                                      warp                          13,65
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:12:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         803,22
    Elapsed Cycles                                                                   cycle                          3.344
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,08
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          50,86
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,32
    Achieved Active Warps Per SM                                                      warp                          14,50
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:12:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         918,25
    Elapsed Cycles                                                                   cycle                          4.763
    Memory [%]                                                                           %                           0,46
    SOL DRAM                                                                             %                           0,08
    Duration                                                                       usecond                           5,18
    SOL L1/TEX Cache                                                                     %                          23,99
    SOL L2 Cache                                                                         %                           0,46
    SM Active Cycles                                                                 cycle                          84,97
    SM [%]                                                                               %                           0,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,58
    Achieved Active Warps Per SM                                                      warp                          30,91
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:12:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,76
    SM Frequency                                                             cycle/usecond                         888,51
    Elapsed Cycles                                                                   cycle                          6.712
    Memory [%]                                                                           %                           2,01
    SOL DRAM                                                                             %                           0,60
    Duration                                                                       usecond                           7,55
    SOL L1/TEX Cache                                                                     %                          23,48
    SOL L2 Cache                                                                         %                           1,74
    SM Active Cycles                                                                 cycle                         575,53
    SM [%]                                                                               %                           2,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:12:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,71
    SM Frequency                                                             cycle/usecond                         884,66
    Elapsed Cycles                                                                   cycle                          6.430
    Memory [%]                                                                           %                           3,54
    SOL DRAM                                                                             %                           0,25
    Duration                                                                       usecond                           7,26
    SOL L1/TEX Cache                                                                     %                          42,34
    SOL L2 Cache                                                                         %                           1,28
    SM Active Cycles                                                                 cycle                         537,50
    SM [%]                                                                               %                           3,54
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:12:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,29
    SM Frequency                                                             cycle/usecond                         811,61
    Elapsed Cycles                                                                   cycle                          3.302
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           4,06
    SOL L1/TEX Cache                                                                     %                          10,30
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          50,69
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,30
    Achieved Active Warps Per SM                                                      warp                          14,50
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:13:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,34
    SM Frequency                                                             cycle/usecond                         823,75
    Elapsed Cycles                                                                   cycle                          3.298
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,66
    Duration                                                                       usecond                              4
    SOL L1/TEX Cache                                                                     %                          16,59
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          50,56
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,69
    Achieved Active Warps Per SM                                                      warp                          18,14
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:13:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         775,32
    Elapsed Cycles                                                                   cycle                          2.880
    Memory [%]                                                                           %                           2,20
    SOL DRAM                                                                             %                           2,20
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          15,74
    SOL L2 Cache                                                                         %                           1,82
    SM Active Cycles                                                                 cycle                         151,08
    SM [%]                                                                               %                           0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,61
    Achieved Active Warps Per SM                                                      warp                          27,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:13:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         922,26
    Elapsed Cycles                                                                   cycle                         10.039
    Memory [%]                                                                           %                           8,32
    SOL DRAM                                                                             %                           3,23
    Duration                                                                       usecond                          10,88
    SOL L1/TEX Cache                                                                     %                          36,18
    SOL L2 Cache                                                                         %                           3,54
    SM Active Cycles                                                                 cycle                       2.307,97
    SM [%]                                                                               %                           7,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:13:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,76
    SM Frequency                                                             cycle/usecond                         888,63
    Elapsed Cycles                                                                   cycle                          7.740
    Memory [%]                                                                           %                          17,47
    SOL DRAM                                                                             %                           2,12
    Duration                                                                       usecond                           8,70
    SOL L1/TEX Cache                                                                     %                          29,90
    SOL L2 Cache                                                                         %                           6,31
    SM Active Cycles                                                                 cycle                       5.590,69
    SM [%]                                                                               %                          17,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,97
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:13:33, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,38
    SM Frequency                                                             cycle/usecond                         991,31
    Elapsed Cycles                                                                   cycle                          4.220
    Memory [%]                                                                           %                           1,71
    SOL DRAM                                                                             %                           0,80
    Duration                                                                       usecond                           4,26
    SOL L1/TEX Cache                                                                     %                          27,78
    SOL L2 Cache                                                                         %                           0,86
    SM Active Cycles                                                                 cycle                         260,39
    SM [%]                                                                               %                           1,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,04
    Achieved Active Warps Per SM                                                      warp                          30,73
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:13:40, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         756,88
    Elapsed Cycles                                                                   cycle                          2.909
    Memory [%]                                                                           %                           6,55
    SOL DRAM                                                                             %                           6,55
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          17,56
    SOL L2 Cache                                                                         %                           4,67
    SM Active Cycles                                                                 cycle                         385,89
    SM [%]                                                                               %                           2,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,62
    Achieved Active Warps Per SM                                                      warp                          29,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:13:47, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,40
    SM Frequency                                                             cycle/usecond                         832,68
    Elapsed Cycles                                                                   cycle                          4.426
    Memory [%]                                                                           %                          14,07
    SOL DRAM                                                                             %                          14,07
    Duration                                                                       usecond                           5,31
    SOL L1/TEX Cache                                                                     %                          18,69
    SOL L2 Cache                                                                         %                           8,81
    SM Active Cycles                                                                 cycle                       1.115,94
    SM [%]                                                                               %                           5,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,12
    Achieved Active Warps Per SM                                                      warp                          28,84
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:13:54, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,20
    SM Frequency                                                             cycle/usecond                         794,69
    Elapsed Cycles                                                                   cycle                          3.053
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,09
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          10,32
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          43,89
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          52,00
    Achieved Active Warps Per SM                                                      warp                          16,64
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:14:01, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,13
    SM Frequency                                                             cycle/usecond                         944,33
    Elapsed Cycles                                                                   cycle                         12.395
    Memory [%]                                                                           %                          41,93
    SOL DRAM                                                                             %                           3,32
    Duration                                                                       usecond                          13,12
    SOL L1/TEX Cache                                                                     %                          68,60
    SOL L2 Cache                                                                         %                          19,84
    SM Active Cycles                                                                 cycle                      10.299,11
    SM [%]                                                                               %                          41,93
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,73
    Achieved Active Warps Per SM                                                      warp                          14,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:14:08, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         938,56
    Elapsed Cycles                                                                   cycle                          3.367
    Memory [%]                                                                           %                           2,80
    SOL DRAM                                                                             %                           2,80
    Duration                                                                       usecond                           3,58
    SOL L1/TEX Cache                                                                     %                          17,55
    SOL L2 Cache                                                                         %                           2,49
    SM Active Cycles                                                                 cycle                         509,53
    SM [%]                                                                               %                           2,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,18
    Achieved Active Warps Per SM                                                      warp                          22,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:14:15, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         913,80
    Elapsed Cycles                                                                   cycle                          8.282
    Memory [%]                                                                           %                          55,51
    SOL DRAM                                                                             %                          55,51
    Duration                                                                       usecond                           9,06
    SOL L1/TEX Cache                                                                     %                          27,53
    SOL L2 Cache                                                                         %                          35,21
    SM Active Cycles                                                                 cycle                       5.936,75
    SM [%]                                                                               %                           6,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,14
    Achieved Active Warps Per SM                                                      warp                          27,56
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:14:22, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         788,32
    Elapsed Cycles                                                                   cycle                          3.079
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,30
    Duration                                                                       usecond                           3,90
    SOL L1/TEX Cache                                                                     %                          12,06
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          44,67
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,95
    Achieved Active Warps Per SM                                                      warp                          17,26
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:14:29, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         768,81
    Elapsed Cycles                                                                   cycle                          2.610
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,02
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,36
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,13
    Achieved Active Warps Per SM                                                      warp                          18,60
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:14:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,98
    SM Frequency                                                             cycle/usecond                         921,86
    Elapsed Cycles                                                                   cycle                         14.517
    Memory [%]                                                                           %                          30,87
    SOL DRAM                                                                             %                          17,78
    Duration                                                                       usecond                          15,74
    SOL L1/TEX Cache                                                                     %                          52,61
    SOL L2 Cache                                                                         %                          12,38
    SM Active Cycles                                                                 cycle                      10.367,61
    SM [%]                                                                               %                          30,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,94
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:14:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,26
    SM Frequency                                                             cycle/usecond                         815,34
    Elapsed Cycles                                                                   cycle                          4.884
    Memory [%]                                                                           %                          20,60
    SOL DRAM                                                                             %                          20,60
    Duration                                                                       usecond                           5,98
    SOL L1/TEX Cache                                                                     %                          10,96
    SOL L2 Cache                                                                         %                           9,47
    SM Active Cycles                                                                 cycle                       3.042,58
    SM [%]                                                                               %                           6,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          25,02
    Achieved Active Warps Per SM                                                      warp                           8,01
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:14:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,19
    SM Frequency                                                             cycle/usecond                         953,36
    Elapsed Cycles                                                                   cycle                          3.236
    Memory [%]                                                                           %                           3,31
    SOL DRAM                                                                             %                           3,11
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          14,60
    SOL L2 Cache                                                                         %                           3,31
    SM Active Cycles                                                                 cycle                         464,08
    SM [%]                                                                               %                           3,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,57
    Achieved Active Warps Per SM                                                      warp                          29,30
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:14:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,26
    SM Frequency                                                             cycle/usecond                         809,97
    Elapsed Cycles                                                                   cycle                          3.527
    Memory [%]                                                                           %                           2,78
    SOL DRAM                                                                             %                           2,78
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                          12,92
    SOL L2 Cache                                                                         %                           2,64
    SM Active Cycles                                                                 cycle                         321,22
    SM [%]                                                                               %                           2,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,74
    Achieved Active Warps Per SM                                                      warp                          28,08
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:15:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,10
    SM Frequency                                                             cycle/usecond                         946,30
    Elapsed Cycles                                                                   cycle                         15.720
    Memory [%]                                                                           %                           3,72
    SOL DRAM                                                                             %                           2,52
    Duration                                                                       usecond                          16,61
    SOL L1/TEX Cache                                                                     %                          37,11
    SOL L2 Cache                                                                         %                           2,57
    SM Active Cycles                                                                 cycle                       1.573,58
    SM [%]                                                                               %                           3,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:15:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         929,98
    Elapsed Cycles                                                                   cycle                          3.215
    Memory [%]                                                                           %                           1,27
    SOL DRAM                                                                             %                           1,17
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          13,06
    SOL L2 Cache                                                                         %                           1,27
    SM Active Cycles                                                                 cycle                         182,03
    SM [%]                                                                               %                           1,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,92
    Achieved Active Warps Per SM                                                      warp                          26,85
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:15:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,12
    SM Frequency                                                             cycle/usecond                         784,67
    Elapsed Cycles                                                                   cycle                          3.215
    Memory [%]                                                                           %                           1,21
    SOL DRAM                                                                             %                           1,12
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          13,60
    SOL L2 Cache                                                                         %                           1,21
    SM Active Cycles                                                                 cycle                         121,31
    SM [%]                                                                               %                           0,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,87
    Achieved Active Warps Per SM                                                      warp                          28,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:15:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         922,44
    Elapsed Cycles                                                                   cycle                          9.654
    Memory [%]                                                                           %                           1,13
    SOL DRAM                                                                             %                           0,50
    Duration                                                                       usecond                          10,46
    SOL L1/TEX Cache                                                                     %                          31,33
    SOL L2 Cache                                                                         %                           1,13
    SM Active Cycles                                                                 cycle                         227,67
    SM [%]                                                                               %                           0,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:15:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,88
    SM Frequency                                                             cycle/usecond                         903,95
    Elapsed Cycles                                                                   cycle                          2.836
    Memory [%]                                                                           %                           0,73
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,14
    SOL L1/TEX Cache                                                                     %                          13,92
    SOL L2 Cache                                                                         %                           0,73
    SM Active Cycles                                                                 cycle                          37,92
    SM [%]                                                                               %                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,94
    Achieved Active Warps Per SM                                                      warp                          19,82
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:15:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         927,60
    Elapsed Cycles                                                                   cycle                          2.851
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                           5,54
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         288,75
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:15:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         909,23
    Elapsed Cycles                                                                   cycle                          3.115
    Memory [%]                                                                           %                           1,64
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                           4,56
    SOL L2 Cache                                                                         %                           1,64
    SM Active Cycles                                                                 cycle                            351
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:15:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,85
    SM Frequency                                                             cycle/usecond                         912,54
    Elapsed Cycles                                                                   cycle                          4.235
    Memory [%]                                                                           %                           1,24
    SOL DRAM                                                                             %                           0,15
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                           7,07
    SOL L2 Cache                                                                         %                           1,24
    SM Active Cycles                                                                 cycle                          75,83
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,67
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:15:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         928,24
    Elapsed Cycles                                                                   cycle                          4.012
    Memory [%]                                                                           %                           1,24
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,32
    SOL L1/TEX Cache                                                                     %                           6,35
    SOL L2 Cache                                                                         %                           1,24
    SM Active Cycles                                                                 cycle                          70,42
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,20
    Achieved Active Warps Per SM                                                      warp                           8,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:16:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         766,69
    Elapsed Cycles                                                                   cycle                          2.676
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,44
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          33,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,96
    Achieved Active Warps Per SM                                                      warp                          17,59
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:16:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,76
    SM Frequency                                                             cycle/usecond                         739,64
    Elapsed Cycles                                                                   cycle                          2.628
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          12,82
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,48
    Achieved Active Warps Per SM                                                      warp                          18,07
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:16:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         770,15
    Elapsed Cycles                                                                   cycle                          2.638
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,84
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,22
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,65
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:16:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         766,51
    Elapsed Cycles                                                                   cycle                          2.679
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,66
    SOL L2 Cache                                                                         %                           0,63
    SM Active Cycles                                                                 cycle                          33,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,56
    Achieved Active Warps Per SM                                                      warp                          17,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:16:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,91
    SM Frequency                                                             cycle/usecond                         926,25
    Elapsed Cycles                                                                   cycle                          2.669
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           2,88
    SOL L1/TEX Cache                                                                     %                          13,00
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          31,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,77
    Achieved Active Warps Per SM                                                      warp                          18,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:16:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,90
    SM Frequency                                                             cycle/usecond                         910,70
    Elapsed Cycles                                                                   cycle                          2.830
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                           5,53
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         289,17
    SM [%]                                                                               %                           0,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:16:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,26
    SM Frequency                                                             cycle/usecond                         804,24
    Elapsed Cycles                                                                   cycle                          3.606
    Memory [%]                                                                           %                           1,38
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,48
    SOL L1/TEX Cache                                                                     %                           9,10
    SOL L2 Cache                                                                         %                           1,38
    SM Active Cycles                                                                 cycle                          58,33
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          40,72
    Achieved Active Warps Per SM                                                      warp                          13,03
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:16:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,38
    SM Frequency                                                             cycle/usecond                         835,28
    Elapsed Cycles                                                                   cycle                          8.502
    Memory [%]                                                                           %                           2,01
    SOL DRAM                                                                             %                           0,26
    Duration                                                                       usecond                          10,18
    SOL L1/TEX Cache                                                                     %                          63,21
    SOL L2 Cache                                                                         %                           2,01
    SM Active Cycles                                                                 cycle                         202,50
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          64,03
    Achieved Active Warps Per SM                                                      warp                          20,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:16:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,65
    SM Frequency                                                             cycle/usecond                         875,95
    Elapsed Cycles                                                                   cycle                         16.035
    Memory [%]                                                                           %                           1,58
    SOL DRAM                                                                             %                           0,22
    Duration                                                                       usecond                          18,30
    SOL L1/TEX Cache                                                                     %                          46,04
    SOL L2 Cache                                                                         %                           1,58
    SM Active Cycles                                                                 cycle                         404,56
    SM [%]                                                                               %                           0,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,25
    Achieved Active Warps Per SM                                                      warp                          14,48
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:17:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         779,77
    Elapsed Cycles                                                                   cycle                          2.847
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          13,51
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          38,86
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,64
    Achieved Active Warps Per SM                                                      warp                          18,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:17:11, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         804,66
    Elapsed Cycles                                                                   cycle                          3.349
    Memory [%]                                                                           %                           0,95
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                          10,12
    SOL L2 Cache                                                                         %                           0,95
    SM Active Cycles                                                                 cycle                          53,53
    SM [%]                                                                               %                           0,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          52,82
    Achieved Active Warps Per SM                                                      warp                          16,90
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:17:18, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         762,27
    Elapsed Cycles                                                                   cycle                          2.636
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,81
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,31
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,43
    Achieved Active Warps Per SM                                                      warp                          18,06
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:17:25, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         777,35
    Elapsed Cycles                                                                   cycle                          2.912
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,74
    SOL L1/TEX Cache                                                                     %                          10,31
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,61
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:17:32, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         788,15
    Elapsed Cycles                                                                   cycle                          2.906
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          10,20
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          40,03
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,12
    Achieved Active Warps Per SM                                                      warp                           7,40
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:17:39, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         774,55
    Elapsed Cycles                                                                   cycle                          2.728
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,80
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,83
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,37
    Achieved Active Warps Per SM                                                      warp                          21,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:17:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         762,09
    Elapsed Cycles                                                                   cycle                          2.637
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,52
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,61
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,94
    Achieved Active Warps Per SM                                                      warp                          17,90
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:17:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         768,52
    Elapsed Cycles                                                                   cycle                          2.657
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,47
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,75
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,80
    Achieved Active Warps Per SM                                                      warp                          17,86
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         773,64
    Elapsed Cycles                                                                   cycle                          2.724
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          14,60
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,81
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,34
    Achieved Active Warps Per SM                                                      warp                          21,23
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         788,07
    Elapsed Cycles                                                                   cycle                          3.330
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                           8,05
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,06
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,11
    Achieved Active Warps Per SM                                                      warp                          14,43
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         774,11
    Elapsed Cycles                                                                   cycle                          2.603
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          12,99
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,44
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,82
    Achieved Active Warps Per SM                                                      warp                          18,50
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         768,23
    Elapsed Cycles                                                                   cycle                          2.657
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,52
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,61
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,86
    Achieved Active Warps Per SM                                                      warp                          17,88
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:26, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,23
    SM Frequency                                                             cycle/usecond                         804,90
    Elapsed Cycles                                                                   cycle                          3.350
    Memory [%]                                                                           %                           0,97
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,04
    SOL L2 Cache                                                                         %                           0,97
    SM Active Cycles                                                                 cycle                          51,14
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,14
    Achieved Active Warps Per SM                                                      warp                          14,45
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:33, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         794,62
    Elapsed Cycles                                                                   cycle                          3.308
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           7,96
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          51,64
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          44,74
    Achieved Active Warps Per SM                                                      warp                          14,32
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,90
    SM Frequency                                                             cycle/usecond                         766,67
    Elapsed Cycles                                                                   cycle                          2.724
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,75
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,75
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,02
    Achieved Active Warps Per SM                                                      warp                          21,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:18:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,15
    SM Frequency                                                             cycle/usecond                         787,67
    Elapsed Cycles                                                                   cycle                          2.801
    Memory [%]                                                                           %                           0,74
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,76
    SOL L2 Cache                                                                         %                           0,74
    SM Active Cycles                                                                 cycle                          34,97
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,12
    Achieved Active Warps Per SM                                                      warp                          21,16
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:18:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         784,12
    Elapsed Cycles                                                                   cycle                          3.063
    Memory [%]                                                                           %                           1,66
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,90
    SOL L1/TEX Cache                                                                     %                           9,63
    SOL L2 Cache                                                                         %                           1,66
    SM Active Cycles                                                                 cycle                             43
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,68
    Achieved Active Warps Per SM                                                      warp                          17,18
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:19:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         776,08
    Elapsed Cycles                                                                   cycle                          2.734
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,85
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,69
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,47
    Achieved Active Warps Per SM                                                      warp                          21,27
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:19:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         776,42
    Elapsed Cycles                                                                   cycle                          3.504
    Memory [%]                                                                           %                           1,91
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           4,51
    SOL L1/TEX Cache                                                                     %                           9,33
    SOL L2 Cache                                                                         %                           1,91
    SM Active Cycles                                                                 cycle                          56,58
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,71
    Achieved Active Warps Per SM                                                      warp                          13,67
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:19:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,07
    SM Frequency                                                             cycle/usecond                         786,40
    Elapsed Cycles                                                                   cycle                          3.298
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           8,15
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          50,44
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,67
    Achieved Active Warps Per SM                                                      warp                          14,61
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:19:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         807,57
    Elapsed Cycles                                                                   cycle                          4.523
    Memory [%]                                                                           %                           0,48
    SOL DRAM                                                                             %                           0,08
    Duration                                                                       usecond                           5,60
    SOL L1/TEX Cache                                                                     %                          23,95
    SOL L2 Cache                                                                         %                           0,48
    SM Active Cycles                                                                 cycle                          85,14
    SM [%]                                                                               %                           0,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,59
    Achieved Active Warps Per SM                                                      warp                          30,91
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:19:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,69
    SM Frequency                                                             cycle/usecond                         884,54
    Elapsed Cycles                                                                   cycle                          6.768
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,57
    Duration                                                                       usecond                           7,65
    SOL L1/TEX Cache                                                                     %                          23,48
    SOL L2 Cache                                                                         %                           1,73
    SM Active Cycles                                                                 cycle                         575,36
    SM [%]                                                                               %                           2,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:19:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,74
    SM Frequency                                                             cycle/usecond                         886,42
    Elapsed Cycles                                                                   cycle                          6.385
    Memory [%]                                                                           %                           3,57
    SOL DRAM                                                                             %                           0,22
    Duration                                                                       usecond                           7,20
    SOL L1/TEX Cache                                                                     %                          42,49
    SOL L2 Cache                                                                         %                           1,29
    SM Active Cycles                                                                 cycle                         535,61
    SM [%]                                                                               %                           3,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:19:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,29
    SM Frequency                                                             cycle/usecond                         815,45
    Elapsed Cycles                                                                   cycle                          3.316
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,06
    SOL L1/TEX Cache                                                                     %                           9,92
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          52,67
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          43,77
    Achieved Active Warps Per SM                                                      warp                          14,01
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:19:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,33
    SM Frequency                                                             cycle/usecond                         812,65
    Elapsed Cycles                                                                   cycle                          3.279
    Memory [%]                                                                           %                           0,91
    SOL DRAM                                                                             %                           0,73
    Duration                                                                       usecond                           4,03
    SOL L1/TEX Cache                                                                     %                          16,97
    SOL L2 Cache                                                                         %                           0,91
    SM Active Cycles                                                                 cycle                          49,44
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,37
    Achieved Active Warps Per SM                                                      warp                          18,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:19:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,10
    SM Frequency                                                             cycle/usecond                         792,13
    Elapsed Cycles                                                                   cycle                          2.943
    Memory [%]                                                                           %                           2,22
    SOL DRAM                                                                             %                           2,22
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          15,91
    SOL L2 Cache                                                                         %                           1,78
    SM Active Cycles                                                                 cycle                         149,44
    SM [%]                                                                               %                           0,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,90
    Achieved Active Warps Per SM                                                      warp                          27,17
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:20:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,91
    SM Frequency                                                             cycle/usecond                         915,94
    Elapsed Cycles                                                                   cycle                          9.970
    Memory [%]                                                                           %                           8,38
    SOL DRAM                                                                             %                           3,25
    Duration                                                                       usecond                          10,88
    SOL L1/TEX Cache                                                                     %                          36,14
    SOL L2 Cache                                                                         %                           3,56
    SM Active Cycles                                                                 cycle                       2.310,69
    SM [%]                                                                               %                           7,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:20:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,80
    SM Frequency                                                             cycle/usecond                         897,12
    Elapsed Cycles                                                                   cycle                          7.842
    Memory [%]                                                                           %                          17,24
    SOL DRAM                                                                             %                           2,12
    Duration                                                                       usecond                           8,74
    SOL L1/TEX Cache                                                                     %                          29,50
    SOL L2 Cache                                                                         %                           6,23
    SM Active Cycles                                                                 cycle                       5.589,17
    SM [%]                                                                               %                          17,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,97
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:20:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,18
    SM Frequency                                                             cycle/usecond                         961,84
    Elapsed Cycles                                                                   cycle                          4.064
    Memory [%]                                                                           %                           1,73
    SOL DRAM                                                                             %                           0,80
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                          27,20
    SOL L2 Cache                                                                         %                           0,89
    SM Active Cycles                                                                 cycle                         257,75
    SM [%]                                                                               %                           1,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          95,71
    Achieved Active Warps Per SM                                                      warp                          30,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:20:26, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,01
    SM Frequency                                                             cycle/usecond                         774,95
    Elapsed Cycles                                                                   cycle                          2.955
    Memory [%]                                                                           %                           6,45
    SOL DRAM                                                                             %                           6,45
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          17,37
    SOL L2 Cache                                                                         %                           4,59
    SM Active Cycles                                                                 cycle                         390,19
    SM [%]                                                                               %                           2,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,37
    Achieved Active Warps Per SM                                                      warp                          28,92
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:20:33, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,57
    SM Frequency                                                             cycle/usecond                         852,68
    Elapsed Cycles                                                                   cycle                          4.399
    Memory [%]                                                                           %                          14,15
    SOL DRAM                                                                             %                          14,15
    Duration                                                                       usecond                           5,15
    SOL L1/TEX Cache                                                                     %                          18,62
    SOL L2 Cache                                                                         %                           8,87
    SM Active Cycles                                                                 cycle                       1.120,14
    SM [%]                                                                               %                           5,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,20
    Achieved Active Warps Per SM                                                      warp                          28,86
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:20:40, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         805,78
    Elapsed Cycles                                                                   cycle                          3.070
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,09
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          10,31
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          43,92
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          51,97
    Achieved Active Warps Per SM                                                      warp                          16,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:20:47, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,14
    SM Frequency                                                             cycle/usecond                         948,01
    Elapsed Cycles                                                                   cycle                         12.414
    Memory [%]                                                                           %                          41,87
    SOL DRAM                                                                             %                           3,39
    Duration                                                                       usecond                          13,09
    SOL L1/TEX Cache                                                                     %                          68,51
    SOL L2 Cache                                                                         %                          19,82
    SM Active Cycles                                                                 cycle                      10.361,25
    SM [%]                                                                               %                          41,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,67
    Achieved Active Warps Per SM                                                      warp                          14,61
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:20:54, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         937,22
    Elapsed Cycles                                                                   cycle                          3.391
    Memory [%]                                                                           %                           2,74
    SOL DRAM                                                                             %                           2,74
    Duration                                                                       usecond                           3,62
    SOL L1/TEX Cache                                                                     %                          17,39
    SOL L2 Cache                                                                         %                           2,47
    SM Active Cycles                                                                 cycle                         514,36
    SM [%]                                                                               %                           2,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,46
    Achieved Active Warps Per SM                                                      warp                          22,55
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:21:01, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         911,83
    Elapsed Cycles                                                                   cycle                          8.410
    Memory [%]                                                                           %                          54,57
    SOL DRAM                                                                             %                          54,57
    Duration                                                                       usecond                           9,22
    SOL L1/TEX Cache                                                                     %                          28,32
    SOL L2 Cache                                                                         %                          34,68
    SM Active Cycles                                                                 cycle                       5.770,83
    SM [%]                                                                               %                           6,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,25
    Achieved Active Warps Per SM                                                      warp                          27,60
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:21:08, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,23
    SM Frequency                                                             cycle/usecond                         805,78
    Elapsed Cycles                                                                   cycle                          3.095
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,26
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          12,15
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          44,36
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,48
    Achieved Active Warps Per SM                                                      warp                          17,43
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:21:15, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         764,68
    Elapsed Cycles                                                                   cycle                          2.595
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,04
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,31
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,89
    Achieved Active Warps Per SM                                                      warp                          18,52
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:21:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         926,71
    Elapsed Cycles                                                                   cycle                         14.713
    Memory [%]                                                                           %                          30,46
    SOL DRAM                                                                             %                          17,66
    Duration                                                                       usecond                          15,87
    SOL L1/TEX Cache                                                                     %                          51,93
    SOL L2 Cache                                                                         %                          12,22
    SM Active Cycles                                                                 cycle                      10.310,28
    SM [%]                                                                               %                          30,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,94
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:21:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         809,67
    Elapsed Cycles                                                                   cycle                          4.874
    Memory [%]                                                                           %                          20,65
    SOL DRAM                                                                             %                          20,65
    Duration                                                                       usecond                           6,02
    SOL L1/TEX Cache                                                                     %                          10,86
    SOL L2 Cache                                                                         %                           9,49
    SM Active Cycles                                                                 cycle                       3.068,36
    SM [%]                                                                               %                           6,80
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,87
    Achieved Active Warps Per SM                                                      warp                           7,96
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:21:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         941,12
    Elapsed Cycles                                                                   cycle                          3.225
    Memory [%]                                                                           %                           3,32
    SOL DRAM                                                                             %                           3,24
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          14,54
    SOL L2 Cache                                                                         %                           3,32
    SM Active Cycles                                                                 cycle                         466,31
    SM [%]                                                                               %                           3,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,67
    Achieved Active Warps Per SM                                                      warp                          29,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:21:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         815,28
    Elapsed Cycles                                                                   cycle                          3.524
    Memory [%]                                                                           %                           2,87
    SOL DRAM                                                                             %                           2,87
    Duration                                                                       usecond                           4,32
    SOL L1/TEX Cache                                                                     %                          13,35
    SOL L2 Cache                                                                         %                           2,64
    SM Active Cycles                                                                 cycle                         318,42
    SM [%]                                                                               %                           2,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,86
    Achieved Active Warps Per SM                                                      warp                          28,11
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:21:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,10
    SM Frequency                                                             cycle/usecond                         943,70
    Elapsed Cycles                                                                   cycle                         15.768
    Memory [%]                                                                           %                           3,70
    SOL DRAM                                                                             %                           2,47
    Duration                                                                       usecond                          16,70
    SOL L1/TEX Cache                                                                     %                          36,85
    SOL L2 Cache                                                                         %                           2,56
    SM Active Cycles                                                                 cycle                       1.584,61
    SM [%]                                                                               %                           3,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:21:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,28
    SM Frequency                                                             cycle/usecond                         959,23
    Elapsed Cycles                                                                   cycle                          3.286
    Memory [%]                                                                           %                           1,25
    SOL DRAM                                                                             %                           0,97
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          13,31
    SOL L2 Cache                                                                         %                           1,25
    SM Active Cycles                                                                 cycle                         178,58
    SM [%]                                                                               %                           1,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,40
    Achieved Active Warps Per SM                                                      warp                          27,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:22:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,12
    SM Frequency                                                             cycle/usecond                         794,68
    Elapsed Cycles                                                                   cycle                          3.258
    Memory [%]                                                                           %                           1,19
    SOL DRAM                                                                             %                           1,03
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          13,38
    SOL L2 Cache                                                                         %                           1,19
    SM Active Cycles                                                                 cycle                         123,36
    SM [%]                                                                               %                           0,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,61
    Achieved Active Warps Per SM                                                      warp                          28,04
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:22:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,92
    SM Frequency                                                             cycle/usecond                         914,38
    Elapsed Cycles                                                                   cycle                          9.629
    Memory [%]                                                                           %                           1,14
    SOL DRAM                                                                             %                           0,48
    Duration                                                                       usecond                          10,53
    SOL L1/TEX Cache                                                                     %                          31,74
    SOL L2 Cache                                                                         %                           1,14
    SM Active Cycles                                                                 cycle                         224,78
    SM [%]                                                                               %                           0,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:22:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         923,78
    Elapsed Cycles                                                                   cycle                          2.869
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                          13,93
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          37,89
    SM [%]                                                                               %                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,99
    Achieved Active Warps Per SM                                                      warp                          19,84
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:22:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         924,67
    Elapsed Cycles                                                                   cycle                          2.845
    Memory [%]                                                                           %                           1,35
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                           5,48
    SOL L2 Cache                                                                         %                           1,35
    SM Active Cycles                                                                 cycle                         291,72
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:22:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         905,03
    Elapsed Cycles                                                                   cycle                          3.128
    Memory [%]                                                                           %                           1,64
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                           4,56
    SOL L2 Cache                                                                         %                           1,64
    SM Active Cycles                                                                 cycle                         350,97
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:22:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,92
    SM Frequency                                                             cycle/usecond                         914,19
    Elapsed Cycles                                                                   cycle                          4.213
    Memory [%]                                                                           %                           1,24
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                           7,08
    SOL L2 Cache                                                                         %                           1,24
    SM Active Cycles                                                                 cycle                          75,69
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,67
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:22:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,04
    SM Frequency                                                             cycle/usecond                         934,86
    Elapsed Cycles                                                                   cycle                          4.044
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,32
    SOL L1/TEX Cache                                                                     %                           6,34
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          70,53
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,08
    Achieved Active Warps Per SM                                                      warp                           8,67
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:22:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,92
    SM Frequency                                                             cycle/usecond                         763,36
    Elapsed Cycles                                                                   cycle                          2.664
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,44
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          33,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,96
    Achieved Active Warps Per SM                                                      warp                          17,59
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:22:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         763,89
    Elapsed Cycles                                                                   cycle                          2.643
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,81
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,31
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,52
    Achieved Active Warps Per SM                                                      warp                          18,09
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:23:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         764,66
    Elapsed Cycles                                                                   cycle                          2.619
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,82
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,65
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:23:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         779,87
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,62
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,68
    SOL L2 Cache                                                                         %                           0,62
    SM Active Cycles                                                                 cycle                          33,53
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,57
    Achieved Active Warps Per SM                                                      warp                          17,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:23:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         909,83
    Elapsed Cycles                                                                   cycle                          2.592
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           2,85
    SOL L1/TEX Cache                                                                     %                          12,99
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          31,22
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,94
    Achieved Active Warps Per SM                                                      warp                          18,54
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:23:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,90
    SM Frequency                                                             cycle/usecond                         918,49
    Elapsed Cycles                                                                   cycle                          2.854
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                           5,53
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         289,33
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:23:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         805,48
    Elapsed Cycles                                                                   cycle                          3.558
    Memory [%]                                                                           %                           1,40
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,42
    SOL L1/TEX Cache                                                                     %                           9,12
    SOL L2 Cache                                                                         %                           1,40
    SM Active Cycles                                                                 cycle                          58,17
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          40,60
    Achieved Active Warps Per SM                                                      warp                          12,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:23:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,14
    SM Frequency                                                             cycle/usecond                         796,29
    Elapsed Cycles                                                                   cycle                          8.282
    Memory [%]                                                                           %                           2,06
    SOL DRAM                                                                             %                           0,43
    Duration                                                                       usecond                          10,40
    SOL L1/TEX Cache                                                                     %                          68,18
    SOL L2 Cache                                                                         %                           2,06
    SM Active Cycles                                                                 cycle                         187,75
    SM [%]                                                                               %                           0,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,66
    Achieved Active Warps Per SM                                                      warp                          21,97
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:23:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,87
    SM Frequency                                                             cycle/usecond                         906,92
    Elapsed Cycles                                                                   cycle                         17.007
    Memory [%]                                                                           %                           1,49
    SOL DRAM                                                                             %                           0,32
    Duration                                                                       usecond                          18,75
    SOL L1/TEX Cache                                                                     %                          43,56
    SOL L2 Cache                                                                         %                           1,49
    SM Active Cycles                                                                 cycle                         426,89
    SM [%]                                                                               %                           0,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,86
    Achieved Active Warps Per SM                                                      warp                          13,72
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:23:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         770,10
    Elapsed Cycles                                                                   cycle                          2.860
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          13,69
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          38,36
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,39
    Achieved Active Warps Per SM                                                      warp                          18,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:23:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         800,48
    Elapsed Cycles                                                                   cycle                          3.332
    Memory [%]                                                                           %                           0,94
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                          10,24
    SOL L2 Cache                                                                         %                           0,94
    SM Active Cycles                                                                 cycle                          53,17
    SM [%]                                                                               %                           0,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,07
    Achieved Active Warps Per SM                                                      warp                          16,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         764,72
    Elapsed Cycles                                                                   cycle                          2.622
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,72
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,53
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,23
    Achieved Active Warps Per SM                                                      warp                          17,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:24:11, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,10
    SM Frequency                                                             cycle/usecond                         783,89
    Elapsed Cycles                                                                   cycle                          2.912
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,29
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,67
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:24:18, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,01
    SM Frequency                                                             cycle/usecond                         783,91
    Elapsed Cycles                                                                   cycle                          2.886
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          10,27
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,75
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,11
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         772,90
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,81
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,81
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,42
    Achieved Active Warps Per SM                                                      warp                          21,25
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         771,90
    Elapsed Cycles                                                                   cycle                          2.645
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,49
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,69
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,81
    Achieved Active Warps Per SM                                                      warp                          17,86
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         768,29
    Elapsed Cycles                                                                   cycle                          2.656
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,11
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          33,72
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,92
    Achieved Active Warps Per SM                                                      warp                          18,21
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,81
    SM Frequency                                                             cycle/usecond                         755,87
    Elapsed Cycles                                                                   cycle                          2.758
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          11,68
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          35,19
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,79
    Achieved Active Warps Per SM                                                      warp                          21,37
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         800,10
    Elapsed Cycles                                                                   cycle                          3.331
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,01
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,33
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,35
    Achieved Active Warps Per SM                                                      warp                          14,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:24:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,03
    SM Frequency                                                             cycle/usecond                         774,88
    Elapsed Cycles                                                                   cycle                          2.605
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          13,00
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,87
    Achieved Active Warps Per SM                                                      warp                          18,52
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         766,26
    Elapsed Cycles                                                                   cycle                          2.650
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,49
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,69
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,97
    Achieved Active Warps Per SM                                                      warp                          17,91
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         799,08
    Elapsed Cycles                                                                   cycle                          3.301
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                           8,02
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          51,28
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,34
    Achieved Active Warps Per SM                                                      warp                          14,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         790,03
    Elapsed Cycles                                                                   cycle                          3.313
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           8,05
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,08
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,24
    Achieved Active Warps Per SM                                                      warp                          14,48
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,01
    SM Frequency                                                             cycle/usecond                         768,47
    Elapsed Cycles                                                                   cycle                          2.731
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,70
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,89
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,00
    Achieved Active Warps Per SM                                                      warp                          21,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         775,91
    Elapsed Cycles                                                                   cycle                          2.734
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,80
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,83
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,22
    Achieved Active Warps Per SM                                                      warp                          21,19
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:25:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,02
    SM Frequency                                                             cycle/usecond                         778,15
    Elapsed Cycles                                                                   cycle                          3.015
    Memory [%]                                                                           %                           1,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,87
    SOL L1/TEX Cache                                                                     %                           9,67
    SOL L2 Cache                                                                         %                           1,69
    SM Active Cycles                                                                 cycle                          42,81
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,47
    Achieved Active Warps Per SM                                                      warp                          17,11
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:25:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         772,05
    Elapsed Cycles                                                                   cycle                          2.720
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,89
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,58
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,52
    Achieved Active Warps Per SM                                                      warp                          21,29
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:25:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         795,98
    Elapsed Cycles                                                                   cycle                          3.568
    Memory [%]                                                                           %                           1,87
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           4,48
    SOL L1/TEX Cache                                                                     %                           9,32
    SOL L2 Cache                                                                         %                           1,87
    SM Active Cycles                                                                 cycle                          56,64
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,59
    Achieved Active Warps Per SM                                                      warp                          13,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:26:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,11
    SM Frequency                                                             cycle/usecond                         792,36
    Elapsed Cycles                                                                   cycle                          3.297
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,13
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          50,58
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,92
    Achieved Active Warps Per SM                                                      warp                          14,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:26:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,62
    SM Frequency                                                             cycle/usecond                         866,45
    Elapsed Cycles                                                                   cycle                          4.521
    Memory [%]                                                                           %                           0,48
    SOL DRAM                                                                             %                           0,08
    Duration                                                                       usecond                           5,22
    SOL L1/TEX Cache                                                                     %                          22,11
    SOL L2 Cache                                                                         %                           0,48
    SM Active Cycles                                                                 cycle                          84,17
    SM [%]                                                                               %                           0,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,85
    Achieved Active Warps Per SM                                                      warp                          30,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:26:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,72
    SM Frequency                                                             cycle/usecond                         880,42
    Elapsed Cycles                                                                   cycle                          6.764
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,54
    Duration                                                                       usecond                           7,68
    SOL L1/TEX Cache                                                                     %                          23,75
    SOL L2 Cache                                                                         %                           1,73
    SM Active Cycles                                                                 cycle                         568,78
    SM [%]                                                                               %                           2,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:26:22, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,68
    SM Frequency                                                             cycle/usecond                         874,64
    Elapsed Cycles                                                                   cycle                          6.383
    Memory [%]                                                                           %                           3,57
    SOL DRAM                                                                             %                           0,24
    Duration                                                                       usecond                           7,30
    SOL L1/TEX Cache                                                                     %                          42,49
    SOL L2 Cache                                                                         %                           1,29
    SM Active Cycles                                                                 cycle                         535,58
    SM [%]                                                                               %                           3,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:26:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,14
    SM Frequency                                                             cycle/usecond                         797,69
    Elapsed Cycles                                                                   cycle                          3.321
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,32
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          50,72
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,28
    Achieved Active Warps Per SM                                                      warp                          14,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:26:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,25
    SM Frequency                                                             cycle/usecond                         817,65
    Elapsed Cycles                                                                   cycle                          3.275
    Memory [%]                                                                           %                           0,91
    SOL DRAM                                                                             %                           0,78
    Duration                                                                       usecond                              4
    SOL L1/TEX Cache                                                                     %                          18,82
    SOL L2 Cache                                                                         %                           0,91
    SM Active Cycles                                                                 cycle                          49,89
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,37
    Achieved Active Warps Per SM                                                      warp                          18,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:26:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,06
    SM Frequency                                                             cycle/usecond                         786,11
    Elapsed Cycles                                                                   cycle                          2.945
    Memory [%]                                                                           %                           2,24
    SOL DRAM                                                                             %                           2,24
    Duration                                                                       usecond                           3,74
    SOL L1/TEX Cache                                                                     %                          16,03
    SOL L2 Cache                                                                         %                           1,78
    SM Active Cycles                                                                 cycle                         148,33
    SM [%]                                                                               %                           0,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,75
    Achieved Active Warps Per SM                                                      warp                          27,44
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:26:47, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,01
    SM Frequency                                                             cycle/usecond                         929,58
    Elapsed Cycles                                                                   cycle                         10.150
    Memory [%]                                                                           %                           8,23
    SOL DRAM                                                                             %                           3,19
    Duration                                                                       usecond                          10,91
    SOL L1/TEX Cache                                                                     %                          36,11
    SOL L2 Cache                                                                         %                           3,50
    SM Active Cycles                                                                 cycle                       2.312,19
    SM [%]                                                                               %                           7,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:26:54, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,79
    SM Frequency                                                             cycle/usecond                         894,97
    Elapsed Cycles                                                                   cycle                          7.766
    Memory [%]                                                                           %                          17,41
    SOL DRAM                                                                             %                           2,08
    Duration                                                                       usecond                           8,67
    SOL L1/TEX Cache                                                                     %                          29,80
    SOL L2 Cache                                                                         %                           6,29
    SM Active Cycles                                                                 cycle                       5.584,03
    SM [%]                                                                               %                          17,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,97
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:27:01, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         947,82
    Elapsed Cycles                                                                   cycle                          4.007
    Memory [%]                                                                           %                           1,81
    SOL DRAM                                                                             %                           0,81
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                          28,33
    SOL L2 Cache                                                                         %                           0,91
    SM Active Cycles                                                                 cycle                         256,14
    SM [%]                                                                               %                           1,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,00
    Achieved Active Warps Per SM                                                      warp                          30,72
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:08, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,11
    SM Frequency                                                             cycle/usecond                         780,51
    Elapsed Cycles                                                                   cycle                          2.976
    Memory [%]                                                                           %                           6,32
    SOL DRAM                                                                             %                           6,32
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          17,46
    SOL L2 Cache                                                                         %                           4,56
    SM Active Cycles                                                                 cycle                         388,14
    SM [%]                                                                               %                           2,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,03
    Achieved Active Warps Per SM                                                      warp                          28,81
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,60
    SM Frequency                                                             cycle/usecond                         865,34
    Elapsed Cycles                                                                   cycle                          4.516
    Memory [%]                                                                           %                          13,74
    SOL DRAM                                                                             %                          13,74
    Duration                                                                       usecond                           5,22
    SOL L1/TEX Cache                                                                     %                          18,62
    SOL L2 Cache                                                                         %                           8,63
    SM Active Cycles                                                                 cycle                       1.119,81
    SM [%]                                                                               %                           5,35
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,28
    Achieved Active Warps Per SM                                                      warp                          28,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,28
    SM Frequency                                                             cycle/usecond                         822,79
    Elapsed Cycles                                                                   cycle                          3.135
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,10
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          10,29
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                             44
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          52,00
    Achieved Active Warps Per SM                                                      warp                          16,64
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:27:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,15
    SM Frequency                                                             cycle/usecond                         950,51
    Elapsed Cycles                                                                   cycle                         12.386
    Memory [%]                                                                           %                          41,97
    SOL DRAM                                                                             %                           3,23
    Duration                                                                       usecond                          13,02
    SOL L1/TEX Cache                                                                     %                          68,67
    SOL L2 Cache                                                                         %                          19,86
    SM Active Cycles                                                                 cycle                      10.341,92
    SM [%]                                                                               %                          41,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,83
    Achieved Active Warps Per SM                                                      warp                          14,67
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:27:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         951,38
    Elapsed Cycles                                                                   cycle                          3.443
    Memory [%]                                                                           %                           2,73
    SOL DRAM                                                                             %                           2,73
    Duration                                                                       usecond                           3,62
    SOL L1/TEX Cache                                                                     %                          17,49
    SOL L2 Cache                                                                         %                           2,45
    SM Active Cycles                                                                 cycle                         511,31
    SM [%]                                                                               %                           2,60
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,29
    Achieved Active Warps Per SM                                                      warp                          22,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,95
    SM Frequency                                                             cycle/usecond                         917,11
    Elapsed Cycles                                                                   cycle                          8.372
    Memory [%]                                                                           %                          54,86
    SOL DRAM                                                                             %                          54,86
    Duration                                                                       usecond                           9,12
    SOL L1/TEX Cache                                                                     %                          27,92
    SOL L2 Cache                                                                         %                          34,84
    SM Active Cycles                                                                 cycle                       5.853,86
    SM [%]                                                                               %                           6,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,28
    Achieved Active Warps Per SM                                                      warp                          27,29
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         798,26
    Elapsed Cycles                                                                   cycle                          3.119
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,25
    Duration                                                                       usecond                           3,90
    SOL L1/TEX Cache                                                                     %                          12,16
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          44,33
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,28
    Achieved Active Warps Per SM                                                      warp                          17,37
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:27:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,94
    SM Frequency                                                             cycle/usecond                         764,45
    Elapsed Cycles                                                                   cycle                          2.594
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,06
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,02
    Achieved Active Warps Per SM                                                      warp                          18,57
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:28:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,01
    SM Frequency                                                             cycle/usecond                         928,87
    Elapsed Cycles                                                                   cycle                         14.658
    Memory [%]                                                                           %                          30,57
    SOL DRAM                                                                             %                          17,79
    Duration                                                                       usecond                          15,78
    SOL L1/TEX Cache                                                                     %                          52,08
    SOL L2 Cache                                                                         %                          12,27
    SM Active Cycles                                                                 cycle                      10.287,08
    SM [%]                                                                               %                          30,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,94
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:28:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,35
    SM Frequency                                                             cycle/usecond                         824,97
    Elapsed Cycles                                                                   cycle                          4.918
    Memory [%]                                                                           %                          20,62
    SOL DRAM                                                                             %                          20,62
    Duration                                                                       usecond                           5,95
    SOL L1/TEX Cache                                                                     %                          10,90
    SOL L2 Cache                                                                         %                           9,41
    SM Active Cycles                                                                 cycle                       3.057,92
    SM [%]                                                                               %                           6,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,80
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:28:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,24
    SM Frequency                                                             cycle/usecond                         961,57
    Elapsed Cycles                                                                   cycle                          3.296
    Memory [%]                                                                           %                           3,25
    SOL DRAM                                                                             %                           3,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          14,38
    SOL L2 Cache                                                                         %                           3,25
    SM Active Cycles                                                                 cycle                         471,42
    SM [%]                                                                               %                           2,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,62
    Achieved Active Warps Per SM                                                      warp                          29,32
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:28:21, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,40
    SM Frequency                                                             cycle/usecond                         845,85
    Elapsed Cycles                                                                   cycle                          3.632
    Memory [%]                                                                           %                           2,68
    SOL DRAM                                                                             %                           2,68
    Duration                                                                       usecond                           4,29
    SOL L1/TEX Cache                                                                     %                          13,15
    SOL L2 Cache                                                                         %                           2,56
    SM Active Cycles                                                                 cycle                         315,56
    SM [%]                                                                               %                           2,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,99
    Achieved Active Warps Per SM                                                      warp                          28,16
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:28:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,14
    SM Frequency                                                             cycle/usecond                         952,80
    Elapsed Cycles                                                                   cycle                         15.736
    Memory [%]                                                                           %                           3,71
    SOL DRAM                                                                             %                           2,52
    Duration                                                                       usecond                          16,51
    SOL L1/TEX Cache                                                                     %                          37,15
    SOL L2 Cache                                                                         %                           2,56
    SM Active Cycles                                                                 cycle                       1.571,94
    SM [%]                                                                               %                           3,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:28:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,04
    SM Frequency                                                             cycle/usecond                         938,54
    Elapsed Cycles                                                                   cycle                          3.245
    Memory [%]                                                                           %                           1,26
    SOL DRAM                                                                             %                           1,09
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          13,38
    SOL L2 Cache                                                                         %                           1,26
    SM Active Cycles                                                                 cycle                         177,75
    SM [%]                                                                               %                           1,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,33
    Achieved Active Warps Per SM                                                      warp                          27,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:28:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,09
    SM Frequency                                                             cycle/usecond                         783,72
    Elapsed Cycles                                                                   cycle                          3.236
    Memory [%]                                                                           %                           1,20
    SOL DRAM                                                                             %                           1,08
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                          13,88
    SOL L2 Cache                                                                         %                           1,20
    SM Active Cycles                                                                 cycle                         118,92
    SM [%]                                                                               %                           0,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,05
    Achieved Active Warps Per SM                                                      warp                          28,18
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:28:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,91
    SM Frequency                                                             cycle/usecond                         912,29
    Elapsed Cycles                                                                   cycle                          9.730
    Memory [%]                                                                           %                           1,13
    SOL DRAM                                                                             %                           0,48
    Duration                                                                       usecond                          10,66
    SOL L1/TEX Cache                                                                     %                          31,56
    SOL L2 Cache                                                                         %                           1,13
    SM Active Cycles                                                                 cycle                            226
    SM [%]                                                                               %                           0,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:28:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,88
    SM Frequency                                                             cycle/usecond                         908,93
    Elapsed Cycles                                                                   cycle                          2.853
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,14
    SOL L1/TEX Cache                                                                     %                          13,95
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          37,83
    SM [%]                                                                               %                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,95
    Achieved Active Warps Per SM                                                      warp                          19,82
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:29:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,76
    SM Frequency                                                             cycle/usecond                         886,88
    Elapsed Cycles                                                                   cycle                          2.839
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,20
    SOL L1/TEX Cache                                                                     %                           5,51
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         290,33
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:29:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,78
    SM Frequency                                                             cycle/usecond                         902,55
    Elapsed Cycles                                                                   cycle                          3.121
    Memory [%]                                                                           %                           1,64
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                           4,56
    SOL L2 Cache                                                                         %                           1,64
    SM Active Cycles                                                                 cycle                         350,53
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:29:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,84
    SM Frequency                                                             cycle/usecond                         897,47
    Elapsed Cycles                                                                   cycle                          4.252
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,74
    SOL L1/TEX Cache                                                                     %                           8,39
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          75,78
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,67
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         924,95
    Elapsed Cycles                                                                   cycle                          4.027
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                           6,36
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          70,33
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,19
    Achieved Active Warps Per SM                                                      warp                           8,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         771,99
    Elapsed Cycles                                                                   cycle                          2.673
    Memory [%]                                                                           %                           0,66
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,40
    SOL L2 Cache                                                                         %                           0,66
    SM Active Cycles                                                                 cycle                          33,39
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,78
    Achieved Active Warps Per SM                                                      warp                          17,53
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         771,12
    Elapsed Cycles                                                                   cycle                          2.666
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,83
    SOL L2 Cache                                                                         %                           0,63
    SM Active Cycles                                                                 cycle                          32,25
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,52
    Achieved Active Warps Per SM                                                      warp                          18,09
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         759,90
    Elapsed Cycles                                                                   cycle                          2.628
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,82
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,28
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,65
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         781,14
    Elapsed Cycles                                                                   cycle                          2.750
    Memory [%]                                                                           %                           0,62
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          12,66
    SOL L2 Cache                                                                         %                           0,62
    SM Active Cycles                                                                 cycle                          33,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,48
    Achieved Active Warps Per SM                                                      warp                          17,44
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:29:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         911,10
    Elapsed Cycles                                                                   cycle                          2.596
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           2,85
    SOL L1/TEX Cache                                                                     %                          13,00
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          31,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,86
    Achieved Active Warps Per SM                                                      warp                          18,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:30:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         919,27
    Elapsed Cycles                                                                   cycle                          2.854
    Memory [%]                                                                           %                           1,31
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                           5,53
    SOL L2 Cache                                                                         %                           1,31
    SM Active Cycles                                                                 cycle                         289,53
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:30:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,19
    SM Frequency                                                             cycle/usecond                         800,95
    Elapsed Cycles                                                                   cycle                          3.538
    Memory [%]                                                                           %                           1,40
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,42
    SOL L1/TEX Cache                                                                     %                           9,29
    SOL L2 Cache                                                                         %                           1,40
    SM Active Cycles                                                                 cycle                          57,14
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          41,29
    Achieved Active Warps Per SM                                                      warp                          13,21
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:30:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,35
    SM Frequency                                                             cycle/usecond                         831,88
    Elapsed Cycles                                                                   cycle                          8.524
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,46
    Duration                                                                       usecond                          10,24
    SOL L1/TEX Cache                                                                     %                          63,93
    SOL L2 Cache                                                                         %                           2,00
    SM Active Cycles                                                                 cycle                         200,17
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          64,70
    Achieved Active Warps Per SM                                                      warp                          20,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:30:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,77
    SM Frequency                                                             cycle/usecond                         890,28
    Elapsed Cycles                                                                   cycle                         16.527
    Memory [%]                                                                           %                           1,54
    SOL DRAM                                                                             %                           0,29
    Duration                                                                       usecond                          18,56
    SOL L1/TEX Cache                                                                     %                          43,63
    SOL L2 Cache                                                                         %                           1,54
    SM Active Cycles                                                                 cycle                         426,72
    SM [%]                                                                               %                           0,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,88
    Achieved Active Warps Per SM                                                      warp                          13,72
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:30:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         770,80
    Elapsed Cycles                                                                   cycle                          2.864
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          13,64
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          38,50
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,28
    Achieved Active Warps Per SM                                                      warp                          18,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:30:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,28
    SM Frequency                                                             cycle/usecond                         814,89
    Elapsed Cycles                                                                   cycle                          3.339
    Memory [%]                                                                           %                           0,92
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          10,60
    SOL L2 Cache                                                                         %                           0,92
    SM Active Cycles                                                                 cycle                          51,36
    SM [%]                                                                               %                           0,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,84
    Achieved Active Warps Per SM                                                      warp                          17,23
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:30:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,80
    SM Frequency                                                             cycle/usecond                         750,57
    Elapsed Cycles                                                                   cycle                          2.643
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          12,79
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,36
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,51
    Achieved Active Warps Per SM                                                      warp                          18,08
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:30:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         780,60
    Elapsed Cycles                                                                   cycle                          2.902
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,26
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,81
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,11
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:30:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         793,53
    Elapsed Cycles                                                                   cycle                          2.925
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          10,29
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,67
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         777,01
    Elapsed Cycles                                                                   cycle                          2.712
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          11,74
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          35,03
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,10
    Achieved Active Warps Per SM                                                      warp                          21,15
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:11, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         769,33
    Elapsed Cycles                                                                   cycle                          2.660
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,50
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,67
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,02
    Achieved Active Warps Per SM                                                      warp                          17,93
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:18, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         762,96
    Elapsed Cycles                                                                   cycle                          2.638
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,51
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,64
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,90
    Achieved Active Warps Per SM                                                      warp                          17,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:25, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,13
    SM Frequency                                                             cycle/usecond                         789,98
    Elapsed Cycles                                                                   cycle                          3.314
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           8,06
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,03
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,29
    Achieved Active Warps Per SM                                                      warp                          14,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:32, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,13
    SM Frequency                                                             cycle/usecond                         785,45
    Elapsed Cycles                                                                   cycle                          3.294
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           7,94
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          51,75
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          44,75
    Achieved Active Warps Per SM                                                      warp                          14,32
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:39, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         788,46
    Elapsed Cycles                                                                   cycle                          2.805
    Memory [%]                                                                           %                           0,74
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          10,60
    SOL L2 Cache                                                                         %                           0,74
    SM Active Cycles                                                                 cycle                          38,53
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          59,85
    Achieved Active Warps Per SM                                                      warp                          19,15
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:31:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         773,18
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,76
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,94
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,09
    Achieved Active Warps Per SM                                                      warp                          21,15
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:31:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         767,07
    Elapsed Cycles                                                                   cycle                          3.020
    Memory [%]                                                                           %                           1,68
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           3,94
    SOL L1/TEX Cache                                                                     %                           9,70
    SOL L2 Cache                                                                         %                           1,68
    SM Active Cycles                                                                 cycle                          42,67
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,69
    Achieved Active Warps Per SM                                                      warp                          17,18
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:32:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,95
    SM Frequency                                                             cycle/usecond                         771,93
    Elapsed Cycles                                                                   cycle                          2.718
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,88
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,61
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,62
    Achieved Active Warps Per SM                                                      warp                          21,32
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:32:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         774,69
    Elapsed Cycles                                                                   cycle                          3.521
    Memory [%]                                                                           %                           1,90
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           4,54
    SOL L1/TEX Cache                                                                     %                           9,34
    SOL L2 Cache                                                                         %                           1,90
    SM Active Cycles                                                                 cycle                          56,50
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,75
    Achieved Active Warps Per SM                                                      warp                          13,68
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:32:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,97
    SM Frequency                                                             cycle/usecond                         776,52
    Elapsed Cycles                                                                   cycle                          3.282
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                           8,13
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          50,58
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,61
    Achieved Active Warps Per SM                                                      warp                          14,59
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:32:21, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         771,09
    Elapsed Cycles                                                                   cycle                          4.544
    Memory [%]                                                                           %                           0,63
    SOL DRAM                                                                             %                           0,08
    Duration                                                                       usecond                           5,89
    SOL L1/TEX Cache                                                                     %                          24,41
    SOL L2 Cache                                                                         %                           0,48
    SM Active Cycles                                                                 cycle                         116,31
    SM [%]                                                                               %                           0,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          97,41
    Achieved Active Warps Per SM                                                      warp                          31,17
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:32:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,73
    SM Frequency                                                             cycle/usecond                         889,30
    Elapsed Cycles                                                                   cycle                          6.718
    Memory [%]                                                                           %                           2,01
    SOL DRAM                                                                             %                           0,53
    Duration                                                                       usecond                           7,55
    SOL L1/TEX Cache                                                                     %                          23,47
    SOL L2 Cache                                                                         %                           1,74
    SM Active Cycles                                                                 cycle                         575,64
    SM [%]                                                                               %                           2,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:32:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,82
    SM Frequency                                                             cycle/usecond                         901,05
    Elapsed Cycles                                                                   cycle                          6.520
    Memory [%]                                                                           %                           3,49
    SOL DRAM                                                                             %                           0,25
    Duration                                                                       usecond                           7,23
    SOL L1/TEX Cache                                                                     %                          42,65
    SOL L2 Cache                                                                         %                           1,26
    SM Active Cycles                                                                 cycle                         533,58
    SM [%]                                                                               %                           3,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:32:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         806,45
    Elapsed Cycles                                                                   cycle                          3.304
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          10,31
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          50,67
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,38
    Achieved Active Warps Per SM                                                      warp                          14,52
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:32:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,25
    SM Frequency                                                             cycle/usecond                         824,20
    Elapsed Cycles                                                                   cycle                          3.300
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,73
    Duration                                                                       usecond                              4
    SOL L1/TEX Cache                                                                     %                          16,86
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          49,75
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,21
    Achieved Active Warps Per SM                                                      warp                          18,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:32:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,87
    SM Frequency                                                             cycle/usecond                         759,38
    Elapsed Cycles                                                                   cycle                          2.919
    Memory [%]                                                                           %                           2,19
    SOL DRAM                                                                             %                           2,19
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          16,07
    SOL L2 Cache                                                                         %                           1,79
    SM Active Cycles                                                                 cycle                            148
    SM [%]                                                                               %                           0,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,34
    Achieved Active Warps Per SM                                                      warp                          27,31
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:33:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         917,54
    Elapsed Cycles                                                                   cycle                          9.989
    Memory [%]                                                                           %                           8,36
    SOL DRAM                                                                             %                           3,24
    Duration                                                                       usecond                          10,88
    SOL L1/TEX Cache                                                                     %                          36,10
    SOL L2 Cache                                                                         %                           3,56
    SM Active Cycles                                                                 cycle                       2.313,28
    SM [%]                                                                               %                           7,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:33:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,78
    SM Frequency                                                             cycle/usecond                         892,62
    Elapsed Cycles                                                                   cycle                          7.774
    Memory [%]                                                                           %                          17,39
    SOL DRAM                                                                             %                           2,12
    Duration                                                                       usecond                           8,70
    SOL L1/TEX Cache                                                                     %                          29,78
    SOL L2 Cache                                                                         %                           6,28
    SM Active Cycles                                                                 cycle                       5.631,75
    SM [%]                                                                               %                          17,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,96
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:33:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,35
    SM Frequency                                                             cycle/usecond                         982,87
    Elapsed Cycles                                                                   cycle                          4.122
    Memory [%]                                                                           %                           1,73
    SOL DRAM                                                                             %                           0,79
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                          27,78
    SOL L2 Cache                                                                         %                           0,88
    SM Active Cycles                                                                 cycle                         257,22
    SM [%]                                                                               %                           1,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          95,94
    Achieved Active Warps Per SM                                                      warp                          30,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:33:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         766,93
    Elapsed Cycles                                                                   cycle                          2.947
    Memory [%]                                                                           %                           6,47
    SOL DRAM                                                                             %                           6,47
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          17,38
    SOL L2 Cache                                                                         %                           4,61
    SM Active Cycles                                                                 cycle                            390
    SM [%]                                                                               %                           2,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,24
    Achieved Active Warps Per SM                                                      warp                          28,88
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:33:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,66
    SM Frequency                                                             cycle/usecond                         877,76
    Elapsed Cycles                                                                   cycle                          4.524
    Memory [%]                                                                           %                          13,72
    SOL DRAM                                                                             %                          13,72
    Duration                                                                       usecond                           5,15
    SOL L1/TEX Cache                                                                     %                          18,57
    SOL L2 Cache                                                                         %                           8,62
    SM Active Cycles                                                                 cycle                       1.123,31
    SM [%]                                                                               %                           5,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,44
    Achieved Active Warps Per SM                                                      warp                          28,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:33:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,25
    SM Frequency                                                             cycle/usecond                         807,26
    Elapsed Cycles                                                                   cycle                          3.049
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,11
    Duration                                                                       usecond                           3,78
    SOL L1/TEX Cache                                                                     %                          10,02
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          45,17
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          50,56
    Achieved Active Warps Per SM                                                      warp                          16,18
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:33:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,19
    SM Frequency                                                             cycle/usecond                         951,01
    Elapsed Cycles                                                                   cycle                         12.419
    Memory [%]                                                                           %                          41,84
    SOL DRAM                                                                             %                           3,35
    Duration                                                                       usecond                          13,06
    SOL L1/TEX Cache                                                                     %                          68,49
    SOL L2 Cache                                                                         %                          19,81
    SM Active Cycles                                                                 cycle                      10.327,78
    SM [%]                                                                               %                          41,84
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,80
    Achieved Active Warps Per SM                                                      warp                          14,65
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:33:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,84
    SM Frequency                                                             cycle/usecond                         913,86
    Elapsed Cycles                                                                   cycle                          3.365
    Memory [%]                                                                           %                           2,80
    SOL DRAM                                                                             %                           2,80
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          17,33
    SOL L2 Cache                                                                         %                           2,49
    SM Active Cycles                                                                 cycle                            516
    SM [%]                                                                               %                           2,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,56
    Achieved Active Warps Per SM                                                      warp                          22,58
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:33:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,99
    SM Frequency                                                             cycle/usecond                         922,57
    Elapsed Cycles                                                                   cycle                          8.451
    Memory [%]                                                                           %                          54,54
    SOL DRAM                                                                             %                          54,54
    Duration                                                                       usecond                           9,15
    SOL L1/TEX Cache                                                                     %                          28,42
    SOL L2 Cache                                                                         %                          34,53
    SM Active Cycles                                                                 cycle                       5.750,31
    SM [%]                                                                               %                           6,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,47
    Achieved Active Warps Per SM                                                      warp                          27,67
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,20
    SM Frequency                                                             cycle/usecond                         800,62
    Elapsed Cycles                                                                   cycle                          3.081
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,24
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          12,19
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          44,19
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,31
    Achieved Active Warps Per SM                                                      warp                          17,38
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         769,04
    Elapsed Cycles                                                                   cycle                          2.614
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,03
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,33
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          58,10
    Achieved Active Warps Per SM                                                      warp                          18,59
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         763,83
    Elapsed Cycles                                                                   cycle                          2.645
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,47
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,75
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,72
    Achieved Active Warps Per SM                                                      warp                          17,83
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,01
    SM Frequency                                                             cycle/usecond                         770,21
    Elapsed Cycles                                                                   cycle                          2.738
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,72
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,83
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,37
    Achieved Active Warps Per SM                                                      warp                          21,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,08
    SM Frequency                                                             cycle/usecond                         796,73
    Elapsed Cycles                                                                   cycle                          3.319
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,03
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,19
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,10
    Achieved Active Warps Per SM                                                      warp                          14,43
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:34:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         770,58
    Elapsed Cycles                                                                   cycle                          2.616
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          12,68
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          32,19
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,54
    Achieved Active Warps Per SM                                                      warp                          18,09
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:34:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         921,37
    Elapsed Cycles                                                                   cycle                         14.570
    Memory [%]                                                                           %                          30,76
    SOL DRAM                                                                             %                          17,83
    Duration                                                                       usecond                          15,81
    SOL L1/TEX Cache                                                                     %                          52,42
    SOL L2 Cache                                                                         %                          12,35
    SM Active Cycles                                                                 cycle                         10.408
    SM [%]                                                                               %                          30,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,94
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:34:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,16
    SM Frequency                                                             cycle/usecond                         799,54
    Elapsed Cycles                                                                   cycle                          4.840
    Memory [%]                                                                           %                          20,80
    SOL DRAM                                                                             %                          20,80
    Duration                                                                       usecond                           6,05
    SOL L1/TEX Cache                                                                     %                          10,91
    SOL L2 Cache                                                                         %                           9,56
    SM Active Cycles                                                                 cycle                       3.053,92
    SM [%]                                                                               %                           6,85
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,91
    Achieved Active Warps Per SM                                                      warp                           7,97
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:35:02, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,17
    SM Frequency                                                             cycle/usecond                         950,47
    Elapsed Cycles                                                                   cycle                          3.257
    Memory [%]                                                                           %                           3,28
    SOL DRAM                                                                             %                           3,11
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          14,39
    SOL L2 Cache                                                                         %                           3,28
    SM Active Cycles                                                                 cycle                         470,92
    SM [%]                                                                               %                           2,98
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          90,92
    Achieved Active Warps Per SM                                                      warp                          29,09
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:35:09, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         807,12
    Elapsed Cycles                                                                   cycle                          3.514
    Memory [%]                                                                           %                           2,82
    SOL DRAM                                                                             %                           2,82
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                          13,05
    SOL L2 Cache                                                                         %                           2,65
    SM Active Cycles                                                                 cycle                         318,08
    SM [%]                                                                               %                           2,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,94
    Achieved Active Warps Per SM                                                      warp                          28,14
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:35:16, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,13
    SM Frequency                                                             cycle/usecond                         946,73
    Elapsed Cycles                                                                   cycle                         15.699
    Memory [%]                                                                           %                           3,72
    SOL DRAM                                                                             %                           2,46
    Duration                                                                       usecond                          16,58
    SOL L1/TEX Cache                                                                     %                          37,32
    SOL L2 Cache                                                                         %                           2,57
    SM Active Cycles                                                                 cycle                       1.564,69
    SM [%]                                                                               %                           3,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:35:23, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,13
    SM Frequency                                                             cycle/usecond                         938,26
    Elapsed Cycles                                                                   cycle                          3.216
    Memory [%]                                                                           %                           1,28
    SOL DRAM                                                                             %                           1,05
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          13,14
    SOL L2 Cache                                                                         %                           1,28
    SM Active Cycles                                                                 cycle                         180,92
    SM [%]                                                                               %                           1,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,36
    Achieved Active Warps Per SM                                                      warp                          26,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:35:30, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,12
    SM Frequency                                                             cycle/usecond                         786,62
    Elapsed Cycles                                                                   cycle                          3.225
    Memory [%]                                                                           %                           1,21
    SOL DRAM                                                                             %                           1,07
    Duration                                                                       usecond                           4,10
    SOL L1/TEX Cache                                                                     %                          13,83
    SOL L2 Cache                                                                         %                           1,21
    SM Active Cycles                                                                 cycle                         119,28
    SM [%]                                                                               %                           0,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,19
    Achieved Active Warps Per SM                                                      warp                          28,22
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:35:37, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,92
    SM Frequency                                                             cycle/usecond                         916,77
    Elapsed Cycles                                                                   cycle                          9.652
    Memory [%]                                                                           %                           1,13
    SOL DRAM                                                                             %                           0,50
    Duration                                                                       usecond                          10,53
    SOL L1/TEX Cache                                                                     %                          31,30
    SOL L2 Cache                                                                         %                           1,13
    SM Active Cycles                                                                 cycle                         227,89
    SM [%]                                                                               %                           0,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:35:44, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         920,57
    Elapsed Cycles                                                                   cycle                          2.830
    Memory [%]                                                                           %                           0,73
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                          13,98
    SOL L2 Cache                                                                         %                           0,73
    SM Active Cycles                                                                 cycle                          37,75
    SM [%]                                                                               %                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,96
    Achieved Active Warps Per SM                                                      warp                          19,83
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:35:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,94
    SM Frequency                                                             cycle/usecond                         916,11
    Elapsed Cycles                                                                   cycle                          2.845
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,10
    SOL L1/TEX Cache                                                                     %                           5,54
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         288,89
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:35:58, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,81
    SM Frequency                                                             cycle/usecond                         901,85
    Elapsed Cycles                                                                   cycle                          3.118
    Memory [%]                                                                           %                           1,64
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                           4,55
    SOL L2 Cache                                                                         %                           1,64
    SM Active Cycles                                                                 cycle                         351,92
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:36:05, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         914,14
    Elapsed Cycles                                                                   cycle                          4.242
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                           6,69
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          80,14
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,72
    Achieved Active Warps Per SM                                                      warp                           3,75
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:12, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,09
    SM Frequency                                                             cycle/usecond                         935,07
    Elapsed Cycles                                                                   cycle                          4.015
    Memory [%]                                                                           %                           1,24
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,29
    SOL L1/TEX Cache                                                                     %                           6,34
    SOL L2 Cache                                                                         %                           1,24
    SM Active Cycles                                                                 cycle                          70,58
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,41
    Achieved Active Warps Per SM                                                      warp                           8,77
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:19, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         771,64
    Elapsed Cycles                                                                   cycle                          2.668
    Memory [%]                                                                           %                           0,65
    SOL DRAM                                                                             %                           0,06
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,41
    SOL L2 Cache                                                                         %                           0,65
    SM Active Cycles                                                                 cycle                          33,36
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,75
    Achieved Active Warps Per SM                                                      warp                          17,52
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         758,56
    Elapsed Cycles                                                                   cycle                          2.625
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,86
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,19
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,62
    Achieved Active Warps Per SM                                                      warp                          18,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<unsigned char const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,89
    SM Frequency                                                             cycle/usecond                         763,66
    Elapsed Cycles                                                                   cycle                          2.641
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,88
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,14
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,63
    Achieved Active Warps Per SM                                                      warp                          18,12
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,99
    SM Frequency                                                             cycle/usecond                         764,97
    Elapsed Cycles                                                                   cycle                          2.669
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,71
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          33,44
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,62
    Achieved Active Warps Per SM                                                      warp                          17,48
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:36:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,87
    SM Frequency                                                             cycle/usecond                         908,54
    Elapsed Cycles                                                                   cycle                          2.619
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           2,88
    SOL L1/TEX Cache                                                                     %                          13,04
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          31,31
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,96
    Achieved Active Warps Per SM                                                      warp                          18,55
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:36:51, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,88
    SM Frequency                                                             cycle/usecond                         921,48
    Elapsed Cycles                                                                   cycle                          2.832
    Memory [%]                                                                           %                           1,33
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                           5,53
    SOL L2 Cache                                                                         %                           1,33
    SM Active Cycles                                                                 cycle                         289,08
    SM [%]                                                                               %                           0,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorReshapingOp<Eigen::IndexList<int, Eigen::type2index<1l> > const, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> > const> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:36:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,22
    SM Frequency                                                             cycle/usecond                         810,73
    Elapsed Cycles                                                                   cycle                          3.587
    Memory [%]                                                                           %                           1,39
    SOL DRAM                                                                             %                           0,17
    Duration                                                                       usecond                           4,42
    SOL L1/TEX Cache                                                                     %                           9,10
    SOL L2 Cache                                                                         %                           1,39
    SM Active Cycles                                                                 cycle                          58,31
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          40,65
    Achieved Active Warps Per SM                                                      warp                          13,01
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:37:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,36
    SM Frequency                                                             cycle/usecond                         831,41
    Elapsed Cycles                                                                   cycle                          8.514
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,39
    Duration                                                                       usecond                          10,24
    SOL L1/TEX Cache                                                                     %                          68,09
    SOL L2 Cache                                                                         %                           2,00
    SM Active Cycles                                                                 cycle                            188
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             54
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,57
    Achieved Active Warps Per SM                                                      warp                          21,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:37:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,72
    SM Frequency                                                             cycle/usecond                         885,19
    Elapsed Cycles                                                                   cycle                         15.837
    Memory [%]                                                                           %                           1,61
    SOL DRAM                                                                             %                           0,23
    Duration                                                                       usecond                          17,89
    SOL L1/TEX Cache                                                                     %                          46,69
    SOL L2 Cache                                                                         %                           1,61
    SM Active Cycles                                                                 cycle                         398,67
    SM [%]                                                                               %                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             62
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          46,92
    Achieved Active Warps Per SM                                                      warp                          15,01
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:37:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         780,48
    Elapsed Cycles                                                                   cycle                          2.848
    Memory [%]                                                                           %                           0,82
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          13,44
    SOL L2 Cache                                                                         %                           0,82
    SM Active Cycles                                                                 cycle                          39,06
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          56,66
    Achieved Active Warps Per SM                                                      warp                          18,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, long long>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:37:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         804,65
    Elapsed Cycles                                                                   cycle                          3.324
    Memory [%]                                                                           %                           0,92
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                          10,66
    SOL L2 Cache                                                                         %                           0,92
    SM Active Cycles                                                                 cycle                          51,08
    SM [%]                                                                               %                           0,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,01
    Achieved Active Warps Per SM                                                      warp                          17,28
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:37:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         760,24
    Elapsed Cycles                                                                   cycle                          2.630
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,77
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          32,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,08
    Achieved Active Warps Per SM                                                      warp                          18,27
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:37:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,10
    SM Frequency                                                             cycle/usecond                         783,24
    Elapsed Cycles                                                                   cycle                          2.909
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,34
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,50
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,09
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type), 2021-May-03 21:37:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,07
    SM Frequency                                                             cycle/usecond                         780,06
    Elapsed Cycles                                                                   cycle                          2.898
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,71
    SOL L1/TEX Cache                                                                     %                          10,30
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          39,64
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                             48
    Threads                                                                         thread                            256
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          23,10
    Achieved Active Warps Per SM                                                      warp                           7,39
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:37:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              5
    SM Frequency                                                             cycle/usecond                         772,43
    Elapsed Cycles                                                                   cycle                          2.770
    Memory [%]                                                                           %                           0,75
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,58
    SOL L1/TEX Cache                                                                     %                          11,84
    SOL L2 Cache                                                                         %                           0,75
    SM Active Cycles                                                                 cycle                          34,72
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,42
    Achieved Active Warps Per SM                                                      warp                          21,25
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:37:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,92
    SM Frequency                                                             cycle/usecond                         754,87
    Elapsed Cycles                                                                   cycle                          2.635
    Memory [%]                                                                           %                           0,69
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,53
    SOL L2 Cache                                                                         %                           0,69
    SM Active Cycles                                                                 cycle                          32,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,91
    Achieved Active Warps Per SM                                                      warp                          17,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         767,13
    Elapsed Cycles                                                                   cycle                          2.652
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          12,53
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,58
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,91
    Achieved Active Warps Per SM                                                      warp                          17,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:11, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,04
    SM Frequency                                                             cycle/usecond                         785,97
    Elapsed Cycles                                                                   cycle                          3.300
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,19
    SOL L1/TEX Cache                                                                     %                           8,08
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          50,86
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,27
    Achieved Active Warps Per SM                                                      warp                          14,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:18, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         776,93
    Elapsed Cycles                                                                   cycle                          3.308
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           4,26
    SOL L1/TEX Cache                                                                     %                           8,06
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                          51,03
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,24
    Achieved Active Warps Per SM                                                      warp                          14,48
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:25, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,98
    SM Frequency                                                             cycle/usecond                         768,81
    Elapsed Cycles                                                                   cycle                          2.708
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,76
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          34,72
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             21
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,07
    Achieved Active Warps Per SM                                                      warp                          21,14
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:32, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,14
    SM Frequency                                                             cycle/usecond                         781,19
    Elapsed Cycles                                                                   cycle                          2.727
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          11,31
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          36,36
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          63,64
    Achieved Active Warps Per SM                                                      warp                          20,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:38:39, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,94
    SM Frequency                                                             cycle/usecond                         760,87
    Elapsed Cycles                                                                   cycle                          2.996
    Memory [%]                                                                           %                           1,70
    SOL DRAM                                                                             %                           0,02
    Duration                                                                       usecond                           3,94
    SOL L1/TEX Cache                                                                     %                           9,69
    SOL L2 Cache                                                                         %                           1,70
    SM Active Cycles                                                                 cycle                          42,69
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          53,54
    Achieved Active Warps Per SM                                                      warp                          17,13
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:38:46, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,05
    SM Frequency                                                             cycle/usecond                         769,48
    Elapsed Cycles                                                                   cycle                          2.735
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,55
    SOL L1/TEX Cache                                                                     %                          11,87
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,64
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,65
    Achieved Active Warps Per SM                                                      warp                          21,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int), 2021-May-03 21:38:53, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,06
    SM Frequency                                                             cycle/usecond                         781,07
    Elapsed Cycles                                                                   cycle                          3.501
    Memory [%]                                                                           %                           1,91
    SOL DRAM                                                                             %                           0,21
    Duration                                                                       usecond                           4,48
    SOL L1/TEX Cache                                                                     %                           9,31
    SOL L2 Cache                                                                         %                           1,91
    SM Active Cycles                                                                 cycle                          56,67
    SM [%]                                                                               %                           0,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          42,57
    Achieved Active Warps Per SM                                                      warp                          13,62
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:39:00, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         792,40
    Elapsed Cycles                                                                   cycle                          3.297
    Memory [%]                                                                           %                           0,99
    SOL DRAM                                                                             %                           0,01
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,16
    SOL L2 Cache                                                                         %                           0,99
    SM Active Cycles                                                                 cycle                          50,39
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,72
    Achieved Active Warps Per SM                                                      warp                          14,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:39:07, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,96
    SM Frequency                                                             cycle/usecond                         767,73
    Elapsed Cycles                                                                   cycle                          4.521
    Memory [%]                                                                           %                           0,48
    SOL DRAM                                                                             %                           0,09
    Duration                                                                       usecond                           5,89
    SOL L1/TEX Cache                                                                     %                          21,86
    SOL L2 Cache                                                                         %                           0,48
    SM Active Cycles                                                                 cycle                          93,28
    SM [%]                                                                               %                           0,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                             40
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            256
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          96,77
    Achieved Active Warps Per SM                                                      warp                          30,97
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:39:14, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,71
    SM Frequency                                                             cycle/usecond                         882,66
    Elapsed Cycles                                                                   cycle                          6.753
    Memory [%]                                                                           %                           2,00
    SOL DRAM                                                                             %                           0,57
    Duration                                                                       usecond                           7,65
    SOL L1/TEX Cache                                                                     %                          23,75
    SOL L2 Cache                                                                         %                           1,73
    SM Active Cycles                                                                 cycle                         568,92
    SM [%]                                                                               %                           2,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          12,48
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_tn, 2021-May-03 21:39:21, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,49
    SM Frequency                                                             cycle/usecond                         856,12
    Elapsed Cycles                                                                   cycle                          6.387
    Memory [%]                                                                           %                           3,56
    SOL DRAM                                                                             %                           0,22
    Duration                                                                       usecond                           7,46
    SOL L1/TEX Cache                                                                     %                          42,47
    SOL L2 Cache                                                                         %                           1,29
    SM Active Cycles                                                                 cycle                         535,86
    SM [%]                                                                               %                           3,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,82
    Achieved Active Warps Per SM                                                      warp                           7,94
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:39:28, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         802,28
    Elapsed Cycles                                                                   cycle                          3.313
    Memory [%]                                                                           %                           0,64
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                           8,33
    SOL L2 Cache                                                                         %                           0,64
    SM Active Cycles                                                                 cycle                          50,69
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,35
    Achieved Active Warps Per SM                                                      warp                          14,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:39:35, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         814,48
    Elapsed Cycles                                                                   cycle                          3.287
    Memory [%]                                                                           %                           0,90
    SOL DRAM                                                                             %                           0,77
    Duration                                                                       usecond                           4,03
    SOL L1/TEX Cache                                                                     %                          16,77
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                          50,03
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,36
    Achieved Active Warps Per SM                                                      warp                          18,36
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:39:42, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,16
    SM Frequency                                                             cycle/usecond                         788,94
    Elapsed Cycles                                                                   cycle                          2.956
    Memory [%]                                                                           %                           2,17
    SOL DRAM                                                                             %                           2,17
    Duration                                                                       usecond                           3,74
    SOL L1/TEX Cache                                                                     %                          15,90
    SOL L2 Cache                                                                         %                           1,77
    SM Active Cycles                                                                 cycle                         149,53
    SM [%]                                                                               %                           0,80
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,56
    Achieved Active Warps Per SM                                                      warp                          27,38
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_tn, 2021-May-03 21:39:49, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,93
    SM Frequency                                                             cycle/usecond                         916,36
    Elapsed Cycles                                                                   cycle                          9.975
    Memory [%]                                                                           %                           8,37
    SOL DRAM                                                                             %                           3,24
    Duration                                                                       usecond                          10,88
    SOL L1/TEX Cache                                                                     %                          36,20
    SOL L2 Cache                                                                         %                           3,56
    SM Active Cycles                                                                 cycle                       2.306,67
    SM [%]                                                                               %                           7,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                          1.280
    Waves Per SM                                                                                                     0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nt, 2021-May-03 21:39:56, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,72
    SM Frequency                                                             cycle/usecond                         886,93
    Elapsed Cycles                                                                   cycle                          7.727
    Memory [%]                                                                           %                          17,50
    SOL DRAM                                                                             %                           2,14
    Duration                                                                       usecond                           8,70
    SOL L1/TEX Cache                                                                     %                          29,96
    SOL L2 Cache                                                                         %                           6,32
    SM Active Cycles                                                                 cycle                       5.588,86
    SM [%]                                                                               %                          17,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          40
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          5.120
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          13,97
    Achieved Active Warps Per SM                                                      warp                           4,47
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int), 2021-May-03 21:40:03, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,18
    SM Frequency                                                             cycle/usecond                         955,82
    Elapsed Cycles                                                                   cycle                          4.040
    Memory [%]                                                                           %                           1,74
    SOL DRAM                                                                             %                           0,80
    Duration                                                                       usecond                           4,22
    SOL L1/TEX Cache                                                                     %                          27,10
    SOL L2 Cache                                                                         %                           0,90
    SM Active Cycles                                                                 cycle                         258,75
    SM [%]                                                                               %                           1,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             17
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                            400
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                            128
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          95,97
    Achieved Active Warps Per SM                                                      warp                          30,71
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,11
    SM Frequency                                                             cycle/usecond                         778,31
    Elapsed Cycles                                                                   cycle                          2.968
    Memory [%]                                                                           %                           6,43
    SOL DRAM                                                                             %                           6,43
    Duration                                                                       usecond                           3,81
    SOL L1/TEX Cache                                                                     %                          15,97
    SOL L2 Cache                                                                         %                           4,58
    SM Active Cycles                                                                 cycle                         424,53
    SM [%]                                                                               %                           2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          89,97
    Achieved Active Warps Per SM                                                      warp                          28,79
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:15, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,60
    SM Frequency                                                             cycle/usecond                         867,41
    Elapsed Cycles                                                                   cycle                          4.526
    Memory [%]                                                                           %                          13,53
    SOL DRAM                                                                             %                          13,53
    Duration                                                                       usecond                           5,22
    SOL L1/TEX Cache                                                                     %                          18,66
    SOL L2 Cache                                                                         %                           8,62
    SM Active Cycles                                                                 cycle                       1.117,61
    SM [%]                                                                               %                           5,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         30.720
    Waves Per SM                                                                                                     0,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          89,98
    Achieved Active Warps Per SM                                                      warp                          28,79
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:22, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,20
    SM Frequency                                                             cycle/usecond                         798,65
    Elapsed Cycles                                                                   cycle                          3.068
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,11
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          10,33
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          43,83
    SM [%]                                                                               %                           0,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          52,00
    Achieved Active Warps Per SM                                                      warp                          16,64
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x128_nt, 2021-May-03 21:40:29, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,18
    SM Frequency                                                             cycle/usecond                         952,46
    Elapsed Cycles                                                                   cycle                         12.473
    Memory [%]                                                                           %                          41,68
    SOL DRAM                                                                             %                           3,29
    Duration                                                                       usecond                          13,09
    SOL L1/TEX Cache                                                                     %                          68,21
    SOL L2 Cache                                                                         %                          19,72
    SM Active Cycles                                                                 cycle                      10.354,19
    SM [%]                                                                               %                          41,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          70
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                         17.920
    Waves Per SM                                                                                                     0,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,71
    Achieved Active Warps Per SM                                                      warp                          14,63
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type), 2021-May-03 21:40:36, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,98
    SM Frequency                                                             cycle/usecond                         934,62
    Elapsed Cycles                                                                   cycle                          3.381
    Memory [%]                                                                           %                           2,79
    SOL DRAM                                                                             %                           2,79
    Duration                                                                       usecond                           3,62
    SOL L1/TEX Cache                                                                     %                          17,50
    SOL L2 Cache                                                                         %                           2,48
    SM Active Cycles                                                                 cycle                         511,14
    SM [%]                                                                               %                           2,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                           4,22
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             15
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,28
    Achieved Active Warps Per SM                                                      warp                          22,49
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:43, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,01
    SM Frequency                                                             cycle/usecond                         925,57
    Elapsed Cycles                                                                   cycle                          8.445
    Memory [%]                                                                           %                          54,55
    SOL DRAM                                                                             %                          54,55
    Duration                                                                       usecond                           9,12
    SOL L1/TEX Cache                                                                     %                          28,63
    SOL L2 Cache                                                                         %                          34,55
    SM Active Cycles                                                                 cycle                       5.707,50
    SM [%]                                                                               %                           6,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          36
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         36.864
    Waves Per SM                                                                                                        1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,98
    Achieved Active Warps Per SM                                                      warp                          27,51
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 1ul> const, Eigen::TensorReshapingOp<Eigen::Sizes<1l> const, Eigen::TensorMap<Eigen::TensorFixedSize<float const, Eigen::Sizes<>, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:50, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,20
    SM Frequency                                                             cycle/usecond                         804,17
    Elapsed Cycles                                                                   cycle                          3.095
    Memory [%]                                                                           %                           0,77
    SOL DRAM                                                                             %                           0,25
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          12,14
    SOL L2 Cache                                                                         %                           0,77
    SM Active Cycles                                                                 cycle                          44,39
    SM [%]                                                                               %                           0,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             19
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          54,17
    Achieved Active Warps Per SM                                                      warp                          17,33
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:40:57, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,93
    SM Frequency                                                             cycle/usecond                         757,07
    Elapsed Cycles                                                                   cycle                          2.593
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,42
    SOL L1/TEX Cache                                                                     %                          12,54
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          32,56
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,87
    Achieved Active Warps Per SM                                                      warp                          17,88
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:41:04, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           4,88
    SM Frequency                                                             cycle/usecond                         761,70
    Elapsed Cycles                                                                   cycle                          2.658
    Memory [%]                                                                           %                           0,68
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,49
    SOL L1/TEX Cache                                                                     %                          12,49
    SOL L2 Cache                                                                         %                           0,68
    SM Active Cycles                                                                 cycle                          32,69
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          55,89
    Achieved Active Warps Per SM                                                      warp                          17,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:41:10, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,02
    SM Frequency                                                             cycle/usecond                         773,01
    Elapsed Cycles                                                                   cycle                          2.722
    Memory [%]                                                                           %                           0,76
    SOL DRAM                                                                             %                           0,03
    Duration                                                                       usecond                           3,52
    SOL L1/TEX Cache                                                                     %                          11,73
    SOL L2 Cache                                                                         %                           0,76
    SM Active Cycles                                                                 cycle                          34,81
    SM [%]                                                                               %                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          66,42
    Achieved Active Warps Per SM                                                      warp                          21,25
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:41:17, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,17
    SM Frequency                                                             cycle/usecond                         798,61
    Elapsed Cycles                                                                   cycle                          3.325
    Memory [%]                                                                           %                           0,98
    SOL DRAM                                                                             %                           0,04
    Duration                                                                       usecond                           4,16
    SOL L1/TEX Cache                                                                     %                           8,06
    SOL L2 Cache                                                                         %                           0,98
    SM Active Cycles                                                                 cycle                             51
    SM [%]                                                                               %                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             30
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          45,05
    Achieved Active Warps Per SM                                                      warp                          14,42
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:41:24, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,03
    SM Frequency                                                             cycle/usecond                         774,05
    Elapsed Cycles                                                                   cycle                          2.602
    Memory [%]                                                                           %                           0,70
    SOL DRAM                                                                             %                           0,05
    Duration                                                                       usecond                           3,36
    SOL L1/TEX Cache                                                                     %                          13,00
    SOL L2 Cache                                                                         %                           0,70
    SM Active Cycles                                                                 cycle                          31,42
    SM [%]                                                                               %                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          57,70
    Achieved Active Warps Per SM                                                      warp                          18,46
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_128x32_nn, 2021-May-03 21:41:31, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,96
    SM Frequency                                                             cycle/usecond                         922,28
    Elapsed Cycles                                                                   cycle                         14.584
    Memory [%]                                                                           %                          30,73
    SOL DRAM                                                                             %                          17,85
    Duration                                                                       usecond                          15,81
    SOL L1/TEX Cache                                                                     %                          52,34
    SOL L2 Cache                                                                         %                          12,32
    SM Active Cycles                                                                 cycle                      10.317,47
    SM [%]                                                                               %                          30,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          30
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          16,38
    Threads                                                                         thread                          7.680
    Waves Per SM                                                                                                     0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 30 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                              4
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,93
    Achieved Active Warps Per SM                                                      warp                           7,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*), 2021-May-03 21:41:38, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,33
    SM Frequency                                                             cycle/usecond                         819,35
    Elapsed Cycles                                                                   cycle                          4.907
    Memory [%]                                                                           %                          20,22
    SOL DRAM                                                                             %                          20,22
    Duration                                                                       usecond                           5,98
    SOL L1/TEX Cache                                                                     %                          10,69
    SOL L2 Cache                                                                         %                           9,42
    SM Active Cycles                                                                 cycle                       3.117,53
    SM [%]                                                                               %                           6,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          75
    Registers Per Thread                                                   register/thread                             45
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          9.600
    Waves Per SM                                                                                                     0,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          24,91
    Achieved Active Warps Per SM                                                      warp                           7,97
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:41:45, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,19
    SM Frequency                                                             cycle/usecond                         945,20
    Elapsed Cycles                                                                   cycle                          3.271
    Memory [%]                                                                           %                           3,27
    SOL DRAM                                                                             %                           3,10
    Duration                                                                       usecond                           3,46
    SOL L1/TEX Cache                                                                     %                          14,66
    SOL L2 Cache                                                                         %                           3,27
    SM Active Cycles                                                                 cycle                         462,19
    SM [%]                                                                               %                           2,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          91,38
    Achieved Active Warps Per SM                                                      warp                          29,24
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:41:52, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         811,39
    Elapsed Cycles                                                                   cycle                          3.508
    Memory [%]                                                                           %                           2,77
    SOL DRAM                                                                             %                           2,77
    Duration                                                                       usecond                           4,32
    SOL L1/TEX Cache                                                                     %                          13,02
    SOL L2 Cache                                                                         %                           2,65
    SM Active Cycles                                                                 cycle                         318,64
    SM [%]                                                                               %                           2,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          10
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         10.240
    Waves Per SM                                                                                                     0,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 36             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,67
    Achieved Active Warps Per SM                                                      warp                          28,05
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:41:59, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,10
    SM Frequency                                                             cycle/usecond                         940,28
    Elapsed Cycles                                                                   cycle                         15.618
    Memory [%]                                                                           %                           3,74
    SOL DRAM                                                                             %                           2,47
    Duration                                                                       usecond                          16,61
    SOL L1/TEX Cache                                                                     %                          37,06
    SOL L2 Cache                                                                         %                           2,58
    SM Active Cycles                                                                 cycle                       1.575,86
    SM [%]                                                                               %                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            512
    Waves Per SM                                                                                                     0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:42:06, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,15
    SM Frequency                                                             cycle/usecond                         942,57
    Elapsed Cycles                                                                   cycle                          3.199
    Memory [%]                                                                           %                           1,28
    SOL DRAM                                                                             %                           1,10
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                          13,29
    SOL L2 Cache                                                                         %                           1,28
    SM Active Cycles                                                                 cycle                         178,89
    SM [%]                                                                               %                           1,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,51
    Achieved Active Warps Per SM                                                      warp                          27,04
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 0>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:42:13, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,21
    SM Frequency                                                             cycle/usecond                         792,44
    Elapsed Cycles                                                                   cycle                          3.274
    Memory [%]                                                                           %                           1,19
    SOL DRAM                                                                             %                           1,03
    Duration                                                                       usecond                           4,13
    SOL L1/TEX Cache                                                                     %                          13,87
    SOL L2 Cache                                                                         %                           1,19
    SM Active Cycles                                                                 cycle                         118,97
    SM [%]                                                                               %                           0,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           4
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          4.096
    Waves Per SM                                                                                                     0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          88,09
    Achieved Active Warps Per SM                                                      warp                          28,19
    ---------------------------------------------------------------------- --------------- ------------------------------

  volta_sgemm_32x32_sliced1x4_nn, 2021-May-03 21:42:20, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           6,05
    SM Frequency                                                             cycle/usecond                         932,56
    Elapsed Cycles                                                                   cycle                          9.789
    Memory [%]                                                                           %                           1,12
    SOL DRAM                                                                             %                           0,47
    Duration                                                                       usecond                          10,50
    SOL L1/TEX Cache                                                                     %                          31,46
    SOL L2 Cache                                                                         %                           1,12
    SM Active Cycles                                                                 cycle                         226,78
    SM [%]                                                                               %                           0,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             86
    Shared Memory Configuration Size                                                 Kbyte                          65,54
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                             Kbyte/block                          32,77
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                              2
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                              8
    Theoretical Occupancy                                                                %                             25
    Achieved Occupancy                                                                   %                          12,49
    Achieved Active Warps Per SM                                                      warp                           4,00
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int), 2021-May-03 21:42:27, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         926,17
    Elapsed Cycles                                                                   cycle                          2.846
    Memory [%]                                                                           %                           0,72
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                          13,93
    SOL L2 Cache                                                                         %                           0,72
    SM Active Cycles                                                                 cycle                          37,89
    SM [%]                                                                               %                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             18
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          61,98
    Achieved Active Warps Per SM                                                      warp                          19,83
    ---------------------------------------------------------------------- --------------- ------------------------------

  void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type), 2021-May-03 21:42:34, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                              6
    SM Frequency                                                             cycle/usecond                         924,67
    Elapsed Cycles                                                                   cycle                          2.841
    Memory [%]                                                                           %                           1,32
    SOL DRAM                                                                             %                           0,14
    Duration                                                                       usecond                           3,07
    SOL L1/TEX Cache                                                                     %                           5,52
    SOL L2 Cache                                                                         %                           1,32
    SM Active Cycles                                                                 cycle                         290,11
    SM [%]                                                                               %                           0,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             42
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             10
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,45
    Achieved Active Warps Per SM                                                      warp                           3,98
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c21SubtractAndExpFunctorIffEENS2_21CountingInputIteratorIilEElEEPfNS2_3SumEEEvT_T0_iiT1_NSt15iterator_traitsISC_E10value_typeE, 2021-May-03 21:42:41, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,92
    SM Frequency                                                             cycle/usecond                         922,41
    Elapsed Cycles                                                                   cycle                          3.130
    Memory [%]                                                                           %                           1,63
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           3,39
    SOL L1/TEX Cache                                                                     %                           4,57
    SOL L2 Cache                                                                         %                           1,63
    SM Active Cycles                                                                 cycle                         350,11
    SM [%]                                                                               %                           0,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          12,46
    Achieved Active Warps Per SM                                                      warp                           3,99
    ---------------------------------------------------------------------- --------------- ------------------------------

  _ZN10tensorflow88_GLOBAL__N__64_tmpxft_0000650a_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_a03ead0c22GenerateNormalizedProbIffLi4EEEvPKT_PKT0_S4_PS2_iib, 2021-May-03 21:42:48, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,88
    SM Frequency                                                             cycle/usecond                         913,66
    Elapsed Cycles                                                                   cycle                          4.242
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,13
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                           7,07
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          75,78
    SM [%]                                                                               %                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        128
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             37
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11,67
    Achieved Active Warps Per SM                                                      warp                           3,74
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<long long, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:42:55, Context 1, Stream 13
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           5,97
    SM Frequency                                                             cycle/usecond                         925,18
    Elapsed Cycles                                                                   cycle                          4.028
    Memory [%]                                                                           %                           1,23
    SOL DRAM                                                                             %                           0,12
    Duration                                                                       usecond                           4,35
    SOL L1/TEX Cache                                                                     %                           6,33
    SOL L2 Cache                                                                         %                           1,23
    SM Active Cycles                                                                 cycle                          70,64
    SM [%]                                                                               %                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           1
    Registers Per Thread                                                   register/thread                             32
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.024
    Waves Per SM                                                                                                     0,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 36              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources.            

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          27,20
    Achieved Active Warps Per SM                                                      warp                           8,70
    ---------------------------------------------------------------------- --------------- ------------------------------

  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long), 2021-May-03 21:43:02, Context 1, Stream 13
